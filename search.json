[
  {
    "objectID": "slides/02_rv.html#確率空間の公理",
    "href": "slides/02_rv.html#確率空間の公理",
    "title": "確率論",
    "section": "確率空間の公理",
    "text": "確率空間の公理\n確率空間 \\((\\Omega,\\,P)\\) の公理\n\n\\(\\Omega\\colon\\) (非可算でもよい)集合(標本空間)\n\\(P\\colon 2^\\Omega\\to\\mathbb{R}_{\\ge 0}\\) (確率測度)\n\n\n\n\\(P(\\Omega)=1\\). \n\\(\\forall (A_n\\subseteq\\Omega)_{n\\ge 0}\\), \\(\\forall i\\ne j,\\, A_i\\cap A_j=\\varnothing\\implies P\\left(\\bigcup_{n\\ge0} A_n\\right)=\\sum_{n\\ge0} P(A_n)\\) (完全加法性, \\(\\sigma\\)-加法性).\n\n\n\n本当は正しくないけど"
  },
  {
    "objectID": "slides/02_rv.html#確率空間の例",
    "href": "slides/02_rv.html#確率空間の例",
    "title": "確率論",
    "section": "確率空間の例",
    "text": "確率空間の例\n一回のコイン投げ\n\n\n\\(\\Omega = \\{\\mathrm{H},\\mathrm{T}\\}\\).\n\\(P(A) = \\frac{|A|}2\\qquad\\forall A\\subseteq\\Omega\\).\n\n\n二回の独立なコイン投げ\n\n\n\\(\\Omega = \\{\\mathrm{HH},\\mathrm{HT},\\mathrm{TH},\\mathrm{TT}\\}\\).\n\\(P(A) = \\frac{|A|}4\\qquad\\forall A\\subseteq\\Omega\\).\n\n\n実数\n\n\n\\(\\Omega = [0,1)\\).\n\\(P([a,b)) = b-a\\qquad\\forall A\\subseteq\\Omega\\)."
  },
  {
    "objectID": "slides/02_rv.html#確率変数",
    "href": "slides/02_rv.html#確率変数",
    "title": "確率論",
    "section": "確率変数",
    "text": "確率変数\n実際に知りたい情報は限定されている。\n\\(100\\) 回コインを投げると \\(2^{100}\\) 通りの結果があるが、興味がある情報は例えば以下のものがある。\n\n\n\\(k\\) 回目に表が出たか裏が出たか\n表が出た回数\n二回連続同じ面が出た回数\n連続して何回表が出たか\n\n\n\n確率変数\n\\((\\Omega,\\,P)\\) を確率空間とするとき、関数 \\(X\\colon \\Omega\\to\\mathbb{R}\\) を確率変数とよぶ。 また、実数 \\(a\\in\\mathbb{R}\\) について \\[\\begin{align*}\n\\Pr(X\\le a) &\\coloneqq P(\\left\\{\\omega\\in\\Omega\\mid X(\\omega)\\le a\\right\\})\n\\end{align*}\\] と表す。 \\(\\Pr(X\\ge a),\\,\\Pr(X=a),\\,\\Pr(X&lt;a),\\,\\Pr(X&gt;a)\\) なども同様に定義される。\n\n\n例えば、\\(\\Omega=\\{\\mathrm{HH},\\mathrm{HT},\\mathrm{TH},\\mathrm{TT}\\}\\) のとき、.\n\\[\\begin{align*}\nX_1(\\mathrm{HH}) &= X_1(\\mathrm{HT}) = 1,& X_1(\\mathrm{TH}) = X_1(\\mathrm{TT}) = 0\\\\\nX_2(\\mathrm{HH}) &= X_2(\\mathrm{TH}) = 1,& X_2(\\mathrm{HT}) = X_2(\\mathrm{TT}) = 0\\\\\nX&=X_1+X_2\n\\end{align*}\\]"
  },
  {
    "objectID": "slides/02_rv.html#累積分布関数",
    "href": "slides/02_rv.html#累積分布関数",
    "title": "確率論",
    "section": "累積分布関数",
    "text": "累積分布関数\n確率変数 \\(X\\) の累積分布関数 (cumulative distribution function)\n\\[\\begin{align*}\nF_X(x) &\\coloneqq \\Pr(X\\le x)\\qquad\\forall x\\in\\mathbb{R}\n\\end{align*}\\]\n累積分布関数は定義より単調非減少関数であることが分かる。 累積分布関数は連続とは限らないが右連続であることは以下のように確認できる。\n\\[\\begin{align*}\n\\lim_{n\\to\\infty} \\Pr\\left(X \\le x + \\frac1n\\right) &=\n\\lim_{n\\to\\infty} P\\left(\\left\\{\\omega\\in\\Omega\\mid X(\\omega) \\le x + \\frac1n\\right\\}\\right)\\\\\n&= P\\left(\\bigcap_{n=1}^\\infty \\left\\{\\omega\\in\\Omega\\mid X(\\omega) \\le x + \\frac1n\\right\\}\\right)\\\\\n&= P\\left(\\left\\{\\omega\\in\\Omega\\mid X(\\omega) \\le x\\right\\}\\right)\\\\\n&= \\Pr\\left(X\\le x\\right).\n\\end{align*}\\]\n累積分布関数は以下の性質を持つ。\n\n\\(F_X\\) は単調非減少。\n\\(F_X\\) は右連続。\n\\(\\lim_{x\\to\\infty}F_X(x) = 1\\).\n\\(\\lim_{x\\to-\\infty}F_X(x) = 0\\).\n\n逆にこれらの性質を満たしていれば、何かしらの確率変数 \\(X\\) の累積分布関数とみなせる。"
  },
  {
    "objectID": "slides/02_rv.html#累積分布関数の例",
    "href": "slides/02_rv.html#累積分布関数の例",
    "title": "確率論",
    "section": "累積分布関数の例",
    "text": "累積分布関数の例\n二項分布 \\(\\mathrm{Binomial}(n,p)\\colon\\) 表が出る確率が \\(p\\in[0,1]\\) のコインを独立に \\(n\\) 回投げて表が出る回数\n\\[\\begin{align*}\n\\Pr(X=k) &= \\binom{n}{k} p^k(1-p)^{n-k}\\qquad\\forall k\\in\\{0,1,\\dotsc,n\\}\\\\\nF_X(k) &= \\sum_{i=0}^k \\binom{n}{i} p^i(1-p)^{n-i}.\n\\end{align*}\\]\n\n\n\n\n\n\n\n\n\nFigure 1: 二項分布の累積分布関数"
  },
  {
    "objectID": "slides/02_rv.html#離散型確率変数",
    "href": "slides/02_rv.html#離散型確率変数",
    "title": "確率論",
    "section": "離散型確率変数",
    "text": "離散型確率変数\n離散型確率変数: 像が高々可算無限の確率変数\n任意の \\(A\\subseteq\\mathrm{Image}(X)\\) について、 \\[\\begin{align*}\n\\Pr(X\\in A) &= P\\left(\\{\\omega\\in\\Omega\\mid X(\\omega)\\in A\\}\\right)\\\\\n&= P\\left(\\bigcup_{x\\in A} \\{\\omega\\in\\Omega\\mid X(\\omega)=x\\}\\right)\\\\\n&= \\sum_{x\\in A} P\\left(\\{\\omega\\in\\Omega\\mid X(\\omega)=x\\}\\right)\\\\\n&= \\sum_{x\\in A} \\Pr\\left(X=x\\right)\n\\end{align*}\\]\n確率質量関数 (probability mass function) \\[\\begin{align*}\nf_X(x)&\\coloneqq \\Pr(X=x)\\qquad\\forall x\\in\\mathbb{R}.\n\\end{align*}\\]\nすると \\[\\begin{align*}\n\\Pr(X\\in A) &= \\sum_{x\\in A} f_X(x).\n\\end{align*}\\]"
  },
  {
    "objectID": "slides/02_rv.html#確率質量関数の例",
    "href": "slides/02_rv.html#確率質量関数の例",
    "title": "確率論",
    "section": "確率質量関数の例",
    "text": "確率質量関数の例\n二項分布 \\(\\mathrm{Binomial}(n,p)\\colon\\)\n\\[\\begin{align*}\nf_X(k) &= \\binom{n}{k} p^k(1-p)^{n-k}.\n\\end{align*}\\]\n\n\n\n\n\n\n\n\n\nFigure 2: 二項分布の確率質量関数"
  },
  {
    "objectID": "slides/02_rv.html#連続型確率変数",
    "href": "slides/02_rv.html#連続型確率変数",
    "title": "確率論",
    "section": "連続型確率変数",
    "text": "連続型確率変数\n連続型確率変数: 離散型確率変数でない確率変数\n確率密度関数 (probability density function) \\[\\begin{align*}\n\\Pr(X\\in A) &= \\int_{A} f_X(x) \\mathrm{d}x.\n\\end{align*}\\] を満たす関数 \\(f_X\\colon\\mathbb{R}\\to\\mathbb{R}_{\\ge 0}\\). 離散確率変数に対する \\[\\begin{align*}\n\\Pr(X\\in A) &= \\sum_{x\\in A} f_X(x)\n\\end{align*}\\]\nと同じ形。 一般的には確率密度関数は存在するとは限らない。\n累積分布関数 \\(F_X(x)\\) が微分可能なとき、 \\[\\begin{align*}\nf_X(x) &= \\frac{\\mathrm{d} F_X}{\\mathrm{d}x}\n\\end{align*}\\]\nとおくと \\[\\begin{align*}\n\\int_{-\\infty}^x f_X(z) \\mathrm{d}z &= F_X(x)\n\\end{align*}\\] を満たす。 累積分布関数が連続で微分不可能な点が飛び飛びにある場合も確率密度関数は \\(f_X = F_X'\\) と取れる。 累積分布関数が微分不可能な点は確率密度関数の値を任意に決めてよい。"
  },
  {
    "objectID": "slides/02_rv.html#連続確率変数の例",
    "href": "slides/02_rv.html#連続確率変数の例",
    "title": "確率論",
    "section": "連続確率変数の例",
    "text": "連続確率変数の例\n正規分布(ガウス分布) \\(N(\\mu,\\sigma^2)\\colon\\)\n\\[\\begin{align*}\nf_X(x) &= \\frac1{\\sqrt{2\\pi\\sigma^2}}\\mathrm{e}^{-\\frac{(x-\\mu)^2}{2\\sigma^2}},&\nF_X(x) &= \\int_{-\\infty}^x \\frac1{\\sqrt{2\\pi\\sigma^2}}\\mathrm{e}^{-\\frac{(z-\\mu)^2}{2\\sigma^2}}\\mathrm{d}z\n\\end{align*}\\]\n特に \\(\\mu=0\\), \\(\\sigma=1\\) のとき標準正規分布という。\n\n\n\n\n\n\n\n\n\nFigure 3: 標準正規分布の確率密度関数\n\n\n\n\n\n\n\n\n\n\n\nFigure 4: 標準正規分布の累積分布関数"
  },
  {
    "objectID": "slides/02_rv.html#離散確率変数の例",
    "href": "slides/02_rv.html#離散確率変数の例",
    "title": "確率論",
    "section": "離散確率変数の例",
    "text": "離散確率変数の例\n\n二項分布 \\(\\mathrm{Binomial}(n,p)\\): 表が出る確率が \\(p\\) のコインを \\(n\\) 回独立に投げたとき、表が出る回数の分布 \\[\\Pr(X=k) = \\binom{n}{k} p^k (1-p)^{n-k}.\\]\n幾何分布 \\(\\mathrm{Geometric}(p)\\): 表が出るまでに投げるコインの回数の分布 \\[\\Pr(X=k) = (1-p)^{k-1}p.\\]\n超幾何分布 \\(\\mathrm{HyperGeometric}(N,K,n)\\): 袋の中に \\(N\\) 個のボールがあって、そのうち \\(K\\) 個が当たりとし、 \\(n\\) 個引いたときの当たりの個数の分布 \\[\\Pr(X=k) = \\frac{\\binom{K}{k}\\binom{N-K}{n-k}}{\\binom{N}{n}}.\\]\nポアソン分布 \\(\\mathrm{Poisson}(\\lambda)\\): \\[\n\\Pr(X=k) = \\frac{\\lambda^k}{k!}\\mathrm{e}^{-\\lambda}.\n\\]"
  },
  {
    "objectID": "slides/02_rv.html#幾何分布",
    "href": "slides/02_rv.html#幾何分布",
    "title": "確率論",
    "section": "幾何分布",
    "text": "幾何分布\n幾何分布 \\(\\mathrm{Geometric}(p)\\): 表が出る確率が \\(p\\in[0,1]\\) のコインを独立に何度も投げて表が出るまでに投げる回数\n\\[\nf_X(k) = (1-p)^{k-1}p,\\qquad\\forall k\\ge 1\n\\]\n\n\n\n\n\n\n\n\n\nFigure 5: 幾何分布の確率質量関数\n\n\n\n\n\n\n\n\n\n\n\nFigure 6: 幾何分布の累積分布関数"
  },
  {
    "objectID": "slides/02_rv.html#超幾何分布",
    "href": "slides/02_rv.html#超幾何分布",
    "title": "確率論",
    "section": "超幾何分布",
    "text": "超幾何分布\n超幾何分布 \\(\\mathrm{HyperGeometric}(N,K,n)\\): 袋の中に \\(N\\) 個のボールがあって、そのうち \\(K\\) 個が当たりとし、 \\(n\\) 個引いたときの当たりの個数\n\\[\nf_X(k) = \\frac{\\binom{K}{k}\\binom{N-K}{n-k}}{\\binom{N}{n}},\\qquad\\forall k\\in \\{0,\\dotsc,\\min\\{K, n\\}\\}\n\\]\n\n\n\n\n\n\n\n\n\nFigure 7: 超幾何分布の確率質量関数\n\n\n\n\n\n\n\n\n\n\n\nFigure 8: 超幾何分布の累積分布関数"
  },
  {
    "objectID": "slides/02_rv.html#ポアソン分布",
    "href": "slides/02_rv.html#ポアソン分布",
    "title": "確率論",
    "section": "ポアソン分布",
    "text": "ポアソン分布\n正のパラメータ \\(\\lambda\\in\\mathbb{R}_{&gt;0}\\) について、ポアソン分布 \\(\\mathrm{Poisson}(\\lambda)\\) の確率質量関数は\n\\[\nf_X(k) = \\frac{\\lambda^k}{k!}\\mathrm{e}^{-\\lambda},\\qquad \\forall k\\ge 0.\n\\]\n\n\n\n\n\n\n\n\n\nFigure 9: ポアソン分布の確率質量関数\n\n\n\n\n\n\n\n\n\n\n\nFigure 10: ポアソン分布の累積分布関数"
  },
  {
    "objectID": "slides/02_rv.html#一様分布",
    "href": "slides/02_rv.html#一様分布",
    "title": "確率論",
    "section": "一様分布",
    "text": "一様分布\n実数 \\(a&lt;b\\) について、一様分布 \\(\\mathrm{U}(a,b)\\) の確率密度関数と累積分布関数は\n\\[\\begin{align*}\nf_X(x) &= \\begin{cases}\n\\frac1{b-a}& \\text{if } x\\in[a,b]\\\\\n0&\\text{otherwise}\n\\end{cases},&\nF_X(x) &= \\begin{cases}\n0&\\text{if } x &lt; a\\\\\n\\frac{x-a}{b-a}&\\text{if } x \\in[a,b]\\\\\n1&\\text{otherwise.}\n\\end{cases}\n\\end{align*}\\]\n\n\n\n\n\n\n\n\n\nFigure 11: 一様分布の確率密度関数\n\n\n\n\n\n\n\n\n\n\n\nFigure 12: 一様分布の累積分布関数"
  },
  {
    "objectID": "slides/02_rv.html#正規分布-ガウス分布",
    "href": "slides/02_rv.html#正規分布-ガウス分布",
    "title": "確率論",
    "section": "正規分布 (ガウス分布)",
    "text": "正規分布 (ガウス分布)\nパラメータ \\(\\mu\\in\\mathbb{R},\\,\\sigma\\in\\mathbb{R}_{&gt;0}\\) について、正規分布 \\(N(\\mu,\\sigma^2)\\) の確率密度関数と累積分布関数は \\[\\begin{align*}\nf_X(x) &= \\frac1{\\sqrt{2\\pi\\sigma^2}}\\mathrm{e}^{-\\frac{(x-\\mu)^2}{2\\sigma^2}},&\nF_X(x) &= \\int_{-\\infty}^x \\frac1{\\sqrt{2\\pi\\sigma^2}}\\mathrm{e}^{-\\frac{(z-\\mu)^2}{2\\sigma^2}}\\mathrm{d}z.\n\\end{align*}\\]\n特に \\(\\mu=0\\), \\(\\sigma=1\\) のとき標準正規分布という。\n\n\n\n\n\n\n\n\n\nFigure 13: 標準正規分布の確率密度関数\n\n\n\n\n\n\n\n\n\n\n\nFigure 14: 標準正規分布の累積分布関数"
  },
  {
    "objectID": "slides/02_rv.html#指数分布",
    "href": "slides/02_rv.html#指数分布",
    "title": "確率論",
    "section": "指数分布",
    "text": "指数分布\nパラメータ \\(\\lambda\\in\\mathbb{R}_{&gt;0}\\) について、指数分布 \\(\\mathrm{Exp}(\\lambda)\\) の確率密度関数と累積分布関数は\n\\[\\begin{align*}\nf_X(x) &= \\begin{cases}\n0&\\text{if } x &lt; 0\\\\\n\\lambda\\mathrm{e}^{-\\lambda x}&\\text{otherwise}\n\\end{cases},&\nF_X(x) &= \\begin{cases}\n0&\\text{if } x &lt; 0\\\\\n1-\\mathrm{e}^{-\\lambda x}&\\text{otherwise}\n\\end{cases}\n\\end{align*}\\]\n\n\n\n\n\n\n\n\n\nFigure 15: 指数分布の確率密度関数\n\n\n\n\n\n\n\n\n\n\n\nFigure 16: 指数分布の累積分布関数"
  },
  {
    "objectID": "slides/02_rv.html#確率変数確率分布確率空間",
    "href": "slides/02_rv.html#確率変数確率分布確率空間",
    "title": "確率論",
    "section": "確率変数、確率分布、確率空間",
    "text": "確率変数、確率分布、確率空間\n確率変数 \\(X\\) の累積分布関数が○○分布の累積分布関数と等しいとき、 「確率変数 \\(X\\) は○○分布に従う」という。\n例えば「確率変数 \\(X\\) は二項分布 \\(\\mathrm{Binomial}(n,p)\\) に従う」という。 このとき、\\(X\\sim\\mathrm{Binomial}(n,p)\\) と表す。\n\n確率空間を陽に定義しないで確率変数を考えることも多い。 確率変数が特定の値を取る確率を解析したいときには確率空間の定義は不要。\n\n離散型確率変数は自然に説明できるものが多いので、自然な確率空間を考えることができることが多い。\n\n二項分布: \\(n\\) 回のコイン投げ、もしくは無限回のコイン投げ。\n幾何分布: 無限回のコイン投げ。\n超幾何分布: \\(K\\) 個の当たりと \\(N-K\\) 個のはずれのボールの \\(\\binom{N}{K}\\) 通りの並び順。\nポアソン分布: ？\n\n\n今後は主に確率変数を用いた確率の解析をしていく。 確率空間を陽に考えることは少ない。"
  },
  {
    "objectID": "slides/02_rv.html#xa-の確率密度関数",
    "href": "slides/02_rv.html#xa-の確率密度関数",
    "title": "確率論",
    "section": "\\(X+a\\) の確率密度関数",
    "text": "\\(X+a\\) の確率密度関数\n\nLemma 1 確率密度関数を持つ任意の確率変数 \\(X\\) と \\(a\\in\\mathbb{R}\\) について、 \\[\\begin{align*}\nf_{X+a}(x) &= f_X(x-a)\n\\end{align*}\\] は \\(X+a\\) の確率密度関数になる。\n\n\nProof. 関数 \\(f_Z\\colon \\mathbb{R}\\to\\mathbb{R}_{\\ge 0}\\) が\n\\[\n\\Pr(Z\\le x) = \\int_{-\\infty}^x f_Z(z)\\mathrm{d} z\n\\]\nを満たすとき、\\(f_Z\\) は確率変数 \\(Z\\) の確率密度関数となる。\n任意の \\(a\\in\\mathbb{R}\\) について、 \\[\\begin{align*}\n\\Pr(X+a\\le x) &= \\Pr(X\\le x-a)\\\\\n&= \\int_{-\\infty}^{x-a} f_{X}(z)\\mathrm{d}z\\\\\n&= \\int_{-\\infty}^{x} f_{X}(z'-a)\\mathrm{d}z'\\qquad (z'=z+a).\n\\end{align*}\\]"
  },
  {
    "objectID": "slides/02_rv.html#ax-の確率密度関数",
    "href": "slides/02_rv.html#ax-の確率密度関数",
    "title": "確率論",
    "section": "\\(aX\\) の確率密度関数",
    "text": "\\(aX\\) の確率密度関数\n\nLemma 2 確率密度関数を持つ任意の確率変数 \\(X\\) と \\(a\\in\\mathbb{R}_{\\ne 0}\\) について、 \\[\\begin{align*}\nf_{aX}(x) &= \\frac1{|a|} f_X(x/a)\n\\end{align*}\\] は \\(aX\\) の確率密度関数になる。\n\n\nProof. 関数 \\(f_Z\\colon \\mathbb{R}\\to\\mathbb{R}_{\\ge 0}\\) が\n\\[\n\\Pr(Z\\le x) = \\int_{-\\infty}^x f_Z(z)\\mathrm{d} z\n\\]\nを満たすとき、\\(f_Z\\) は確率変数 \\(Z\\) の確率密度関数となる。\n任意の \\(a&gt;0\\) について、 \\[\\begin{align*}\n\\Pr(aX\\le x) &= \\Pr(X\\le x/a)\\\\\n&= \\int_{-\\infty}^{x/a} f_{X}(z)\\mathrm{d}z\\\\\n&= \\int_{-\\infty}^{x} \\frac1{a} f_{X}(z'/a)\\mathrm{d}z'\\qquad (z'=az).\n\\end{align*}\\] \\(a&lt;0\\) についても同様。"
  },
  {
    "objectID": "slides/02_rv.html#gx-の確率密度関数",
    "href": "slides/02_rv.html#gx-の確率密度関数",
    "title": "確率論",
    "section": "\\(g(X)\\) の確率密度関数",
    "text": "\\(g(X)\\) の確率密度関数\n\nLemma 3 \\(J\\subseteq\\mathbb{R}\\) を有界とは限らない区間とし、\\(g\\colon J\\to\\mathbb{R}\\) を \\(J\\) の内点で微分可能で \\(g'(x)&gt;0\\) とする。 確率変数 \\(X\\) が \\(\\Pr(X\\in J) = 1\\) を満たし確率密度関数を持つとき、 \\[\\begin{align*}\nf_{g(X)}(x) &=\n\\begin{cases}\n\\frac1{g'(g^{-1}(x))} f_X(g^{-1}(x))&\\text{if } x\\in\\mathrm{Image}(g)\\\\\n0&\\text{otherwise}\n\\end{cases}\n\\end{align*}\\] は \\(g(X)\\) の確率密度関数になる。\n\n\nProof. \\(\\Pr(g(X)\\in\\mathrm{Image}(g)) = 1\\) なので、\\(x\\notin\\mathrm{Image}(g)\\) について \\(f_{g(X)}(x) = 0\\) とおいてよい。\n任意の \\(x\\in\\mathrm{Image}(g)\\) について \\[\\begin{align*}\n\\Pr(g(X)\\le x) &= \\Pr(X\\le g^{-1}(x))\\\\\n&= \\int_{-\\infty}^{g^{-1}(x)} f_{X}(z)\\mathrm{d}z\\\\\n&= \\int_{\\inf J}^{g^{-1}(x)} f_{X}(z)\\mathrm{d}z\\\\\n&= \\int_{\\inf \\mathrm{Image}(g)}^{x} f_{X}(g^{-1}(z')) \\frac1{g'(g^{-1}(z'))}\\mathrm{d}z'\\qquad (z'=g(z))\\\\\n&= \\int_{-\\infty}^{x} f_{g(X)}(z')\\mathrm{d}z'.\n\\end{align*}\\]"
  },
  {
    "objectID": "slides/02_rv.html#今週の課題",
    "href": "slides/02_rv.html#今週の課題",
    "title": "確率論",
    "section": "今週の課題",
    "text": "今週の課題\n以下の問に答えよ\n\n\n\\(\\Pr(X=1) = 0.2,\\,\\Pr(X=2)=0.1,\\,\\Pr(X=3)=0.7\\) を満たす確率変数 \\(X\\) の累積分布関数 \\(F_X(x)\\) を \\([0,4]\\) の区間で図示せよ。不連続点で取る値が分かるようにすること。\n\\(U\\sim\\mathrm{U}(0,1)\\) とする。このとき、\\(-2\\log U\\) の確率密度関数をもとめよ。すべての \\(x\\in\\mathbb{R}\\) に対する値を示すこと。"
  },
  {
    "objectID": "slides/macros.html",
    "href": "slides/macros.html",
    "title": "確率・統計基礎",
    "section": "",
    "text": "\\[\n\\newcommand{\\defiff}{\\overset{\\text{def}}{\\iff}}\n\\newcommand{\\expt}[1]{\\mathbb{E}\\left[#1\\right]}\n\\newcommand{\\var}[1]{\\mathrm{Var}\\left[#1\\right]}\n\\newcommand{\\cov}[2]{\\mathrm{Cov}\\left[#1,\\,#2\\right]}\n\\]"
  },
  {
    "objectID": "slides/04_moments.html#期待値",
    "href": "slides/04_moments.html#期待値",
    "title": "確率論",
    "section": "期待値",
    "text": "期待値\n\nDefinition 1 (期待値) 離散型確率変数 \\(X\\) の期待値は\n\\[\\begin{align*}\n\\expt{X}\n% &= \\sum_{\\omega \\in \\Omega} X(\\omega) P(\\{\\omega\\})\\\\\n%&= \\sum_{x\\in \\mathrm{Image}(X)} x P(\\{\\omega\\mid X(\\omega)=x\\})\\\\\n&\\coloneqq \\sum_{x\\in \\mathrm{Image}(X)} x \\Pr(X=x)\\\\\n&= \\sum_{x\\in \\mathrm{Image}(X)} x f_X(x)\n\\end{align*}\\]\nと定義される。ここで、右辺の和が絶対収束しない場合は(適当な順番で和を取って収束したとしても)期待値は定義されない。\n連続型確率変数 \\(X\\) が確率密度関数 \\(f_X\\) を持つとき、その期待値は\n\\[\n\\expt{X}\\coloneqq \\int_{-\\infty}^\\infty x f_X(x) \\mathrm{d}x\n\\]\nと定義される。 ただし、広義積分で上記の積分が存在する場合でも、 \\[\n\\int_{-\\infty}^\\infty |x| f_X(x) \\mathrm{d}x\n\\] が存在しない場合には期待値は定義されない。\n\n連続型確率変数の期待値に関する様々な証明はルベーグ積分の知識を必要とするのでこの授業では扱わない。 以下、証明はすべて離散確率変数の場合に限って与えて分かった気になることにする。"
  },
  {
    "objectID": "slides/04_moments.html#確率変数の和の期待値",
    "href": "slides/04_moments.html#確率変数の和の期待値",
    "title": "確率論",
    "section": "確率変数の和の期待値",
    "text": "確率変数の和の期待値\n\nLemma 1 確率変数 \\(X,\\,Y\\) について \\[\\begin{align*}\n\\expt{X+Y}&=\\expt{X}+\\expt{Y}.\n\\end{align*}\\]\n\n\nProof. \\[\\begin{align*}\n\\expt{X+Y} &= \\sum_{z} z f_{X+Y}(z)\\\\\n&= \\sum_{z} z \\sum_x f_{X,\\,Y}(x, z-x)\\\\\n&= \\sum_{x,\\,y} (x+y) f_{X,\\,Y}(x, y)\\qquad (y=z-x)\\\\\n&= \\sum_{x,\\,y} xf_{X,\\,Y}(x,y) + \\sum_{x,\\,y} yf_{X,\\,Y}(x,y)\\\\\n&= \\sum_{x} xf_{X}(x) + \\sum_{y} yf_{Y}(y)\\\\\n&= \\expt{X} + \\expt{Y}.\n\\end{align*}\\]"
  },
  {
    "objectID": "slides/04_moments.html#確率変数の積の期待値",
    "href": "slides/04_moments.html#確率変数の積の期待値",
    "title": "確率論",
    "section": "確率変数の積の期待値",
    "text": "確率変数の積の期待値\n\nLemma 2 確率変数 \\(X\\) と \\(Y\\) が独立のとき、 \\[\\begin{align*}\n\\expt{XY}&=\\expt{X}\\,\\expt{Y}.\n\\end{align*}\\]\n\n\nProof. \\[\\begin{align*}\n\\expt{XY} &= \\sum_{z} z f_{XY}(z)\\\\\n&= \\sum_{z} z \\sum_{x\\ne 0}f_{X,\\,Y}(x,z/x)\\\\\n&= \\sum_{z} z \\sum_{x\\ne 0}f_{X}(x)f_Y(z/x)\\\\\n&= \\sum_{x\\ne 0,\\, y} xy f_{X}(x)f_Y(y)\\qquad(y=z/x)\\\\\n&= \\sum_{x,\\, y} xy f_{X}(x)f_Y(y)\\\\\n&= \\left(\\sum_{x} xf_{X}(x)\\right)\\left(\\sum_y yf_Y(y)\\right)\\\\\n&= \\expt{X}\\,\\expt{Y}\n\\end{align*}\\]"
  },
  {
    "objectID": "slides/04_moments.html#期待値の簡潔な表現",
    "href": "slides/04_moments.html#期待値の簡潔な表現",
    "title": "確率論",
    "section": "期待値の簡潔な表現",
    "text": "期待値の簡潔な表現\n\nLemma 3 (Law of the unconscious statistician (LOTUS)) 任意の関数 \\(g\\colon\\mathbb{R}\\to\\mathbb{R}\\) について、\n\n\\(X\\) が離散型確率変数のとき、 \\[\\begin{align*}\n\\expt{g(X)} &= \\sum_{x} g(x) f_X(x).\n\\end{align*}\\]\n\\(X\\) が連続型確率変数で確率密度関数を持つとき、 \\[\\begin{align*}\n\\expt{g(X)} &= \\int_{-\\infty}^\\infty g(x) f_X(x) \\mathrm{d}x.\n\\end{align*}\\]\n\n\n\nProof. \\(X\\) を離散型確率変数とする。 \\[\\begin{align*}\n\\expt{g(X)}\n%&= \\sum_{x} x f_{g(X)}(x)\\\\\n&= \\sum_{x} x \\Pr(g(X) = x)\n= \\sum_{x} x P(\\{\\omega\\in\\Omega\\mid g(X(\\omega)) = x\\})\\\\\n&= \\sum_{x} x P\\left(\\bigcup_{y\\in\\mathrm{Image}(X)\\colon\\, g(y) = x}\\{\\omega\\in\\Omega\\mid X(\\omega) = y\\}\\right)\\\\\n&= \\sum_{x}\\sum_{y\\in\\mathrm{Image}(X)\\colon\\, g(y) = x} x P\\left(\\{\\omega\\in\\Omega\\mid X(\\omega) = y\\}\\right)\\\\\n&= \\sum_{y\\in\\mathrm{Image}(X)} g(y) f_X(y).\n\\end{align*}\\]"
  },
  {
    "objectID": "slides/04_moments.html#期待値の性質",
    "href": "slides/04_moments.html#期待値の性質",
    "title": "確率論",
    "section": "期待値の性質",
    "text": "期待値の性質\n\nProposition 1 (期待値の性質) 任意の確率変数 \\(X\\) と \\(a\\in\\mathbb{R}\\) について \\[\\begin{align*}\n\\expt{X+a} &= \\expt{X}+a\\\\\n\\expt{aX} &= a\\expt{X}.\n\\end{align*}\\]"
  },
  {
    "objectID": "slides/04_moments.html#マルコフの不等式",
    "href": "slides/04_moments.html#マルコフの不等式",
    "title": "確率論",
    "section": "マルコフの不等式",
    "text": "マルコフの不等式\n\nTheorem 1 (マルコフの不等式) 任意の非負確率変数 \\(X\\) と \\(a&gt;0\\) について \\[\n\\Pr(X\\ge a)\\le\\frac{\\expt{X}}{a}.\n\\]\n\n\nProof. \\[\\begin{align*}\n\\expt{X} &= \\sum_{x\\in \\mathrm{Image}(X)} f_X(x) x\\\\\n&= \\sum_{\\mathrm{Image}(X)\\colon\\, x\\ge a} f_X(x) x + \\sum_{\\mathrm{Image}(X)\\colon\\, x &lt; a} f_X(x) x\\\\\n&\\ge \\sum_{\\mathrm{Image}(X)\\colon\\, x\\ge a} f_X(x) x\\qquad\\qquad (\\Pr(X\\ge 0)=1)\\\\\n&\\ge \\sum_{\\mathrm{Image}(X)\\colon\\, x\\ge a} f_X(x) a\\\\\n&= \\Pr(X\\ge a) a.\n\\end{align*}\\]"
  },
  {
    "objectID": "slides/04_moments.html#分散",
    "href": "slides/04_moments.html#分散",
    "title": "確率論",
    "section": "分散",
    "text": "分散\n\nDefinition 2 (分散) 確率変数 \\(X\\) が期待値を持つとき、その分散を\n\\[\n\\var{X}\\coloneqq  \\expt{(X-\\expt{X})^2}\n\\]\nと定義する。 また、分散の平方根を標準偏差という。\n\n確率変数 \\(X\\) が分散を持つとき、\n\\[\\begin{align*}\n\\var{X} &= \\expt{(X-\\expt{X})^2}\\\\\n&= \\expt{X^2-2X\\expt{X}+\\expt{X}^2}\\\\\n&= \\expt{X^2}-2\\expt{X}\\expt{X}+\\expt{X}^2\\\\\n&= \\expt{X^2}-\\expt{X}^2\n\\end{align*}\\]\nである。 分散は定義より非負の値を持つ。\n\nProposition 2 (分散の性質) 任意の確率変数 \\(X\\) と \\(a\\in\\mathbb{R}\\) について \\[\\begin{align*}\n\\var{X+a} &= \\var{X}\\\\\n\\var{aX} &= a^2\\var{X}.\n\\end{align*}\\]\n\n分散は直感的には期待値からのはずれ具合を表す値である。"
  },
  {
    "objectID": "slides/04_moments.html#チェビシェフの不等式",
    "href": "slides/04_moments.html#チェビシェフの不等式",
    "title": "確率論",
    "section": "チェビシェフの不等式",
    "text": "チェビシェフの不等式\n\nTheorem 2 (チェビシェフの不等式) 任意の確率変数 \\(X\\) と \\(a&gt;0\\) について \\[\n\\Pr(|X-\\expt{X}|\\ge a)\\le\\frac{\\var{X}}{a^2}.\n\\]\n\n\nProof. \\[\\begin{align*}\n\\Pr(|X-\\expt{X}|\\ge a)&= \\Pr((X-\\expt{X})^2\\ge a^2)\\\\\n&\\le\n\\frac{\\expt{(X-\\expt{X})^2}}{a^2} = \\frac{\\var{X}}{a^2}.\n\\end{align*}\\]"
  },
  {
    "objectID": "slides/04_moments.html#互いに独立な確率変数の和",
    "href": "slides/04_moments.html#互いに独立な確率変数の和",
    "title": "確率論",
    "section": "互いに独立な確率変数の和",
    "text": "互いに独立な確率変数の和\n\nLemma 4 (互いに独立な確率変数の和) 確率変数 \\(X_1,\\,X_2,\\dotsc,X_n\\) が互いに独立のとき\n\\[\\begin{align*}\n\\var{X_1+\\dotsb+X_n} &= \\var{X_1} +\\dotsb + \\var{X_n}.\n\\end{align*}\\]\n\n\nProof. \\[\\begin{align*}\n\\var{X_1+\\dotsb+X_n} &= \\expt{\\left((X_1+\\dotsb+X_n) - \\expt{X_1+\\dotsb+X_n}\\right)^2}\\\\\n&= \\expt{\\left((X_1- \\expt{X_1}) + \\dotsb + (X_n-\\expt{X_n})\\right)^2}\\\\\n&= \\expt{\\sum_i (X_i- \\expt{X_i})^2  + 2\\sum_{i &lt; j}\\left(X_i-\\expt{X_i}\\right)\\left(X_j-\\expt{X_j}\\right)}\\\\\n&= \\sum_i \\expt{(X_i- \\expt{X_i})^2} +  2\\sum_{i &lt; j}\\expt{\\left(X_i-\\expt{X_i}\\right)\\left(X_j-\\expt{X_j}\\right)}\\\\\n&= \\sum_i \\expt{(X_i- \\expt{X_i})^2} +  2\\sum_{i &lt; j}\\expt{X_i-\\expt{X_i}}\\expt{X_j-\\expt{X_j}}\\\\\n&= \\sum_i \\expt{(X_i- \\expt{X_i})^2}\n=\\sum_i \\var{X_i}.\n\\end{align*}\\]"
  },
  {
    "objectID": "slides/04_moments.html#確率変数の平均",
    "href": "slides/04_moments.html#確率変数の平均",
    "title": "確率論",
    "section": "確率変数の平均",
    "text": "確率変数の平均\n\nExample 1 互いに独立な確率変数 \\(X_1,\\dotsc,X_n\\) のそれぞれが確率変数 \\(X\\) と同分布であるとし、 \\[\\begin{align*}\nY&\\coloneqq \\frac1{n} (X_1+\\dotsb+X_n)\n\\end{align*}\\] と定義する。 このとき、 \\[\\begin{align*}\n\\expt{Y} &= \\expt{X}\\\\\n\\var{Y} &= \\frac1{n}\\var{X}\n\\end{align*}\\] である。互いに独立な確率変数の平均を取ると期待値は変わらず、分散は小さくなる。\nチェビシェフの不等式を適用すると、\\(Y\\) は \\(n\\) を大きくすると期待値周辺に集中していくことが分かる。"
  },
  {
    "objectID": "slides/04_moments.html#共分散",
    "href": "slides/04_moments.html#共分散",
    "title": "確率論",
    "section": "共分散",
    "text": "共分散\n\nDefinition 3 (共分散) 確率変数 \\(X,Y\\) が期待値を持つとき、その共分散を\n\\[\\begin{align*}\n\\cov{X}{Y} &\\coloneqq \\expt{(X-\\expt{X})(Y-\\expt{Y})}\\\\\n&= \\expt{XY}-\\expt{X}\\,\\expt{Y}\n\\end{align*}\\]\nと定義する。 共分散がゼロである確率変数のペアを無相関であるという。\n\n定義より、\\(\\cov{X}{X}=\\var{X}\\) であることが分かる。\n\nProposition 3 独立確率変数 \\(X,Y\\) は無相関である。"
  },
  {
    "objectID": "slides/04_moments.html#無相関だけど独立ではない例",
    "href": "slides/04_moments.html#無相関だけど独立ではない例",
    "title": "確率論",
    "section": "無相関だけど独立ではない例",
    "text": "無相関だけど独立ではない例\n逆に無相関であっても独立とは限らない。\n\nExample 2 確率変数 \\(X\\) を \\[\\begin{align*}\nf_X(0)= f_X(+1)= f_X(-1)= \\frac13\n\\end{align*}\\] を満たすものとし、\\(Y=X^2\\) とする。 このとき、 \\[\\begin{align*}\n\\cov{X}{Y} &= \\expt{XY} - \\expt{X}\\expt{Y}\\\\\n&= \\expt{X^3} - \\expt{X}\\expt{X^2}\\\\\n&= \\expt{X} - \\expt{X}\\expt{X^2}\\\\\n&= \\expt{X}(1-\\expt{X^2})\\\\\n&= 0\n\\end{align*}\\] なので、\\(X\\) と \\(Y\\) は無相関である。 一方で \\[\\begin{align*}\nf_{Y}(0) &= \\frac13&\nf_{Y}(1) &= \\frac23\\\\\nf_{X,\\,Y}(0, 0) &= \\frac13&\nf_{X,\\,Y}(1, 1) &= \\frac13&\nf_{X,\\,Y}(-1, 1) &= \\frac13&\n\\end{align*}\\] なので \\(X\\) と \\(Y\\) は独立ではない。"
  },
  {
    "objectID": "slides/04_moments.html#共分散と分散の関係",
    "href": "slides/04_moments.html#共分散と分散の関係",
    "title": "確率論",
    "section": "共分散と分散の関係",
    "text": "共分散と分散の関係\n共分散は正の値も負の値も取り得る。 大雑把に言うと、\n\n\\(X\\) と \\(Y\\) の共分散が正 \\(\\iff\\) \\(X\\) が大きいとき \\(Y\\) も大きい\n\\(X\\) と \\(Y\\) の共分散が負 \\(\\iff\\) \\(X\\) が大きいとき \\(Y\\) は小さい\n\nという意味になる。\n\nLemma 5 任意の確率変数 \\(X_1,\\dotsc,X_n\\) について \\[\\begin{align*}\n\\var{\\sum_i X_i} &= \\sum_i \\var{X_i} + 2\\sum_{i &lt; j} \\cov{X_i}{X_j}.\n\\end{align*}\\]\n\n\nProof. Lemma 4 の証明参照。"
  },
  {
    "objectID": "slides/04_moments.html#モーメントとモーメント母関数",
    "href": "slides/04_moments.html#モーメントとモーメント母関数",
    "title": "確率論",
    "section": "モーメントとモーメント母関数",
    "text": "モーメントとモーメント母関数\n\nDefinition 4 (モーメント) 確率変数 \\(X\\) と正の整数 \\(n\\ge 1\\) について、\n\\[\n\\mu_n(X)\\coloneqq \\expt{X^n}\n\\]\nを \\(X\\) の \\(n\\) 次モーメントという。\n\n\nDefinition 5 (モーメント母関数(積率母関数)) 確率変数 \\(X\\) について、\n\\[\nM_X(t) \\coloneqq \\expt{\\mathrm{e}^{tX}}\\qquad t\\in\\mathbb{R}\n\\]\nを \\(X\\) のモーメント母関数という。 すべての \\(t\\in\\mathbb{R}\\) で \\(M_X(t)\\) が存在しない場合もある。 また、\n\\[\nK_X(t) \\coloneqq \\log M_X(t)\n\\] を \\(X\\) のキュムラント母関数という。\n\n\n定義より、\\(M_X(0) = 1\\), \\(K_X(0)=0\\) である。\nまた、独立確率変数 \\(X,\\,Y\\) について \\[\\begin{align*}\nM_{X+Y}(t) &= \\expt{\\mathrm{e}^{t(X+Y)}} = \\expt{\\mathrm{e}^{tX}\\cdot\\mathrm{e}^{tY}}\n= \\expt{\\mathrm{e}^{tX}}\\cdot\\expt{\\mathrm{e}^{tY}} = M_X(t)M_Y(t)\n\\end{align*}\\] である。同様に \\(K_{X+Y}(t) = K_X(t) + K_Y(t)\\) である。"
  },
  {
    "objectID": "slides/04_moments.html#モーメントの母関数",
    "href": "slides/04_moments.html#モーメントの母関数",
    "title": "確率論",
    "section": "モーメントの母関数",
    "text": "モーメントの母関数\n\nTheorem 3 確率変数 \\(X\\) について、ある \\(\\epsilon &gt;0\\) が存在し、モーメント母関数 \\(M_X(t)\\) が \\(t\\in(-\\epsilon,\\epsilon)\\) で存在するとき、\n\\[\\begin{align*}\nM_X(t) &=\\sum_{n\\ge 0}\\frac{\\expt{X^n}}{n!}t^n\\qquad\\forall t\\in(-\\epsilon,\\epsilon)\\\\\n\\mu_n(X) &= \\left.\\frac{\\mathrm{d}^n M_X(t)}{\\mathrm{d} t^n}\\right|_{t=0}.\n\\end{align*}\\]\n\n\nProof. 前半の証明を与える。 離散型確率変数 \\(X\\) について、 \\[\\begin{align*}\nM_X(t) &= \\expt{\\mathrm{e}^{tX}}\n= \\sum_x \\mathrm{e}^{tx} f_X(x)\n= \\sum_x \\left(\\sum_{n\\ge0}\\frac{(tx)^n}{n!}\\right) f_X(x)\n\\end{align*}\\] である。 ここで、任意の \\(t\\in(-\\epsilon,\\epsilon)\\) について \\[\\begin{align*}\n\\sum_x \\sum_{n\\ge0}\\left|\\frac{(tx)^n}{n!} f_X(x)\\right|\n&= \\sum_x \\sum_{n\\ge0}\\frac{|tx|^n}{n!} f_X(x)\n= \\sum_x \\mathrm{e}^{|tx|} f_X(x)\n\\le \\sum_x (\\mathrm{e}^{tx}+\\mathrm{e}^{-tx}) f_X(x)\\\\\n&= \\expt{\\mathrm{e}^{tX}} + \\expt{\\mathrm{e}^{-tX}}\n= M_X(t) + M_X(-t) &lt; \\infty\n\\end{align*}\\] よって、この無限和は任意の \\(t\\in(-\\epsilon,\\epsilon)\\) について絶対収束する。 そのため、和の順序を変えても収束値は変化しない。 \\[\\begin{align*}\nM_X(t) &=\n\\sum_x \\left(\\sum_{n\\ge0}\\frac{(tx)^n}{n!}\\right) f_X(x)\n= \\sum_{n\\ge 0} \\sum_{x}\\frac{(tx)^n}{n!}f_X(x)\n= \\sum_{n\\ge 0} \\frac{\\sum_xx^n f_X(x)}{n!}t^n\n= \\sum_{n\\ge 0} \\frac{\\expt{X^n}}{n!}t^n\\qquad\\forall t\\in(-\\epsilon,\\epsilon).\n\\end{align*}\\]"
  },
  {
    "objectID": "slides/04_moments.html#キュムラント母関数",
    "href": "slides/04_moments.html#キュムラント母関数",
    "title": "確率論",
    "section": "キュムラント母関数",
    "text": "キュムラント母関数\n\nCorollary 1 確率変数 \\(X\\) について、ある \\(\\epsilon &gt;0\\) が存在し、モーメント母関数 \\(M_X(t)\\) が \\(t\\in(-\\epsilon,\\epsilon)\\) で存在するとき、\n\\[\\begin{align*}\n\\left.\\frac{\\mathrm{d} K_X(t)}{\\mathrm{d} t}\\right|_{t=0} &= \\expt{X},&\n\\left.\\frac{\\mathrm{d}^2 K_X(t)}{\\mathrm{d} t^2}\\right|_{t=0} &=  \\var{X}.\n\\end{align*}\\]\n\n\nProof. \\[\\begin{align*}\n\\left.\\frac{\\mathrm{d} K_X(t)}{\\mathrm{d} t}\\right|_{t=0} &= \\left.\\frac{M'_X(t)}{M_X(t)}\\right|_{t=0}=\\expt{X}\\\\\n\\left.\\frac{\\mathrm{d}^2 K_X(t)}{\\mathrm{d} t^2}\\right|_{t=0} &= \\left.\\frac{M''_X(t)M_X(t) - M'_X(t)^2}{M_X(t)^2}\\right|_{t=0} = M''_X(0) - M'_X(0)^2 = \\var{X}.\n\\end{align*}\\]\n\nまた、重要度は低くなるが、\n\\[\\begin{align*}\n\\left.\\frac{\\mathrm{d}^3 K_X(t)}{\\mathrm{d} t^3}\\right|_{t=0} &= \\expt{(X - \\expt{X})^3}\\\\\n\\left.\\frac{\\mathrm{d}^4 K_X(t)}{\\mathrm{d} t^4}\\right|_{t=0} &= \\expt{(X - \\expt{X})^4} - 3\\var{X}^2\n\\end{align*}\\]\nが成り立つ(覚えなくてよい)。 一般に以下を \\(X\\) の \\(n\\) 次キュムラント と呼ぶ。 \\[\\begin{align*}\n\\kappa_n(X) &\\coloneqq \\left.\\frac{\\mathrm{d}^n K_X(t)}{\\mathrm{d} t^n}\\right|_{t=0}.\n\\end{align*}\\]"
  },
  {
    "objectID": "slides/04_moments.html#モーメント母関数の一致",
    "href": "slides/04_moments.html#モーメント母関数の一致",
    "title": "確率論",
    "section": "モーメント母関数の一致",
    "text": "モーメント母関数の一致\n\nTheorem 4 確率変数 \\(X\\) と \\(Y\\) のモーメント母関数が0を含む開区間 \\((-\\epsilon,\\,\\epsilon)\\) で存在し、それらが等しいとき、\\(X\\) の分布と \\(Y\\) の分布は等しい。\n\n証明は確率変数の像が有限の場合に与える(ウェブ資料参照)。\n\nTheorem 4 より、モーメント母関数には確率変数の分布のすべての情報が含まれていると言える。 ただし、モーメント母関数は原点まわりで存在しないこともあるので、分布の情報をすべて含む関数としては特性関数 \\[\\begin{align*}\n\\varphi_X(t) &\\coloneqq \\expt{\\mathrm{e}^{itX}}\\qquad\\forall t\\in\\mathbb{R}\n\\end{align*}\\] の方が優秀である。 特性関数は常に存在する。 一方でモーメント母関数は確率の集中を示す文脈では中心的な役割を果たす。"
  },
  {
    "objectID": "slides/04_moments.html#今週の課題",
    "href": "slides/04_moments.html#今週の課題",
    "title": "確率論",
    "section": "今週の課題",
    "text": "今週の課題\n\\(\\lambda&gt;0\\) について \\(X\\sim\\mathrm{Poisson}(\\lambda)\\) とする。 以下の問に答えよ\n\n\n\\(X\\) のキュムラント母関数をもとめよ。\n\\(\\expt{X}\\) と \\(\\var{X}\\) をもとめよ。"
  },
  {
    "objectID": "slides/05_bayes.html#統計的推論推定",
    "href": "slides/05_bayes.html#統計的推論推定",
    "title": "確率論",
    "section": "統計的推論推定",
    "text": "統計的推論推定\n統計的推論とは現実の推定問題を確率論に基づきモデル化し、誤り確率を最小化するように推論する方法論である。 統計的推論には大きく分けて二種類の流派がある。\n\nベイズ主義: 推論する対象の分布(事前分布)を仮定する。\n頻度主義: 推論する対象の分布(事前分布)を仮定しない。\n\n例えば統計的推論は以下のような問題に適用されている。\n\n新薬の有効性\nウェブ広告のクリック率の推定\n工場で製造される製品の不良率の推定"
  },
  {
    "objectID": "slides/05_bayes.html#ベイズ推定",
    "href": "slides/05_bayes.html#ベイズ推定",
    "title": "確率論",
    "section": "ベイズ推定",
    "text": "ベイズ推定\n\n\\(\\mathcal{X}\\colon\\) データが取り得る値の集合\n\\(\\Theta\\colon\\) 分布のパラメータが取り得る値の集合\n\n簡単のため、\\(\\mathcal{X}\\) と \\(\\Theta\\) は高々可算集合とする。\nデータ \\(x\\in\\mathcal{X}\\) からパラメータ \\(\\theta\\in\\Theta\\) を推定する問題を考える。 このとき、\\(x\\) と \\(\\theta\\) が何かしらの確率分布に従っていると仮定する。 パラメータ \\(\\theta\\) に対する \\(x\\) の確率質量関数を \\(p(x\\mid \\theta)\\) と表す。 また、パラメータ \\(\\theta\\) の確率質量関数を \\(\\pi(\\theta)\\) と表す。 つまり、パラメータ \\(\\theta\\in\\Theta\\) とデータ \\(x\\in\\mathcal{X}\\) が選ばれる確率は \\[\\begin{align*}\n\\pi(\\theta) p(x\\mid\\theta)\n\\end{align*}\\] である。 また、 \\[\\begin{align*}\np(x) &= \\sum_{\\theta\\in\\Theta}\\pi(\\theta)p(x\\mid\\theta),&\np(\\theta\\mid x)&\\coloneqq \\frac{\\pi(\\theta)p(x\\mid\\theta)}{p(x)}\n\\end{align*}\\] と定義する。 ベイズ推定の文脈では\n\n\\(\\pi(\\theta)\\colon\\) 事前確率\n\\(p(x\\mid \\theta)\\colon\\) 尤度\n\\(p(\\theta\\mid x)\\colon\\) 事後確率\n\nと呼ぶ。"
  },
  {
    "objectID": "slides/05_bayes.html#最大事後確率推定",
    "href": "slides/05_bayes.html#最大事後確率推定",
    "title": "確率論",
    "section": "最大事後確率推定",
    "text": "最大事後確率推定\nこのとき、得られたデータ \\(x\\in\\mathcal{X}\\) からパラメータ \\(\\theta\\in\\Theta\\) を推定する関数 \\(\\widehat{\\theta}\\colon \\mathcal{X}\\to\\Theta\\) の誤り確率は \\[\\begin{align*}\nP_{\\mathrm{err}}(\\widehat{\\theta})\n&\\coloneqq \\sum_{\\theta\\in\\Theta} \\pi(\\theta) \\sum_{x\\in\\mathcal{X}} p(x\\mid\\theta) \\,\\mathbb{I}\\{\\widehat{\\theta}(x)\\ne\\theta\\}\\\\\n&= \\sum_{\\theta\\in\\Theta} \\pi(\\theta) \\sum_{x\\in\\mathcal{X}} p(x\\mid\\theta) (1-\\mathbb{I}\\{\\widehat{\\theta}(x)=\\theta\\})\\\\\n%&= 1- \\sum_{\\theta\\in\\Theta} \\pi(\\theta) \\sum_{x\\in\\mathcal{X}} p(x\\mid\\theta)\\, \\mathbb{I}\\{\\widehat{\\theta}(x)=\\theta\\}\\\\\n&= 1- \\sum_{x\\in\\mathcal{X}}\\sum_{\\theta\\in\\Theta} \\pi(\\theta)  p(x\\mid\\theta)\\, \\mathbb{I}\\{\\widehat{\\theta}(x)=\\theta\\}\\\\\n&= 1- \\sum_{x\\in\\mathcal{X}}\\pi\\left(\\widehat{\\theta}(x)\\right)  p\\left(x\\mid\\widehat{\\theta}(x)\\right)\\\\\n&\\ge 1- \\sum_{x\\in\\mathcal{X}} \\max_{\\theta\\in\\Theta} \\pi\\left(\\theta\\right)  p\\left(x\\mid\\theta\\right)\n\\end{align*}\\] と下から抑えることができ、 \\[\\begin{align*}\n\\widehat{\\theta}_{\\mathrm{MAP}}(x) &\\coloneqq\n  \\arg\\max_{\\theta\\in\\Theta}p\\left(\\theta\\mid x\\right)\\\\\n&= \\arg\\max_{\\theta\\in\\Theta}p\\left(\\theta\\mid x\\right)  p\\left(x\\right)\\\\\n&= \\arg\\max_{\\theta\\in\\Theta}\\pi\\left(\\theta\\right)  p\\left(x\\mid\\theta\\right)\\\\\n\\end{align*}\\] という推定関数により等号が達成される。 この推定関数を最大事後確率(maximum a posteriori; MAP)推定関数と呼ぶ。 事後確率の最大化の代わりに同時確率の最大化と理解してもよい。"
  },
  {
    "objectID": "slides/05_bayes.html#最尤推定",
    "href": "slides/05_bayes.html#最尤推定",
    "title": "確率論",
    "section": "最尤推定",
    "text": "最尤推定\nMAP推定は誤り確率を最小化する推定方法であるが、事前確率 \\(\\pi(\\theta)\\) を仮定しないと用いることができない。 一方で尤度を最大化する推定関数 \\[\\begin{align*}\n\\widehat{\\theta}_{\\mathrm{ML}}(x) &\\coloneqq\n  \\arg\\max_{\\theta\\in\\Theta}p\\left(x\\mid\\theta\\right)\n\\end{align*}\\] を最尤(maximam likelihood; ML)推定関数という。 \\(\\Theta\\) が有限集合で、事前確率が一様分布 \\(\\pi(\\theta)=\\frac1{|\\Theta|}\\) のとき、最尤推定は最大事後確率推定と一致する。"
  },
  {
    "objectID": "slides/05_bayes.html#二つの分布の識別",
    "href": "slides/05_bayes.html#二つの分布の識別",
    "title": "確率論",
    "section": "二つの分布の識別",
    "text": "二つの分布の識別\n特にパラメータが二値である場合を考える。ここでは \\(\\Theta=\\{0,1\\}\\) とする。 また、 \\[\\begin{align*}\np^{(0)}(x) &\\coloneqq p(x\\mid 0)&\np^{(1)}(x) &\\coloneqq p(x\\mid 1)\n\\end{align*}\\] とする。 このとき、 \\[\\begin{align*}\nP_{\\mathrm{err}}(\\widehat{\\theta}_\\mathrm{MAP})\n&= 1- \\sum_{x\\in\\mathcal{X}} \\max_{\\theta\\in\\{0,1\\}} \\pi\\left(\\theta\\right)  p\\left(x\\mid\\theta\\right)\\\\\n&= 1- \\sum_{x\\in\\mathcal{X}} \\max \\left\\{\\pi(0)  p^{(0)}\\left(x\\right),\\,\\pi(1)  p^{(1)}\\left(x\\right)\\right\\}\\\\\n\\end{align*}\\] である。 ここで、 \\[\\begin{align*}\n\\begin{split}\n\\max\\{a,b\\} - \\min\\{a,b\\} &= |\\,a-b\\,|\\\\\n\\max\\{a,b\\} + \\min\\{a,b\\} &= a+b\n\\end{split}\n\\qquad\\forall a,b\\in\\mathbb{R}\n\\end{align*}\\] であるので、 \\[\\begin{align*}\n\\max\\{a,b\\} &= \\frac12(a+b+|\\,a-b\\,|)\\qquad\\forall a,b\\in\\mathbb{R}.\n\\end{align*}\\] よって、 \\[\\begin{align*}\n%\\max_{\\theta\\in\\{0,1\\}} \\{\\pi\\left(\\theta\\right)  p\\left(x\\mid\\theta\\right)\\}\n\\max \\left\\{\\pi(0)  p^{(0)}\\left(x\\right),\\,\\pi(1)  p^{(1)}\\left(x\\right)\\right\\}\n&= \\frac12\\left(p(x) +\n\\left|\\,\\pi\\left(0\\right)  p^{(0)}\\left(x\\right) - \\pi\\left(1\\right)  p^{(1)}\\left(x\\right) \\,\\right|\\right).\n\\end{align*}\\]"
  },
  {
    "objectID": "slides/05_bayes.html#全変動距離",
    "href": "slides/05_bayes.html#全変動距離",
    "title": "確率論",
    "section": "全変動距離",
    "text": "全変動距離\n\\[\\begin{align*}\nP_{\\mathrm{err}}(\\widehat{\\theta}_\\mathrm{MAP})\n&= 1- \\sum_{x\\in\\mathcal{X}} \\max \\left\\{\\pi(0)  p^{(0)}\\left(x\\right),\\,\\pi(1)  p^{(1)}\\left(x\\right)\\right\\}\\\\\n&= 1- \\sum_{x\\in\\mathcal{X}} \\frac12\\left(p(x) +\n\\left|\\,\\pi\\left(0\\right)  p^{(0)}\\left(x\\right) - \\pi\\left(1\\right)  p^{(1)}\\left(x\\right) \\,\\right|\\right)\\\\\n&= 1-  \\frac12\\left(1 +\n\\sum_{x\\in\\mathcal{X}}\\left|\\,\\pi\\left(0\\right)  p^{(0)}\\left(x\\right) - \\pi\\left(1\\right)  p^{(1)}\\left(x\\right) \\,\\right|\\right)\\\\\n&= \\frac12\\left(1 -\n\\sum_{x\\in\\mathcal{X}}\\left|\\,\\pi\\left(0\\right)  p^{(0)}\\left(x\\right) - \\pi\\left(1\\right)  p^{(1)}\\left(x\\right) \\,\\right|\\right).\n\\end{align*}\\]\n\nDefinition 1 (全変動距離) 高々可算集合 \\(\\mathcal{X}\\) 上の関数 \\(f\\) について、 \\(\\|f\\|_1 \\coloneqq \\sum_{x\\in\\mathcal{X}} \\left|\\, f(x)\\,\\right|\\) と定義する。 また、\\(\\mathcal{X}\\) 上の確率質量関数 \\(p^{(0)}\\), \\(p^{(1)}\\) について、全変動距離を以下で定義する。 \\[\\begin{align*}\nd_{\\mathrm{TV}}(p^{(0)},\\, p^{(1)}) &\\coloneqq \\frac12\\left\\|\\, p^{(0)}-p^{(1)}\\,\\right\\|_1\n\\end{align*}\\]\n\nこれらの記法を用いると、 \\[\\begin{align*}\nP_{\\mathrm{err}}(\\widehat{\\theta}_\\mathrm{MAP})&=\\frac12\\left(1-\\left\\|\\pi(0)p^{(0)} - \\pi(1)p^{(1)}\\right\\|_1\\right)\n\\end{align*}\\] と表せる。また、\\(\\pi(0)=\\pi(1)=1/2\\) のとき、 \\[\\begin{align*}\nP_{\\mathrm{err}}(\\widehat{\\theta}_\\mathrm{MAP})&=\\frac12\\left(1-d_{\\mathrm{TV}}(p^{(0)},\\,p^{(1)})\\right).\n\\end{align*}\\]"
  },
  {
    "objectID": "slides/05_bayes.html#損失関数とベイズリスク",
    "href": "slides/05_bayes.html#損失関数とベイズリスク",
    "title": "確率論",
    "section": "損失関数とベイズリスク",
    "text": "損失関数とベイズリスク\nパラメータが取り得る値の集合が実数の部分集合 \\(\\Theta\\subseteq\\mathbb{R}\\) であると仮定する。 真のパラメータとその推定値の間の「誤差」を表す関数 \\(L\\colon\\Theta\\times\\mathbb{R}\\to\\mathbb{R}_{\\ge 0}\\) を損失関数と呼ぶ。 また、期待損失 \\(R\\colon\\Theta\\times(\\mathcal{X}\\to\\mathbb{R})\\to\\mathbb{R}_{\\ge 0}\\) を \\[\\begin{align*}\nR(\\theta,\\,\\widehat{\\theta}) &\\coloneqq \\expt{L(\\theta,\\,\\widehat{\\theta}(X))\\mid\\theta}\\\\\n&=\\sum_{x\\in\\mathcal{X}} L(\\theta,\\,\\widehat{\\theta}(x)) p(x\\mid\\theta)\n\\end{align*}\\] と定義する。 また、ベイズリスク \\(\\rho\\colon \\mathcal{P}(\\Theta)\\times(\\mathcal{X}\\to\\mathbb{R})\\to\\mathbb{R}_{\\ge 0}\\) を \\[\\begin{align*}\n\\rho(\\pi, \\widehat{\\theta})&\\coloneqq  \\expt{L(\\theta,\\,\\widehat{\\theta}(X))}\\\\\n&=\\sum_{\\theta\\in\\Theta}\\sum_{x\\in\\mathcal{X}} L(\\theta,\\,\\widehat{\\theta}(x)) p(x\\mid\\theta)\\pi(\\theta)\n\\end{align*}\\] と定義する。 \\(\\Theta\\subseteq\\mathbb{R}\\) が非可算無限集合の場合は \\(\\pi(\\theta)\\) を確率密度関数とし、 \\[\\begin{align*}\n\\rho(\\pi, \\widehat{\\theta})&\\coloneqq  \\expt{L(\\theta,\\,\\widehat{\\theta}(X))}\\\\\n&=\\int\\sum_{x\\in\\mathcal{X}} L(\\theta,\\,\\widehat{\\theta}(x)) p(x\\mid\\theta)\\pi(\\theta)\\mathrm{d}\\theta\n\\end{align*}\\] と定義する。 このとき、 \\(p(x\\mid\\theta)\\) は条件付き確率というより、\\(\\theta\\in\\Theta\\) というパラメータを持った確率質量関数(\\(\\theta\\in\\Theta\\) から定まる確率質量関数)と理解すれば十分である。"
  },
  {
    "objectID": "slides/05_bayes.html#損失関数の例",
    "href": "slides/05_bayes.html#損失関数の例",
    "title": "確率論",
    "section": "損失関数の例",
    "text": "損失関数の例\n例えば \\(\\Theta\\) が高々可算集合で、 \\[\\begin{align*}\nL(\\theta,\\,\\theta') &= \\mathbb{I}\\{\\theta\\ne \\theta'\\}\\qquad\\forall\\theta,\\theta'\\in\\Theta\n\\end{align*}\\] と定義すると、ベイズリスク \\(\\rho(\\pi, \\widehat{\\theta})\\) は推定関数 \\(\\widehat{\\theta}\\) の誤り確率 \\(P_\\mathrm{err}(\\widehat{\\theta})\\) である。\nその他の重要な損失関数の例として二乗誤差がある。 \\[\\begin{align*}\nL(\\theta,\\,\\theta') &= (\\theta-\\theta')^2.\n\\end{align*}\\]"
  },
  {
    "objectID": "slides/05_bayes.html#ベイズリスクの最小化",
    "href": "slides/05_bayes.html#ベイズリスクの最小化",
    "title": "確率論",
    "section": "ベイズリスクの最小化",
    "text": "ベイズリスクの最小化\n損失関数 \\(L\\) を定めたときに、ベイズリスクを最小化する推定関数 \\[\\begin{align*}\n\\widehat{\\theta} &= \\arg\\min_{\\widehat{\\theta}} \\rho(\\pi, \\widehat{\\theta})\\\\\n\\iff \\widehat{\\theta}(x) &= \\arg\\min_{\\theta'\\in\\Theta} \\sum_{\\theta\\in\\Theta} L(\\theta,\\,\\theta') p(x\\mid\\theta)\\pi(\\theta)\\qquad\\forall x\\in\\mathcal{X}\\\\\n\\iff \\widehat{\\theta}(x) &= \\arg\\min_{\\theta'\\in\\Theta} \\sum_{\\theta\\in\\Theta} L(\\theta,\\,\\theta') p(\\theta\\mid x)p(x)\\qquad\\forall x\\in\\mathcal{X}\\\\\n\\iff \\widehat{\\theta}(x) &= \\arg\\min_{\\theta'\\in\\Theta} \\sum_{\\theta\\in\\Theta} L(\\theta,\\,\\theta') p(\\theta\\mid x)\\qquad\\forall x\\in\\mathcal{X}\\\\\n\\end{align*}\\] ここで、 \\[\\begin{align*}\n\\expt{L(\\theta,\\,\\theta')\\mid x}&=  \\sum_{\\theta\\in\\Theta} L(\\theta,\\,\\theta') p(\\theta\\mid x)\\qquad\\forall x\\in\\mathcal{X}\n\\end{align*}\\] を損失関数の事後平均という。 各 \\(x\\in\\mathcal{X}\\) について、\\(\\theta'=\\widehat{\\theta}(x)\\) が損失関数の事後平均を最小化するとき、ベイズリスクを最小化する。"
  },
  {
    "objectID": "slides/05_bayes.html#損失関数が凸で微分可能な場合",
    "href": "slides/05_bayes.html#損失関数が凸で微分可能な場合",
    "title": "確率論",
    "section": "損失関数が凸で微分可能な場合",
    "text": "損失関数が凸で微分可能な場合\n損失関数が \\(L(\\theta,\\,\\theta')\\) が \\(\\theta\\in\\Theta\\) を固定したときに \\(\\theta'\\) について凸関数であるとき、事後平均 \\(\\expt{L(\\theta,\\,\\theta')\\mid x}\\) も \\(\\theta'\\) について凸関数となる(凸関数の非負倍は凸関数であり、凸関数の和は凸関数なので)。 さらに、\\(L(\\theta,\\,\\theta')\\) が \\(\\theta'\\) について微分可能なとき、 \\[\\begin{align*}\n\\frac{\\partial \\expt{L(\\theta,\\,\\theta')\\mid x}}{\\partial\\, \\theta'}&=  \\sum_{\\theta\\in\\Theta} \\frac{\\partial L(\\theta,\\,\\theta')}{\\partial\\, \\theta'} p(\\theta\\mid x)=0\\qquad\\forall x\\in\\mathcal{X}\n\\end{align*}\\] を満たす \\(\\theta'\\) を \\(\\widehat{\\theta}(x)\\) として選択するのが最適である。 二乗誤差 \\(L(\\theta,\\,\\theta')=(\\theta-\\theta')^2\\) のとき、この条件は \\[\\begin{align*}\n0&=\\sum_{\\theta} 2(\\theta'-\\theta) p(\\theta\\mid x)\n=2\\left(\\theta' - \\sum_{\\theta}\\theta p(\\theta\\mid x)\\right)\n\\end{align*}\\] となり、 \\[\\begin{align*}\n\\widehat{\\theta}(x) &= \\sum_\\theta \\theta p(\\theta\\mid x)\\qquad \\forall x\\in\\mathcal{X}\n\\end{align*}\\] とするのが最適であることが分かる。この右辺の値をパラメータ \\(\\theta\\) の事後平均という。"
  },
  {
    "objectID": "slides/05_bayes.html#今週の課題",
    "href": "slides/05_bayes.html#今週の課題",
    "title": "確率論",
    "section": "今週の課題",
    "text": "今週の課題\n\\(\\Theta=\\{0,1\\}\\), \\(\\mathcal{X}=\\{0,1\\}\\) とする。 事前確率と尤度を \\[\\begin{align*}\n\\pi(0) &= 1/3&\\pi(1)=2/3\\\\\np(x=0\\mid \\theta=0) &= 1/3&\np(x=1\\mid \\theta=0) &= 2/3\\\\\np(x=0\\mid \\theta=1) &= 1/4&\np(x=1\\mid \\theta=1) &= 3/4\n\\end{align*}\\] とする。\nこのとき、以下の問に答えよ\n\n\nMAP推定関数 \\(\\widehat{\\theta}_{\\mathrm{MAP}}(x)\\) と最尤推定関数 \\(\\widehat{\\theta}_{\\mathrm{ML}}(x)\\) をもとめよ。\n損失関数を \\[\\begin{align*}\nL(0,0) &= L(1,1) = 0,& L(0,1) &= 1,& L(1,0) &= 3\n\\end{align*}\\] としたときにベイズリスクを最小化する推定量 \\(\\widehat{\\theta}(x)\\) をもとめよ。"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Home",
    "section": "",
    "text": "確率・統計基礎の授業ページです。"
  },
  {
    "objectID": "slides.html",
    "href": "slides.html",
    "title": "Slides",
    "section": "",
    "text": "講義スライド\n\n集合論と確率空間\n確率変数\n複数の確率変数\n期待値、分散、モーメント\nベイズ推定\n仮説検定\n大数の法則"
  },
  {
    "objectID": "slides/07_large_numbers.html#大数の弱法則",
    "href": "slides/07_large_numbers.html#大数の弱法則",
    "title": "確率論",
    "section": "大数の弱法則",
    "text": "大数の弱法則\n表が出る確率が \\(1/2\\) のコインを100回独立に投げたときに表が出る回数は大体50回くらいになるだろう。 それを一般的な形で述べたものが大数の法則である。\n\nTheorem 1 (大数の弱法則(分散有限を仮定)) 確率変数 \\(X\\) が分散を持つとする。 確率変数 \\(X_1,\\dotsc,X_N\\) が独立同分布で \\(X\\) と同じ分布に従うとする。 このとき、 \\[\\begin{align*}\n\\lim_{N\\to\\infty}\\Pr\\left(\\left|\\frac1N\\sum_{i=1}^N X_i-\\expt{X}\\right|\\ge\\epsilon\\right) &= 0\n\\end{align*}\\] が成り立つ。\n\n\nProof. \\[\\begin{align*}\n\\Pr\\left(\\left|\\frac1n\\sum_{i=1}^N X_i-\\expt{X}\\right|\\ge\\epsilon\\right)\n&=  \\Pr\\left(\\left(\\frac1N\\sum_{i=1}^N X_i-\\expt{X}\\right)^2\\ge\\epsilon^2\\right) \\\\\n&=  \\Pr\\left(\\left(\\sum_{i=1}^N X_i-N\\expt{X}\\right)^2\\ge\\epsilon^2N^2\\right) \\\\\n&\\le \\frac{N\\var{X}}{\\epsilon^2N^2}\n= \\frac{\\var{X}}{\\epsilon^2N}\\longrightarrow 0.\n\\end{align*}\\]"
  },
  {
    "objectID": "slides/07_large_numbers.html#チェルノフ上界",
    "href": "slides/07_large_numbers.html#チェルノフ上界",
    "title": "確率論",
    "section": "チェルノフ上界",
    "text": "チェルノフ上界\n上記の大数の弱法則の証明では確率が0に収束するスピートは \\(O(1/N)\\) であった。 より詳しく確率が0にいくスピードを解析しよう。\n\nLemma 1 (チェルノフ上界) 任意の確率変数 \\(X\\) と \\(a\\in\\mathbb{R}\\) について、 \\[\\begin{align*}\n\\Pr\\left(X\\ge a\\right) &\\le \\frac{M_X(t)}{\\mathrm{e}^{at}}=\\mathrm{e}^{K_X(t)-at}\\qquad\\forall t\\ge 0\\\\\n\\Pr\\left(X\\le a\\right) &\\le \\frac{M_X(t)}{\\mathrm{e}^{at}}=\\mathrm{e}^{K_X(t)-at}\\qquad\\forall t\\le 0.\n\\end{align*}\\]\n\n\nProof. \\(t=0\\) のときは不等式の右辺は1となるので、不等式は自明に成り立つ。 任意の \\(t&gt;0\\) について、 \\[\\begin{align*}\n\\Pr\\left(X\\ge a\\right) &= \\Pr\\left(\\mathrm{e}^{tX}\\ge \\mathrm{e}^{ta}\\right)\\\\\n&\\le \\frac{M_X(t)}{\\mathrm{e}^{at}}\\qquad(\\text{マルコフの不等式}).\n\\end{align*}\\] が成り立つ。 もう一つの不等式も同様に示すことができる。\n\nマルコフの不等式は非負の確率変数にしか適用できないが、チェルノフ上界は任意の確率変数に適用できる。"
  },
  {
    "objectID": "slides/07_large_numbers.html#確率変数の和に対するチェルノフ上界",
    "href": "slides/07_large_numbers.html#確率変数の和に対するチェルノフ上界",
    "title": "確率論",
    "section": "確率変数の和に対するチェルノフ上界",
    "text": "確率変数の和に対するチェルノフ上界\n\nLemma 2 (確率変数の和に対するチェルノフ上界) 任意の確率変数 \\(X\\) と \\(a\\in\\mathbb{R}\\) について、 \\[\\begin{align*}\n\\Pr\\left(\\frac1N\\sum_{i=1}^N X_i\\ge a\\right) &\\le \\mathrm{e}^{-(at-K_X(t))N}\\qquad\\forall t\\ge 0\\\\\n\\Pr\\left(\\frac1N\\sum_{i=1}^N X_i\\le a\\right) &\\le \\mathrm{e}^{-(at-K_X(t))N}\\qquad\\forall t\\le 0.\n\\end{align*}\\]\n\n\nProof. \\[\\begin{align*}\n\\Pr\\left(\\frac1N\\sum_{i=1}^N X_i\\ge a\\right) &= \\Pr\\left(\\sum_{i=1}^N X_i\\ge aN\\right)\\\\\n&\\le \\mathrm{e}^{K_{\\sum_i X_i}(t) - atN}\\\\\n&= \\mathrm{e}^{(K_X(t) - at)N}\\\\\n\\end{align*}\\]\n\nこのようにチェルノフ上界を使うと \\(N\\) について指数関数の上界が得られる。 係数 \\(at-K_X(t)\\) が正であれば、確率は指数関数的に小さいことになる。 ここで、最適な \\(t\\) を選ぶことで、この係数 \\(at-K_X(t)\\) を最大化することを考える。"
  },
  {
    "objectID": "slides/07_large_numbers.html#キュムラント母関数の定義域",
    "href": "slides/07_large_numbers.html#キュムラント母関数の定義域",
    "title": "確率論",
    "section": "キュムラント母関数の定義域",
    "text": "キュムラント母関数の定義域\nキュムラント母関数 \\[\\begin{align*}\nK_X(t) &= \\log\\expt{\\mathrm{e}^{tX}}\n\\end{align*}\\] の性質を改めて考えよう。\nまず、\\(K_X(0)=0\\) である。\nある \\(t&gt;0\\) について、 \\(M_X(t)\\) が存在すると仮定すると、任意の \\(x\\in(0,t)\\) について \\[\\begin{align*}\nM_X(s) &= \\expt{\\mathrm{e}^{sX}}\\\\\n&= \\expt{\\mathrm{e}^{sX} \\mathbb{1}_{\\{X\\ge 0\\}}}\n+ \\expt{\\mathrm{e}^{sX} \\mathbb{1}_{\\{X&lt; 0\\}}}\\\\\n&\\le \\expt{\\mathrm{e}^{tX} \\mathbb{1}_{\\{X\\ge 0\\}}} + 1\\\\\n&\\le M_X(t) + 1 &lt; \\infty\n\\end{align*}\\] なので、\\(M_X(s)\\) も存在する。 同様に、ある \\(t&lt;0\\) について、 \\(M_X(t)\\) が存在すると仮定すると、任意の \\(x\\in(t,0)\\) について \\(M_X(s)\\) も存在する。 よって、\\(M_X(t)\\) や \\(K_X(t)\\) が存在する範囲は0を含む区間となる。 ここでいう区間とは一般的に空集合、もしくは \\(a&lt; b\\) について、 \\[\\begin{align*}\n[a,\\,a]\\quad\n(a,\\,b)\\quad\n[a,\\,b)\\quad\n(a,\\,b]\\quad\n[a,\\,b]\\quad\n(a,\\,\\infty)\\quad\n[a,\\,\\infty)\\quad\n(-\\infty,\\, b)\\quad\n(-\\infty,\\, b]\\quad\n(-\\infty,\\,\\infty)\n\\end{align*}\\] のいずれかの形の集合を指す。 この区間を \\(\\mathrm{dom}(K_X)\\) と表す。"
  },
  {
    "objectID": "slides/07_large_numbers.html#キュムラント母関数の微分",
    "href": "slides/07_large_numbers.html#キュムラント母関数の微分",
    "title": "確率論",
    "section": "キュムラント母関数の微分",
    "text": "キュムラント母関数の微分\n証明はしないが、キュムラント母関数 \\(K_X(t)\\) は \\(\\mathrm{dom}(K_X)\\) の内点で微分可能であり、無限和や積分を取る前に微分しても構わない。\n\\[\\begin{align*}\n\\frac{\\mathrm{d} K_X(t)}{\\mathrm{d}t} &= \\frac{\\expt{X\\mathrm{e}^{tX}}}{\\expt{\\mathrm{e}^{tX}}}\\\\\n\\frac{\\mathrm{d}^2 K_X(t)}{\\mathrm{d}t^2} &= \\frac{\\expt{X^2\\mathrm{e}^{tX}}\\expt{\\mathrm{e}^{tX}}-\\expt{X\\mathrm{e}^{tX}}^2}{\\expt{\\mathrm{e}^{tX}}^2}\\\\\n&= \\frac{\\expt{X^2\\mathrm{e}^{tX}}}{\\expt{\\mathrm{e}^{tX}}}-\\left(\\frac{\\expt{X\\mathrm{e}^{tX}}}{\\expt{\\mathrm{e}^{tX}}}\\right)^2\\\\\n&= \\frac{\\expt{\\left(X-\\frac{\\expt{X\\mathrm{e}^{tX}}}{\\expt{\\mathrm{e}^{tX}}}\\right)^2\\mathrm{e}^{tX}}}{\\expt{\\mathrm{e}^{tX}}}\\ge 0\n\\end{align*}\\]  また、\\(X\\)が決定的(\\(\\Pr(X=\\expt{X})=1\\))でない限り、\\(K_X\\) は \\(\\mathrm{dom}(K_X)\\) で狭義凸である。"
  },
  {
    "objectID": "slides/07_large_numbers.html#キュムラント母関数の性質",
    "href": "slides/07_large_numbers.html#キュムラント母関数の性質",
    "title": "確率論",
    "section": "キュムラント母関数の性質",
    "text": "キュムラント母関数の性質\nよって \\(X\\) のキュムラント母関数 \\(K_X(t)\\) が原点付近で存在すると仮定すると、\\(K_X(t)\\) は\n\n0を含む区間で定義され、\n原点を通り、\n凸関数で、\n原点の傾きは \\(\\expt{X}\\)\n\nであることが分かる。\nまた、キュムラント母関数の簡単な性質として以下が成り立つ。 任意の独立確率変数 \\(X\\) と \\(Y\\) と \\(a\\in\\mathbb{R}\\) について \\[\\begin{align*}\nK_{X+a}(t) &= \\log\\expt{\\mathrm{e}^{t(X+a)}} = \\log\\left(\\expt{\\mathrm{e}^{tX}}\\cdot \\mathrm{e}^{ta}\\right) = K_X(t) + at\\\\%\\quad\\text{for } t\\in\\mathrm{dom}(K_X)\\\\\nK_{aX}(t) &= \\log\\expt{\\mathrm{e}^{t(aX)}} = K_X(at)\\\\%\\qquad\\text{if } at\\in\\mathrm{dom}(K_X)\\\\\nK_{X+Y}(t) &= \\log\\expt{\\mathrm{e}^{t(X+Y)}} =\\log\\left(\\expt{\\mathrm{e}^{tX}}\\expt{\\mathrm{e}^{tY}}\\right) = K_X(t) + K_Y(t).\n%&\\hspace{17em}\\text{for } t\\in\\mathrm{dom}(K_X)\\cap\\mathrm{dom}(K_Y)\n\\end{align*}\\]"
  },
  {
    "objectID": "slides/07_large_numbers.html#ルジャンドル変換",
    "href": "slides/07_large_numbers.html#ルジャンドル変換",
    "title": "確率論",
    "section": "ルジャンドル変換",
    "text": "ルジャンドル変換\nチェルノフ上界に現れる係数 \\(at-K_X(t)\\) の最大化はルジャンドル変換を用いて \\(K_X^*(a)\\) と表せる。 ルジャンドル変換を定義する際は \\(+\\infty\\) という値を許して \\((-\\infty,\\,+\\infty]\\) を値域として考えると都合がよい。 このように \\(+\\infty\\) を値として許した場合にも凸性を通常の関数と同じように定義する。 一般に区間上で定義された凸関数を実数全体に拡張し、元の定義域の外で \\(+\\infty\\) を取ることにするとやはり凸関数になる。 また、\\(f\\colon\\mathbb{R}\\to(-\\infty,\\,+\\infty]\\) の有効領域を \\[\\begin{align*}\n\\mathrm{dom}(f) &\\coloneqq\\left\\{x\\in\\mathbb{R}\\mid f(x)&lt;+\\infty\\right\\}\n\\end{align*}\\] と定義する。 凸関数の有効領域は区間になる。\n\nDefinition 1 (ルジャンドル変換)  \n\n凸関数 \\(f\\colon \\mathbb{R}\\to (-\\infty,\\,+\\infty]\\) のルジャンドル変換 \\(f^*\\colon \\mathbb{R}\\to (-\\infty,\\,+\\infty]\\) を以下で定義する。 \\[\\begin{align*}\nf^*(a) &\\coloneqq \\sup_{t\\in \\mathbb{R}}\\left\\{at-f(t)\\right\\}.\n\\end{align*}\\]"
  },
  {
    "objectID": "slides/07_large_numbers.html#ルジャンドル変換の理解",
    "href": "slides/07_large_numbers.html#ルジャンドル変換の理解",
    "title": "確率論",
    "section": "ルジャンドル変換の理解",
    "text": "ルジャンドル変換の理解\nルジャンドル変換において \\(f\\) は凸関数なので、\\(at-f(t)\\) は凹関数(上に凸の関数)になる。 簡単のため \\(f\\) が \\(\\mathrm{dom}(f)\\) の内点で微分可能であると仮定しよう。 このとき、\n\n\\(at-f(t)\\) の微分が 0 になる点、つまり \\(f'(t_a) = a\\) を満たす \\(t_a\\in \\mathrm{dom}(f)^\\circ\\) が存在するとき、\\(t_a\\) で \\(at-f(t)\\) は最大化される。\nそのような \\(t_a\\in \\mathrm{dom}(f)^\\circ\\) が存在しないときは、\\(\\mathrm{dom}(f)\\) の端への極限で \\(\\sup\\) が達成される。\n\n凸関数は \\(\\mathrm{dom}(f)\\) の上では接線の集合で表すことができる。 接線 \\(ax+b\\) は傾き \\(a\\) と切片 \\(b\\) のペアで表すことができる。 傾き \\(a\\) を持つ \\(f\\) の接線は \\[\\begin{align*}\na(x-t_a) + f(t_a) &= ax - (at_a - f(t_a)) = ax - f^*(a)\n\\end{align*}\\] この傾き \\(a\\) から接線の切片の \\(-1\\)倍である \\(-b\\) への関数が \\(f^*\\) である。 よって \\(f\\) が微分可能であるとき \\[\\begin{align*}\nf^*(f'(t)) &= -f(t)\n\\end{align*}\\] である。"
  },
  {
    "objectID": "slides/07_large_numbers.html#ルジャンドル変換の理解-1",
    "href": "slides/07_large_numbers.html#ルジャンドル変換の理解-1",
    "title": "確率論",
    "section": "ルジャンドル変換の理解",
    "text": "ルジャンドル変換の理解\nまた、ルジャンドル変換 \\(f^*\\) は凸関数である。\n\nLemma 3 凸関数 \\(f\\colon \\mathbb{R}\\to (-\\infty,\\,+\\infty]\\) のルジャンドル変換 \\(f^*\\colon \\mathbb{R}\\to (-\\infty,\\,+\\infty]\\) は凸関数である。\n\n\nProof. 任意の \\(a_1,a_2\\in \\mathbb{R}\\) と \\(\\lambda\\in[0,1]\\) について \\[\\begin{align*}\nf^*(\\lambda a_1+ (1-\\lambda)a_2) &= \\sup_{t\\in \\mathbb{R}}\\left\\{(\\lambda a_1+(1-\\lambda)a_2)t - f(t)\\right\\}\\\\\n&= \\sup_{t\\in \\mathbb{R}}\\left\\{\\lambda (a_1t - f(t))+(1-\\lambda)(a_2t - f(t))\\right\\}\\\\\n&\\le \\sup_{t\\in \\mathbb{R}}\\left\\{\\lambda (a_1t - f(t))\\right\\}+\\sup_{t\\in \\mathbb{R}}\\left\\{(1-\\lambda)(a_2t - f(t))\\right\\}\\\\\n&\\le \\lambda f^*(a_1) + (1-\\lambda) f^*(a_2).\n\\end{align*}\\]\n\nルジャンドル変換を凸でない関数 \\(f\\) についても同様に定義した場合でも、ルジャンドル変換 \\(f^*\\) は同様に凸関数となる。"
  },
  {
    "objectID": "slides/07_large_numbers.html#今週の課題",
    "href": "slides/07_large_numbers.html#今週の課題",
    "title": "確率論",
    "section": "今週の課題",
    "text": "今週の課題\n以下の凸関数をルジャンドル変換せよ\n\n\\(f(t) = t^2 + bt + c\\).\n\\(f(t) = \\mathrm{e}^t\\)."
  },
  {
    "objectID": "slides/01_probability.html#確率論とは",
    "href": "slides/01_probability.html#確率論とは",
    "title": "確率論",
    "section": "確率論とは",
    "text": "確率論とは\n\n\n世の中のランダムな事象を数学的に記述したもの。\n統計・機械学習の基礎となっている。\n確率論はコルモゴロフが1933年に導入した測度論的確率論によって定式化するのが一般的。"
  },
  {
    "objectID": "slides/01_probability.html#統計学とは",
    "href": "slides/01_probability.html#統計学とは",
    "title": "確率論",
    "section": "統計学とは",
    "text": "統計学とは\n統計学はデータから未来を予測したり意思決定をするための方法論。\n\nこの薬は効果がありますか？\nこのユーザーにどの製品が売れますか？\nこの時間の道路の混雑具合は？\n\n確率論は統計学の基礎となる。"
  },
  {
    "objectID": "slides/01_probability.html#確率論の数学モデルとは",
    "href": "slides/01_probability.html#確率論の数学モデルとは",
    "title": "確率論",
    "section": "確率論の数学モデルとは？",
    "text": "確率論の数学モデルとは？\n\n測度論！\n\n\n\n確率は面積(\\(=\\)測度)のようなもの。\n数学的にに様々な結果(大数の法則、大偏差原理、中心極限定理)が証明できる。\nとても重要だが勉強するのは3年生以降(解析学要論Ⅱ、確率論)。\nこの授業では測度論には深入りせず、数学的に厳密な議論なごまかしながら確率・統計について学ぶ。"
  },
  {
    "objectID": "slides/01_probability.html#この授業の進め方",
    "href": "slides/01_probability.html#この授業の進め方",
    "title": "確率論",
    "section": "この授業の進め方",
    "text": "この授業の進め方\n\n\n講義資料は https://prob-stat.github.io/ にすべてある。ここだけ見ればOK。\nその他の連絡事項はTACTを通じて行う。\n毎回課題を出す。提出はTACTを用いる。\n成績は課題50% 期末試験50%.\n課題の内容と授業資料は上記のページにあるので、授業は出席しなくても構わない。"
  },
  {
    "objectID": "slides/01_probability.html#集合",
    "href": "slides/01_probability.html#集合",
    "title": "確率論",
    "section": "集合",
    "text": "集合\n集合 \\(=\\) 「ものの集まり」\n\\[\\begin{align*}\nA &= \\{1,2,3\\}&\nB &= \\{赤、青、黄、緑\\}\n\\end{align*}\\]\n集合を構成するものを要素もしくは元という。\n\n\\(x\\in A\\): 要素 \\(x\\) は集合 \\(A\\) に含まれる。\n\\(x\\notin A\\): 要素 \\(x\\) は集合 \\(A\\) に含まない。\n\\(|A|\\): 集合 \\(A\\) の要素数\n\n要素数が無限の集合を考えることもできる。 例えば\n\\[\\begin{align*}\nA&=\\{n\\in\\mathbb{N}\\mid \\textsf{$n$ は偶数}\\},& B&=\\{x\\in\\mathbb{R}\\mid \\textsf{$x$ は無理数} \\}\n\\end{align*}\\]\nという集合は無限集合の例となる。\n\n\\(\\varnothing\\): 空集合 \\(\\coloneqq\\) 要素数が 0 の集合 。"
  },
  {
    "objectID": "slides/01_probability.html#集合の関係",
    "href": "slides/01_probability.html#集合の関係",
    "title": "確率論",
    "section": "集合の関係",
    "text": "集合の関係\n集合 \\(A\\) の要素がすべて集合 \\(B\\) に含まれるとき、\\(A\\) を \\(B\\) の部分集合 という。\n\\[\\begin{align*}\nA\\subseteq B &\\defiff \\forall x\\,(x\\in A\\implies x \\in B)&\\textsf{($A$ は $B$ の部分集合)}\\\\\nA\\supseteq B &\\defiff B\\subseteq A&\\textsf{($A$ は $B$ の上位集合)}\\\\\nA = B &\\defiff (A\\subseteq B\\land A\\supseteq B)& \\textsf{($A$ と $B$ は等しい)}\\\\\nA \\ne B &\\defiff \\lnot(A = B)& \\textsf{($A$ と $B$ は等しくない)}\n\\end{align*}\\]\nまた、\n\\[\\begin{align*}\nA\\subsetneq B &\\defiff (A\\subseteq B \\land A\\ne B)&\\textsf{($A$ は $B$ の真部分集合)}\\\\\nA\\supsetneq B &\\defiff B\\subsetneq A&\\textsf{($A$ は $B$ の真上位集合)}\n\\end{align*}\\]\nとする。 部分集合や上位集合のような集合間の関係を包含関係という。 集合 \\(A,\\,B\\) について、\\(A\\subseteq B\\) と \\(B\\subseteq A\\) のどちらかが成り立つとき、「\\(A\\) と \\(B\\) の間に包含関係が成り立 つ」という。\n包含関係は以下の三条件を満たす(半順序の公理)。\n\n(反射律) \\(\\quad A\\subseteq A\\).\n(反対称律) \\(\\quad (A\\subseteq B\\land B\\subseteq A) \\iff A = B\\).\n(推移律) \\(\\quad (A\\subseteq B\\land B\\subseteq C)\\implies A\\subseteq C\\)."
  },
  {
    "objectID": "slides/01_probability.html#集合の演算",
    "href": "slides/01_probability.html#集合の演算",
    "title": "確率論",
    "section": "集合の演算",
    "text": "集合の演算\n複数の集合から新しい集合を作る演算がある。\n\\[\\begin{align*}\nA\\cup B &\\coloneqq\\left\\{x\\mid x\\in A \\textsf{ または } x \\in B\\right\\}\\qquad\\textsf{(和集合)}\\\\\nA\\cap B &\\coloneqq \\left\\{x\\mid x\\in A \\textsf{ かつ } x \\in B\\right\\}\\qquad\\textsf{(積集合)}\\\\\nA\\setminus B &\\coloneqq \\left\\{x\\mid x\\in A \\textsf{ かつ } x \\notin B\\right\\}\\qquad\\textsf{(差集合)}\n\\end{align*}\\]\nこれらの演算は以下の法則を満たす。\n\n(交換法則) \\(\\quad A\\cup B = B\\cup A, \\quad A\\cap B = B\\cap A\\).\n(結合法則) \\(\\quad (A\\cup B)\\cup C = A\\cup (B\\cup C), \\quad (A\\cap B)\\cap C=A\\cap(B\\cap C)\\).\n(分配法則) \\(\\quad A\\cup(B\\cap C) = (A\\cup B)\\cap (A\\cup C),\\quad A\\cap (B\\cup C) = (A\\cap B)\\cup (A\\cap C)\\).\n(冪等法則) \\(\\quad A \\cup A = A, \\quad A\\cap A = A\\).\n(吸収法則) \\(\\quad A \\cup (A\\cap B) = A, \\quad A\\cap (A\\cup B) = A\\).\n\\(A\\cup \\varnothing = A,\\quad A\\cap\\varnothing = \\varnothing\\).\n\n和集合と積集合は結合法則満たすことから、括弧を使わずに \\(A\\cup B\\cup C\\) と表すことができる。\n集合 \\(A\\) と \\(B\\) が \\(A\\cap B=\\varnothing\\) を満たすとき、確率論文脈では、「\\(A\\) と \\(B\\) は排反である」(集合論文脈では「互いに素である」)という。"
  },
  {
    "objectID": "slides/01_probability.html#補集合",
    "href": "slides/01_probability.html#補集合",
    "title": "確率論",
    "section": "補集合",
    "text": "補集合\nまた、全体の集合 \\(\\Omega\\) というのが文脈上存在する場合は、\n\\[\\begin{align*}\nA^\\mathrm{c} &\\coloneqq \\Omega\\setminus A\\qquad\\textsf{(補集合)}\n\\end{align*}\\]\nと定義する。\n補集合に関連して以下の法則を満たす。\n\n\\(\\Omega^\\mathrm{c} = \\varnothing,\\quad \\varnothing^\\mathrm{c} = \\Omega\\).\n\\(A\\cup \\Omega = \\Omega,\\quad A\\cap\\Omega = A\\).\n\\(A\\cup A^\\mathrm{c} = \\Omega,\\quad A\\cap A^\\mathrm{c} =\\varnothing\\).\n(二重補集合の法則) \\(\\quad (A^\\mathrm{c})^\\mathrm{c} = A\\).\n(ド・モルガンの法則) \\(\\quad(A\\cup B)^\\mathrm{c} = A^\\mathrm{c} \\cap B^\\mathrm{c},\\quad(A\\cap B)^\\mathrm{c} = A^\\mathrm{c} \\cup B^\\mathrm{c}\\)"
  },
  {
    "objectID": "slides/01_probability.html#集合族",
    "href": "slides/01_probability.html#集合族",
    "title": "確率論",
    "section": "集合族",
    "text": "集合族\n集合 \\(\\Omega\\) について \\(2^\\Omega\\) を \\(\\Omega\\) のすべての部分集合からなる集合を表す。\n\\[\\begin{align*}\n2^\\Omega &\\coloneqq \\left\\{A\\subseteq\\Omega\\right\\}.\n\\end{align*}\\]\nこれを \\(\\Omega\\) の冪集合という。 例えば \\(\\Omega=\\{1,2,3\\}\\) のとき、\n\\[\n2^\\Omega = \\left\\{\\varnothing, \\{1\\}, \\{2\\}, \\{3\\}, \\{1,2\\},\\{2,3\\},\\{1,3\\},\\{1,2,3\\}\\right\\}\n\\]\nである。 \\(\\Omega\\) が有限集合のとき、\\(|2^\\Omega|=2^{|\\Omega|}\\) が成り立つ。 また、\\(2^\\Omega\\) の部分集合を \\(\\Omega\\) 上の(部分)集合族と呼ぶ。 集合 \\(\\Lambda\\) の各 \\(\\lambda\\in\\Lambda\\) に対して集合 \\(A_\\lambda\\subseteq\\Omega\\) が存在するとき、集合族\n\\[\n\\left\\{A_\\lambda\\subseteq\\Omega\\mid \\lambda\\in\\Lambda\\right\\}\\subseteq 2^\\Omega\n\\]\nを添字集合 \\(\\Lambda\\) で添字付けられた \\(\\Omega\\) 上の集合族という。\n添字集合が有限集合の場合は集合族全体の和集合や積集合は二つの集合の和集合と積集合の定義を繰り返し用いることで定義できる。 それらは以下のように表す。\n\\[\n\\bigcup_{\\lambda\\in\\Lambda} A_\\lambda \\quad,\\quad\n\\bigcap_{\\lambda\\in\\Lambda} A_\\lambda.\n\\]"
  },
  {
    "objectID": "slides/01_probability.html#ドモルガンの法則",
    "href": "slides/01_probability.html#ドモルガンの法則",
    "title": "確率論",
    "section": "ド・モルガンの法則",
    "text": "ド・モルガンの法則\n添字集合 \\(\\Lambda\\) が無限集合の場合は和集合と積集合を以下で定義する。\n\\[\\begin{align*}\n\\bigcup_{\\lambda\\in\\Lambda} A_\\lambda\n&\\coloneqq\n\\left\\{x\\in\\Omega\\mid \\exists \\lambda\\in\\Lambda,\\quad x\\in A_\\lambda\\right\\}\\\\\n\\bigcap_{\\lambda\\in\\Lambda} A_\\lambda\n&\\coloneqq\n\\left\\{x\\in\\Omega\\mid \\forall \\lambda\\in\\Lambda,\\quad x\\in A_\\lambda\\right\\}\n\\end{align*}\\]\nこの定義は \\(\\Lambda\\) が有限集合の場合も正しいものである。 この場合もド・モルガンの法則は成り立つ。つまり、\n\\[\\begin{align*}\n\\left(\\bigcup_{\\lambda\\in\\Lambda} A_\\lambda\\right)^\\mathrm{c}\n&=\n\\bigcap_{\\lambda\\in\\Lambda} A_\\lambda^\\mathrm{c},&\n\\left(\\bigcap_{\\lambda\\in\\Lambda} A_\\lambda\\right)^\\mathrm{c}\n&=\n\\bigcup_{\\lambda\\in\\Lambda} A_\\lambda^\\mathrm{c}\n\\end{align*}\\]\nが成り立つ。\n証明: \\(x\\in\\Omega\\) について、 \\[\\begin{align*}\nx\\in\\left(\\bigcup_{\\lambda\\in\\Lambda} A_\\lambda\\right)^\\mathrm{c}\n&\\iff x\\notin\\left(\\bigcup_{\\lambda\\in\\Lambda} A_\\lambda\\right)\\\\\n&\\iff \\lnot\\left(\\exists\\lambda\\in\\Lambda,\\quad x\\in A_\\lambda\\right)\\\\\n&\\iff \\forall\\lambda\\in\\Lambda,\\quad x\\notin A_\\lambda\\\\\n&\\iff \\forall\\lambda\\in\\Lambda,\\quad x\\in A_\\lambda^\\mathrm{c}\\\\\n&\\iff x\\in\\bigcap_{\\lambda\\in\\Lambda} A_\\lambda^{\\mathrm{c}}.\n\\end{align*}\\]"
  },
  {
    "objectID": "slides/01_probability.html#標本空間と確率",
    "href": "slides/01_probability.html#標本空間と確率",
    "title": "確率論",
    "section": "標本空間と確率",
    "text": "標本空間と確率\n\n\\(\\Omega\\colon\\) 集合。これの部分集合に確率が与えられる\n\\(P\\colon 2^\\Omega\\to\\mathbb{R}_{\\ge 0}.\\) 確率を与える関数\n\n\nExample 1  \n\n\n\\(\\Omega=\\{表,裏\\}\\).\n\\(P(\\varnothing)= 0,\\, P(\\{\\mathrm{表}\\})=P(\\{\\mathrm{裏}\\})=\\frac12,\\,P(\\{\\mathrm{表},\\mathrm{裏}\\})=1\\).\n\n\n\n\n\\(\\Omega=\\{1,2,3,4,5,6\\}\\).\n\\(P(A) = \\frac{|A|}6\\quad\\forall A\\subseteq\\Omega\\).\n\n\n\n\n\\(\\Omega=\\{晴,雨,雪\\}\\).\n\\(P(\\varnothing)= 0,\\, P(\\{晴\\})=0.7,\\, P(\\{雨\\})=0.2,\\,P(\\{雪\\})=0.1\\), \\(P(\\{晴,雨\\})=0.9,\\, P(\\{雨,雪\\})=0.3,\\, P(\\{雪,晴\\})=0.8\\), \\(P(\\{晴,雨,雪\\})=1\\)."
  },
  {
    "objectID": "slides/01_probability.html#確率論の公理有限版",
    "href": "slides/01_probability.html#確率論の公理有限版",
    "title": "確率論",
    "section": "確率論の公理有限版",
    "text": "確率論の公理有限版\n\n\\(\\Omega\\colon\\) 有限集合(標本空間)\n\\(P\\colon 2^\\Omega\\to\\mathbb{R}_{\\ge 0}\\) (確率測度)\n\n確率の公理\n\n\\(P(\\Omega)=1\\).\n\\(\\forall A, B\\subseteq\\Omega\\), \\(A\\cap B=\\varnothing\\implies P(A\\cup B)=P(A)+P(B)\\) (有限加法性).\n\nこの公理を満たすペア \\((\\Omega,\\, P)\\) を確率空間という。\n例えば\n\\[\n   P(\\{\\text{\"晴\"}, \\text{\"雨\"}\\}) = P(\\{\\text{\"晴\"}\\}) + P(\\{\\text{\"雨\"}\\})\n\\] という等式は「晴れもしくは雨になる確率 \\(=\\) 晴れになる確率 \\(+\\) 雨になる確率」という意味の等式になる。\nこのように \\(\\Omega\\) が有限集合の場合、各 \\(\\omega\\in\\Omega\\) に対する一つの要素の確率 \\(P(\\{\\omega\\})\\) から \\(P\\) が定まる。\n\n\\(\\Omega\\) を無限集合にしたい場合はどうする？"
  },
  {
    "objectID": "slides/01_probability.html#確率論の公理可算版",
    "href": "slides/01_probability.html#確率論の公理可算版",
    "title": "確率論",
    "section": "確率論の公理可算版",
    "text": "確率論の公理可算版\n\n\\(\\Omega\\colon\\) 高々可算集合(標本空間)\n\\(P\\colon 2^\\Omega\\to\\mathbb{R}_{\\ge 0}\\) (確率測度)\n\n確率の公理\n\n\\(P(\\Omega)=1\\). \n\\(\\forall (A_n\\subseteq\\Omega)_{n\\ge 0}\\), \\(\\forall i\\ne j,\\, A_i\\cap A_j=\\varnothing\\implies P\\left(\\bigcup_{n\\ge0} A_n\\right)=\\sum_{n\\ge0} P(A_n)\\) (完全加法性, \\(\\sigma\\)-加法性).\n\n無限和 \\(\\sum_{n\\ge0} P(A_n)\\) において \\(P(A_n)\\ge 0\\) なので、この無限和が存在するときは絶対収束する。 よって和の順序を並び変えても収束値は変わらないことが分かる。実際、左辺にある \\(\\bigcup_{n\\ge 0} A_n\\) は事象 \\(A_n\\) の並び順によらない。\n\\(\\Omega\\) が高々可算集合の場合、任意の \\(A\\subseteq\\Omega\\) も高々可算集合なので、\n\\[\\begin{align*}\nP(A) &= P\\left(\\bigcup_{\\omega\\in A} \\{\\omega\\}\\right)\\\\\n&= \\sum_{\\omega\\in A} P(\\{\\omega\\})\n\\end{align*}\\] が成り立つ。 よって各 \\(\\omega\\in\\Omega\\) に対する一つの要素の確率 \\(P(\\{\\omega\\})\\) から \\(P\\) が定まる。"
  },
  {
    "objectID": "slides/01_probability.html#確率論の公理最終版",
    "href": "slides/01_probability.html#確率論の公理最終版",
    "title": "確率論",
    "section": "確率論の公理最終版?",
    "text": "確率論の公理最終版?\nこれでよいのか？\n\n\\(\\Omega\\colon\\) (非可算でもよい)集合(標本空間)\n\\(P\\colon 2^\\Omega\\to\\mathbb{R}_{\\ge 0}\\) (確率測度)\n\n確率の公理\n\n\\(P(\\Omega)=1\\). \n\\(\\forall (A_n\\subseteq\\Omega)_{n\\ge 0}\\), \\(\\forall i\\ne j,\\, A_i\\cap A_j=\\varnothing\\implies P\\left(\\bigcup_{n\\ge0} A_n\\right)=\\sum_{n\\ge0} P(A_n)\\) (完全加法性, \\(\\sigma\\)-加法性).\n\n\nこれで大丈夫？"
  },
  {
    "objectID": "slides/01_probability.html#ダメ完全加法性選択公理",
    "href": "slides/01_probability.html#ダメ完全加法性選択公理",
    "title": "確率論",
    "section": "ダメ(完全加法性+選択公理)",
    "text": "ダメ(完全加法性+選択公理)\n\n\\(\\Omega=[0,1)\\).\n\\(\\forall c\\in\\Omega,\\, A\\subseteq\\Omega,\\, P(A+c) = P(A)\\) where \\(A+c\\coloneqq\\{a+c-\\lfloor a+c\\rfloor\\mid a\\in A\\}\\).\n\n選択公理を仮定するとそのような確率空間は存在しない。\n\\(\\Omega\\) の上の同値関係を \\(x\\sim y\\stackrel{\\mathrm{def}}{\\iff} x-y \\in\\mathbb{Q}\\)と定義する。\n\\(\\Omega\\) の上の同値類から一つずつ要素を選んで集合 \\(V\\) を作る(選択公理)。\n\\[\\begin{align*}\n1 = P([0,1)) &= P\\left(\\bigcup_{q\\in\\mathbb{Q}\\cap[0,1)} (V + q)\\right)\\\\\n&= \\sum_{q\\in\\mathbb{Q}\\cap[0,1)} P\\left(V + q\\right)\\qquad\\textsf{(完全加法性)}\\\\\n&= \\sum_{q\\in\\mathbb{Q}\\cap[0,1)} P\\left(V\\right)\\qquad\\textsf{(平行移動不変性).}\n\\end{align*}\\] 同じ値を無限回足して1にはできない。"
  },
  {
    "objectID": "slides/01_probability.html#ちゃんとした確率論の公理",
    "href": "slides/01_probability.html#ちゃんとした確率論の公理",
    "title": "確率論",
    "section": "ちゃんとした確率論の公理",
    "text": "ちゃんとした確率論の公理\n確率空間 \\((\\Omega, \\mathcal{F}, P)\\)\n\n\\(\\Omega\\colon\\) 集合(標本空間)\n\\(\\mathcal{F}\\subseteq 2^\\Omega\\) (事象の集合、可測集合)\n\\(P\\colon\\mathcal{F}\\to\\mathbb{R}_{\\ge 0}\\) (確率測度、確率は \\(\\mathcal{F}\\) の要素にのみ定義される！)\n\n可測集合 \\(\\mathcal{F}\\) の公理(\\(\\sigma\\)-加法族、完全加法族)\n\n\\(\\varnothing\\in\\mathcal{F}\\).\n\\(A\\in\\mathcal{F}\\implies \\Omega\\setminus A\\in\\mathcal{F}\\).\n\\((A_n\\in\\mathcal{F})_{n\\ge 0}\\implies \\bigcup_{n\\ge 0} A_n\\in\\mathcal{F}\\) (完全加法性, \\(\\sigma\\)-加 法性).\n\n確率の公理\n\n\\(P(\\Omega)=1\\).\n\\(\\forall (A_n\\in\\mathcal{F})_{n=1,\\dotsc}\\), \\(\\forall i\\ne j,\\, A_i\\cap A_j=\\varnothing\\implies P\\left(\\bigcup_{n=1}^\\infty A_n\\right)=\\sum_{n=1}^\\infty P(A_n)\\) (完全加法性, \\(\\sigma\\)-加法性).\n\nつまり、確率が定義される対象を \\(\\mathcal{F}\\) に限定する。\nさっきの例に現れた選択公理で作った集合 \\(V\\) を \\(\\mathcal{F}\\) に含めなければ、矛盾なく確率を定義できる。"
  },
  {
    "objectID": "slides/01_probability.html#この授業の方針",
    "href": "slides/01_probability.html#この授業の方針",
    "title": "確率論",
    "section": "この授業の方針",
    "text": "この授業の方針\nここまでのまとめ\n\n\\(\\Omega\\) が高々可算の場合は \\(\\mathcal{F}=2^\\Omega\\)とできる。\n\\(\\Omega\\) が非可算の場合は(平行移動で不変などの条件を課すと)すべての部分集合を可測とできない場合がある (要選択公理)。\n\nこの授業では \\(\\mathcal{F}=2^\\Omega\\)のつもりですすめる。\n\\(\\Omega\\) の部分集合を事象と呼ぶ。\n実際に考えるような確率空間では非可測な集合\\(A\\notin\\mathcal{F}\\)は選択公理を使わないと構成できない。\n普通に考える集合は全部可測。\nこの授業は測度論の授業ではないので、非可測な集合については考えないことにする。\n今後、確率空間は \\((\\Omega,\\,\\mathcal{F},\\,P)\\) じゃなくて \\((\\Omega,\\,P)\\) とする。"
  },
  {
    "objectID": "slides/01_probability.html#確率空間の性質",
    "href": "slides/01_probability.html#確率空間の性質",
    "title": "確率論",
    "section": "確率空間の性質",
    "text": "確率空間の性質\n確率空間 \\((\\Omega,\\, P)\\) と任意の \\(A,\\,B\\subseteq \\Omega\\) について以下が成り立つ。\n\n\\(P(A^\\mathrm{c}) = 1 - P(A)\\).\n\\(B\\subseteq A\\implies P(B)\\le P(A)\\)\n\\(P(A\\cup B) = P(A) + P(B) - P(A\\cap B)\\).\n\\(P(A\\cup B) \\le P(A) + P(B)\\qquad\\) (ブールの不等式、union bound).\n\n\nProof. \n\n\\[\n1 = P(\\Omega) = P(A \\cup A^\\mathrm{c}) = P(A) + P(A^\\mathrm{c}).\n\\]\n\\[\nP(A) = P(B\\cup (A\\setminus B)) = P(B) + P(A\\setminus B) \\ge P(B).\n\\]\n\\[\\begin{align*}\nP(A\\cup B) &= P(A \\cup (B\\setminus A)) = P(A) + P(B\\setminus A)\\\\\nP(B) &= P((B\\setminus A) \\cup (A\\cap B)) = P(B\\setminus A) + P(A\\cap B)\n\\end{align*}\\] より、 \\(P(B\\setminus A)\\) を消去することで得られる。\n3 より自明"
  },
  {
    "objectID": "slides/01_probability.html#ユニオンバウンド",
    "href": "slides/01_probability.html#ユニオンバウンド",
    "title": "確率論",
    "section": "ユニオンバウンド",
    "text": "ユニオンバウンド\n\nLemma 1 (ユニオンバウンド) 確率空間 \\((\\Omega,\\, P)\\) と \\((A_n\\subseteq\\Omega)_{n\\ge 0}\\) について、 \\[\nP\\left(\\bigcup_{n\\ge 0} A_n\\right) \\le \\sum_{n\\ge 0} P(A_n).\n\\]\n\n\nProof. \\(B_0 \\coloneqq A_0\\), \\(B_n \\coloneqq A_n \\setminus \\bigcup_{k=0}^{n-1} A_k\\) とおくと、\n\\[\\begin{align*}\nP\\left(\\bigcup_{n\\ge 0} A_n\\right) &= P\\left(\\bigcup_{n\\ge 0} B_n\\right)\\\\\n&= \\sum_{n\\ge 0} P\\left(B_n\\right)\\\\\n&\\le \\sum_{n\\ge 0} P\\left(A_n\\right).\n\\end{align*}\\]"
  },
  {
    "objectID": "slides/01_probability.html#確率測度の連続性",
    "href": "slides/01_probability.html#確率測度の連続性",
    "title": "確率論",
    "section": "確率測度の連続性",
    "text": "確率測度の連続性\n\nTheorem 1 (確率測度の連続性) 確率空間 \\((\\Omega,\\, P)\\) と事象列 \\(A_0\\subseteq A_1\\subseteq \\dotsb \\subseteq \\Omega\\) について \\[\\begin{align*}\nP\\left(\\bigcup_{n\\ge 0} A_n\\right) = \\lim_{n\\to\\infty} P(A_n).\n\\end{align*}\\] また、事象列 \\(\\Omega\\supseteq A_0\\supseteq A_1\\supseteq \\dotsb\\) について \\[\\begin{align*}\nP\\left(\\bigcap_{n\\ge 0} A_n\\right) = \\lim_{n\\to\\infty} P(A_n).\n\\end{align*}\\]\n\n\nProof. 事象列 \\(A_0\\subseteq A_1\\subseteq \\dotsb \\subseteq \\Omega\\) について考える。 \\(B_0\\coloneqq A_0\\), \\(n\\ge 1\\)について\\(B_n\\coloneqq A_n\\setminus A_{n-1}\\)とおく。 このとき、\\(i\\ne j\\)について \\(B_i\\cap B_j=\\varnothing\\)。 また \\(k\\ge 0\\) について、\\(\\bigcup_{n=0}^k B_n = \\bigcup_{n=0}^kA_n = A_k\\) が成り立つ.\n\\[\\begin{align*}\nP\\left(\\bigcup_{n\\ge 0} A_n\\right)&= P\\left(\\bigcup_{n\\ge 0} B_n\\right) =\\sum_{n\\ge 0} P(B_n)\\\\\n&=\\lim_{k\\to\\infty} \\sum_{n=0}^k P(B_n)\n=\\lim_{k\\to\\infty} P\\left(\\bigcup_{n=0}^k B_n\\right)\n=\\lim_{k\\to\\infty} P(A_k).\n\\end{align*}\\]\n事象列 \\(\\Omega\\supseteq A_0\\supseteq A_1\\supseteq \\dotsb\\) の場合についてはド・モルガンの法則を使うことで前半の結果に帰着でき証明できる。"
  },
  {
    "objectID": "slides/01_probability.html#今週の課題",
    "href": "slides/01_probability.html#今週の課題",
    "title": "確率論",
    "section": "今週の課題",
    "text": "今週の課題\n\\(\\Omega = \\{1,2,3,4,5,6\\}\\) とし、ある \\(P\\colon\\Omega\\to\\mathbb{R}_{\\ge 0}\\) について \\((\\Omega,\\,P)\\) を確率空間とする。 事象 \\(A,\\,B,\\,C\\) を\n\\[\\begin{align*}\nA&=\\left\\{1,2,3,4\\right\\},&\nB&=\\left\\{2,4,5\\right\\},&\nC&=\\left\\{1,3,5,6\\right\\}\n\\end{align*}\\] とするとき、以下の問に答えよ\n\n\n\\(A\\cup B\\),  \\(A\\cap B\\),  \\(A\\setminus B\\),  \\((A\\cup B)\\cap C\\) をもとめよ。\n\\(P(\\{1,3\\})\\),  \\(P(\\{2,4\\})\\),  \\(P(\\{5\\})\\),  \\(P(\\{6\\})\\) を \\(P(A),\\,P(B),\\,P(C)\\) を用いて表せ。"
  },
  {
    "objectID": "slides/03_multi.html#条件付き確率",
    "href": "slides/03_multi.html#条件付き確率",
    "title": "確率論",
    "section": "条件付き確率",
    "text": "条件付き確率\n\nDefinition 1 (条件付き確率) 確率空間 \\((\\Omega,\\,P)\\) の事象 \\(A,B\\subseteq\\Omega\\) について \\(P(B)&gt; 0\\) のとき、\\(B\\) における \\(A\\) の条件付き確率 は以下で定義される。 \\[\\begin{align*}\n   P(A\\mid B) &\\coloneqq \\frac{P(A\\cap B)}{P(B)}.\n   \\end{align*}\\]\n\n二つの事象 \\(A,B\\subseteq\\Omega\\) を考える文脈では \\(P(A\\cap B)\\) を同時確率、\\(P(A),\\,P(B)\\) を周辺確率という。\n\nDefinition 2 (事象の独立性) 確率空間 \\((\\Omega,\\,P)\\) の事象 \\(A,B\\subseteq\\Omega\\) について \\[\\begin{align*}\nP(A\\cap B) &= P(A) P(B)\n\\end{align*}\\] を満たすとき、事象 \\(A\\) と \\(B\\) は独立であるという。\n\n\n\nExample 1 (二回のコイン投げ) 標本空間を \\(\\Omega = \\{\\mathrm{HH},\\mathrm{HT},\\mathrm{TH},\\mathrm{TT}\\}\\) とし、確率測度を \\(P(A) = \\frac{|A|}4\\quad\\forall A\\subseteq\\Omega\\) とする。 このとき、\\(A=\\{\\mathrm{HH},\\mathrm{HT}\\},\\,B=\\{\\mathrm{HH},\\mathrm{TH}\\}\\) とおくと、 \\[\\begin{align*}\nP(A\\cap B) &= \\frac14,&P(A)&=P(B)=\\frac12\n\\end{align*}\\] より \\(P(A\\cap B) = P(A)P(B)\\) を満たすことが分かる。 よって事象 \\(A,\\,B\\) は独立である。\n\n事象 \\(A\\) と \\(B\\) が独立であり、\\(P(B)&gt;0\\) であるとき、\\(P(A\\mid B)=P(A)\\) である。"
  },
  {
    "objectID": "slides/03_multi.html#確率変数の条件付き確率と独立性",
    "href": "slides/03_multi.html#確率変数の条件付き確率と独立性",
    "title": "確率論",
    "section": "確率変数の条件付き確率と独立性",
    "text": "確率変数の条件付き確率と独立性\n事象は確率変数を通じて表すことが多い。そのため確率変数を用いた条件付き確率も定義する。\n\nDefinition 3 (確率変数) 確率空間 \\((\\Omega,\\,P)\\) 上の確率変数 \\(X_1, X_2\\) について同時確率を \\[\\begin{align*}\n\\Pr(X_1\\in A,\\,X_2\\in B) &\\coloneqq P(\\{\\omega\\in\\Omega\\mid X_1(\\omega)\\in A\\}\\cap\\{\\omega\\in\\Omega\\mid X_2(\\omega)\\in B\\}\\})\\quad\\forall A,B\\subseteq\\mathbb{R}\n\\end{align*}\\] と定義する。確率変数が三つ以上の場合も同様に定義する。 また \\(\\Pr(X_2\\in B)&gt;0\\) のとき、条件付き確率は以下で定義する。 \\[\\begin{align*}\n\\Pr(X_1\\in A\\mid X_2\\in B) &\\coloneqq P(\\{\\omega\\in\\Omega\\mid X_1(\\omega)\\in A\\}\\mid\\{\\omega\\in\\Omega\\mid X_2(\\omega)\\in B\\}\\})\\\\\n&=\\frac{\\Pr(X_1\\in A, X_2\\in B)}{\\Pr(X_2\\in B)}\\qquad\\forall A,B\\subseteq\\mathbb{R}.\n\\end{align*}\\] 任意の \\(A,B\\subseteq\\mathbb{R}\\) について、 \\[\\begin{align*}\n\\Pr(X_1\\in A,\\,X_2\\in B)  &= \\Pr(X_1\\in A)\\Pr(X_2\\in B)\n\\end{align*}\\] を満たすとき、確率変数 \\(X_1\\) と \\(X_2\\) は独立であるという。\n\n\nLemma 1 確率空間 \\((\\Omega,\\,P)\\) 上の確率変数 \\(X_1, X_2\\) が独立であるとする。 このとき任意の関数 \\(f_1,\\,f_2\\colon\\mathbb{R}\\to\\mathbb{R}\\) について、\\(f_1(X_1),\\,f_2(X_2)\\) は独立である。\n\n\nProof. \\[\\begin{align*}\n\\Pr(f_1(X_1)\\in A,\\,f_2(X_2)\\in B) &=\n\\Pr(X_1\\in f_1^{-1}(A),\\,X_2\\in f_2^{-1}(B))\\\\\n&=\\Pr(X_1\\in f_1^{-1}(A))\\Pr(X_2\\in f_2^{-1}(B))\\\\\n&=\\Pr(f_1(X_1)\\in A)\\Pr(f_2(X_2)\\in B).\n\\end{align*}\\]"
  },
  {
    "objectID": "slides/03_multi.html#離散型確率変数と確率質量関数",
    "href": "slides/03_multi.html#離散型確率変数と確率質量関数",
    "title": "確率論",
    "section": "離散型確率変数と確率質量関数",
    "text": "離散型確率変数と確率質量関数\n\nDefinition 4 確率空間 \\((\\Omega,\\,P)\\) 上の離散型確率変数 \\(X_1\\), \\(X_2\\) について、同時確率質量関数を \\[\\begin{align*}\nf_{X_1,\\,X_2}(x_1,x_2) &\\coloneqq \\Pr(X_1=x_1,\\,X_2=x_2)\\\\\n\\end{align*}\\] と定義する。\n\n同時確率質量関数からそれぞれの確率変数の確率質量関数が得られる。 \\[\\begin{align*}\nf_{X_1}(x_1) &= \\sum_{x_2} f_{X_1,\\, X_2}(x_1, x_2),&\nf_{X_2}(x_2) &= \\sum_{x_1} f_{X_1,\\, X_2}(x_1, x_2)\n\\end{align*}\\] それぞれの確率変数の確率質量関数を周辺質量関数と呼ぶ。 同時確率質量関数から周辺質量関数を計算する操作のことを周辺化という。\n\nDefinition 5 確率空間 \\((\\Omega,\\,P)\\) 上の離散型確率変数 \\(X_1\\), \\(X_2\\) について、条件付き確率質量関数を \\[\\begin{align*}\nf_{X_1\\mid X_2}(x_1\\mid x_2) &\\coloneqq \\Pr(X_1=x_1\\mid X_2=x_2)\n\\end{align*}\\] と定義する。\n\n条件付き確率の定義より \\[\\begin{align*}\nf_{X_1,\\,X_2}(x_1,x_2) &= f_{X_1\\mid X_2}(x_1\\mid x_2) f_{X_2}(x_2)\n\\end{align*}\\] が成り立つ。"
  },
  {
    "objectID": "slides/03_multi.html#離散型確率変数の独立性",
    "href": "slides/03_multi.html#離散型確率変数の独立性",
    "title": "確率論",
    "section": "離散型確率変数の独立性",
    "text": "離散型確率変数の独立性\n\nLemma 2 確率空間 \\((\\Omega,\\,P)\\) 上の離散型確率変数 \\(X_1, X_2\\) について、 \\(X_1\\) と \\(X_2\\) が独立 \\(\\iff\\) \\[\\begin{align*}\nf_{X_1,\\,X_2}(x_1,x_2) &= f_{X_1}(x_1) f_{X_2}(x_2)\n&\\forall x_1\\in\\mathrm{Image}(X_1),x_2\\in\\mathrm{Image}(X_2).\n\\end{align*}\\]\n\n\nProof. \\(\\Longrightarrow\\) は自明。 \\(\\Longleftarrow\\) を示す。 \\[\\begin{align*}\n\\Pr(X_1\\in A,\\,X_2\\in B)  &= \\sum_{x_1\\in A}\\sum_{x_2\\in B} \\Pr(X_1=x_1,\\,X_2=x_2)\\\\\n&= \\sum_{x_1\\in A}\\sum_{x_2\\in B} \\Pr(X_1=x_1)\\Pr(X_2=x_2)\\\\\n&= \\Pr(X_1\\in A)\\Pr(X_2\\in B)\n\\end{align*}\\]\n\n\nExample 2 (二回のコイン投げ) 標本空間を \\(\\Omega = \\{\\mathrm{HH},\\mathrm{HT},\\mathrm{TH},\\mathrm{TT}\\}\\) とし、確率測度を \\(P(A) = \\frac{|A|}4\\quad\\forall A\\subseteq\\Omega\\) とする。 \\[\\begin{align*}\nX_1(\\mathrm{HH})&=X_1(\\mathrm{HT}) = 1,&\nX_1(\\mathrm{TH})&=X_1(\\mathrm{TT}) = 0\\\\\nX_2(\\mathrm{HH})&=X_2(\\mathrm{TH}) = 1,&\nX_2(\\mathrm{HT})&=X_2(\\mathrm{TT}) = 0\n\\end{align*}\\] と定義する。 このとき、 \\[\\begin{align*}\nf_{X_1,\\,X_2}(x_1,\\,x_2) &= \\frac14,&\nf_{X_1}(x_1)=f_{X_2}(x_2)&=\\frac12\\qquad\\forall x_1,x_2\\in\\{0,1\\}\n\\end{align*}\\] より \\(f_{X_1,\\,X_2}(x_1,\\,x_2) = f_{X_1}(x_1)f_{X_2}(x_2)\\) を満たすことが分かる。 よって確率変数 \\(X_1,\\,X_2\\) は独立である。"
  },
  {
    "objectID": "slides/03_multi.html#連続型確率変数と確率密度関数",
    "href": "slides/03_multi.html#連続型確率変数と確率密度関数",
    "title": "確率論",
    "section": "連続型確率変数と確率密度関数",
    "text": "連続型確率変数と確率密度関数\n確率空間 \\((\\Omega,\\,P)\\) 上の連続型確率変数 \\(X_1\\), \\(X_2\\) について、同時確率密度関数を \\[\\begin{align*}\n%\\Pr(\\begin{bmatrix}X_1,\\,X_2\\end{bmatrix}\\in A) &= \\int_A f_{X_1,\\,X_2}(x_1,x_2)\\mathrm{d}x_1\\mathrm{d}x_2\n\\Pr(X_1\\in A,\\,X_2\\in B) &= \\int_A\\left(\\int_B f_{X_1,\\,X_2}(x_1,x_2)\\mathrm{d}x_2\\right)\\mathrm{d}x_1\n\\end{align*}\\] を満たすものと定義する。 \\(X_1\\) と \\(X_2\\) が確率密度関数を持つ場合でも \\(X_1\\) と \\(X_2\\) の同時確率密度関数が存在するとは限らない。 例えば \\(X_1=X_2\\) の場合がその例である。 逆に \\(X_1\\) と \\(X_2\\) が同時確率密度関数を持つとき、それぞれの確率密度関数は \\[\\begin{align*}\nf_{X_1}(x_1) &= \\int_{-\\infty}^\\infty f_{X_1,\\,X_2}(x_1,x_2)\\mathrm{d}x_2\\\\\nf_{X_2}(x_2) &= \\int_{-\\infty}^\\infty f_{X_1,\\,X_2}(x_1,x_2)\\mathrm{d}x_1\n\\end{align*}\\] で得られる。この操作を確率密度関数の周辺化という。 同時確率密度関数を持つ確率変数 \\(X_1\\), \\(X_2\\) が独立であるとき、 \\[\\begin{align*}\nf_{X_1,\\,X_2}(x_1,x_2) &= f_{X_1}(x_1) f_{X_2}(x_2)\n\\end{align*}\\] が成り立つ。"
  },
  {
    "objectID": "slides/03_multi.html#三つ以上の独立確率変数",
    "href": "slides/03_multi.html#三つ以上の独立確率変数",
    "title": "確率論",
    "section": "三つ以上の独立確率変数",
    "text": "三つ以上の独立確率変数\n三つ以上の確率変数についても同時確率質量関数、同時確率密度関数を同様に定義する。 独立性についても同様に定義する。\n\nDefinition 6 確率空間 \\((\\Omega,\\,P)\\) 上の確率変数 \\(X_1, X_2,\\dotsc, X_n\\) が独立 \\(\\defiff\\) \\[\\begin{align*}\n\\Pr(X_1\\in A_1,\\dotsc, X_n\\in A_n) &= \\prod_{k=1}^n \\Pr(X_k\\in A_k)\\qquad\\forall A_1,\\dotsc,A_n\\subseteq\\mathbb{R}.\n\\end{align*}\\]\n\n\nDefinition 7 確率空間 \\((\\Omega,\\,P)\\) 上の確率変数 \\(X_1, X_2,\\dotsc, X_n\\) が互いに独立 \\(\\defiff\\) 任意の \\(1\\le i&lt; j\\le n\\) について、\\(X_i\\) と \\(X_j\\) が独立。\n\n\n確率変数 \\(X_1,\\dotsc,X_n\\) が独立であるとき、それらは互いに独立であることは以下から分かる。 \\[\\begin{align*}\n\\Pr(X_1\\in A,\\, X_2\\in B) &= \\Pr(X_1\\in A,\\, X_2\\in B,\\, X_3\\in\\mathbb{R},\\dotsc, X_n\\in\\mathbb{R})\\\\\n&= \\Pr(X_1\\in A)\\Pr(X_2\\in B) \\prod_{k=3}^n \\Pr(X_k\\in\\mathbb{R})\\\\\n&= \\Pr(X_1\\in A)\\Pr(X_2\\in B).\n\\end{align*}\\]"
  },
  {
    "objectID": "slides/03_multi.html#互いに独立であるが独立ではない例",
    "href": "slides/03_multi.html#互いに独立であるが独立ではない例",
    "title": "確率論",
    "section": "互いに独立であるが独立ではない例",
    "text": "互いに独立であるが独立ではない例\n一方で確率変数 \\(X_1,\\dotsc,X_n\\) が互いに独立であっても、それらが独立であるとは限らない。 例えば、離散型確率変数 \\(X_1,\\dotsc,X_n\\) を \\[\\begin{align*}\nf_{X_1,\\dotsc,X_n}(x_1,\\dotsc,x_n)&=\\begin{cases}\n\\frac1{2^{n-1}}&\\text{if } \\sum_{k=1}^n x_k \\text{ is even}\\\\\n0&\\text{otherwise}\n\\end{cases}&\n\\forall x_1,\\dotsc,x_n\\in\\{0,1\\}\n\\end{align*}\\] と定義する。 このとき、確率変数 \\(X_n\\) を周辺化すると \\[\\begin{align*}\nf_{X_1,\\dotsc,X_{n-1}}(x_1,\\dotsc,x_{n-1})&=\nf_{X_1,\\dotsc,X_n}(x_1,\\dotsc,x_{n-1},0)+ f_{X_1,\\dotsc,X_n}(x_1,\\dotsc,x_{n-1},1)\n=\\frac1{2^{n-1}}\n\\end{align*}\\] となる。つまり、\\(X_1,\\dotsc,X_{n-1}\\) は \\(\\{0,1\\}^{n-1}\\) 上の一様分布に従う。 この確率分布は \\(X_1,\\dotsc,X_n\\) について対称なので、どの確率変数を周辺化しても一様分布に従う。 一様分布は独立なので、\\(n\\ge 3\\) のとき、どの二つの確率変数も独立である。 よって \\(n\\ge 3\\) のとき、\\(X_1,\\dotsc,X_n\\) は互いに独立である。\n一方で、\\(n\\ge 2\\) のとき、これらの確率変数の周辺確率は一様である。つまり、 \\[\\begin{align*}\nf_{X_k}(0) &= f_{X_k}(1) = \\frac12\\qquad\\forall k=1,2,\\dotsc,n.\n\\end{align*}\\] しかし、 \\[\\begin{align*}\nf_{X_1,\\dotsc,X_n}(x_1,\\dotsc,x_n)&=\\prod_{k=1}^n f_{X_k}(x_k)\\qquad\\forall x_1,\\dotsc,x_n\\in\\{0,1\\}\n\\end{align*}\\] は成り立たないので独立ではない。"
  },
  {
    "objectID": "slides/03_multi.html#独立な離散型確率変数の和",
    "href": "slides/03_multi.html#独立な離散型確率変数の和",
    "title": "確率論",
    "section": "独立な離散型確率変数の和",
    "text": "独立な離散型確率変数の和\n離散型確率変数 \\(X_1\\) と \\(X_2\\) が独立であるとする。 このとき、\\(X_1+X_2\\) の確率質量関数は \\[\\begin{align*}\nf_{X_1+X_2}(x) &= \\sum_z f_{X_1}(z)f_{X_2}(x-z)\n\\end{align*}\\] で与えられる。 これを確率質量関数の畳み込みという。\n\nExample 3 二項分布の \\(N=1\\) の場合をベルヌーイ分布 \\(\\mathrm{Ber}(p)\\) と呼ぶ。 つまり、\\(X\\sim\\mathrm{Ber}(p)\\defiff\\) \\[\\begin{align*}\n\\Pr(X=0) &= 1-p,& \\Pr(X=1) &= p\n\\end{align*}\\] である。 確率変数 \\(X_1,X_2\\) が独立で \\(\\mathrm{Ber}(p)\\) に従うとする。 このとき、\\(X_1+X_2\\) は \\(\\mathrm{Binom}(2, p)\\) に従う。 \\[\\begin{align*}\n\\Pr(X_1+X_2 = 0) &= \\Pr(X_1=0,\\,X_2=0)\n= \\Pr(X_1=0)\\Pr(X_2=0) = (1-p)^2\\\\\n\\Pr(X_1+X_2 = 1) &= \\Pr(X_1=0,\\,X_2=1) + \\Pr(X_1=1,\\,X_2=0)\\\\\n&=  \\Pr(X_1=0)\\Pr(X_2=1) + \\Pr(X_1=1)\\Pr(X_2=0)\\\\\n&= 2p(1-p)\\\\\n\\Pr(X_1+X_2 = 2) &= \\Pr(X_1=1,\\,X_2=1)\n= \\Pr(X_1=1)\\Pr(X_2=1) = p^2\n\\end{align*}\\] と計算できる。 よって \\[\\begin{align*}\n\\Pr(X_1+X_2 = k) &= \\binom{2}{k} p^k(1-p)^{2-k}\n\\end{align*}\\] が成り立ち \\(X_1+X_2\\sim\\mathrm{Binom}(2, p)\\) であることが分かる。"
  },
  {
    "objectID": "slides/03_multi.html#二項分布の再生性",
    "href": "slides/03_multi.html#二項分布の再生性",
    "title": "確率論",
    "section": "二項分布の再生性",
    "text": "二項分布の再生性\n確率分布の族(集合)が畳み込みに閉じているとき、確率分布の族は再生性を持つという。 二項分布の場合はパラメータ \\(p\\) を固定したときに再生性を持つ。\n\nExample 4 一般に、独立確率変数 \\(X_1,\\,X_2\\) について \\(X_1\\sim\\mathrm{Binom}(n, p)\\), \\(X_2\\sim\\mathrm{Binom}(m, p)\\) のとき、\\(X_1+X_2\\sim\\mathrm{Binom}(n+m,p)\\) である。 \\[\\begin{align*}\n\\Pr(X_1+X_2 = k) &= \\sum_{\\ell\\ge 0} \\Pr(X_1 = \\ell) \\Pr(X_2 = k-\\ell)\\\\\n&= \\sum_{\\ell\\ge 0} \\binom{n}{\\ell} p^\\ell(1-p)^{n-\\ell} \\binom{m}{k-\\ell} p^{k-\\ell}(1-p)^{m-k+\\ell}\\\\\n&= \\left(\\sum_{\\ell= 0}^k \\binom{n}{\\ell} \\binom{m}{k-\\ell}\\right) p^k(1-p)^{n+m-k}\\\\\n&= \\binom{n+m}{k} p^k(1-p)^{n+m-k}.\n\\end{align*}\\]"
  },
  {
    "objectID": "slides/03_multi.html#ポアソン分布の再生性",
    "href": "slides/03_multi.html#ポアソン分布の再生性",
    "title": "確率論",
    "section": "ポアソン分布の再生性",
    "text": "ポアソン分布の再生性\nポアソン分布も再生性を持つ。\n\nExample 5 確率変数 \\(X_1\\), \\(X_2\\) が独立で \\(X_1\\sim\\mathrm{Poisson}(\\lambda_1)\\), \\(X_2\\sim\\mathrm{Poisson}(\\lambda_2)\\) とする。 このとき、 \\[\\begin{align*}\nf_{X_1+X_2}(x) &= \\sum_{z= 0}^x f_{X_1}(z) f_{X_2}(x-z)\\\\\n&= \\sum_{z= 0}^x \\frac{\\lambda_1^z}{z!}\\mathrm{e}^{-\\lambda_1}\\frac{\\lambda_2^{x-z}}{(x-z)!}\\mathrm{e}^{-\\lambda_2}\\\\\n&= \\frac1{x!}\\mathrm{e}^{-(\\lambda_1+\\lambda_2)}\\sum_{z=0}^x\\binom{x}{z} \\lambda_1^z\\lambda_2^{x-z}\\\\\n&= \\frac1{x!}\\mathrm{e}^{-(\\lambda_1+\\lambda_2)}(\\lambda_1+\\lambda_2)^x\n\\end{align*}\\] が成り立つ。よって \\(X_1+X_2\\sim\\mathrm{Poisson}(\\lambda_1+\\lambda_2)\\) である。"
  },
  {
    "objectID": "slides/03_multi.html#独立な連続型確率変数の和",
    "href": "slides/03_multi.html#独立な連続型確率変数の和",
    "title": "確率論",
    "section": "独立な連続型確率変数の和",
    "text": "独立な連続型確率変数の和\n連続確率変数 \\(X_1\\) と \\(X_2\\) が独立で密度関数を持つとき、 \\[\\begin{align*}\n\\Pr(X_1+X_2\\in A) &= \\int\\int_{y+z\\in A} f_{X_1}(y)f_{X_2}(z)\\mathrm{d}y\\mathrm{d}z\\\\\n&= \\int\\int_{x\\in A} f_{X_1}(y)f_{X_2}(x-y)\\mathrm{d}y\\mathrm{d}x \\qquad(x=y+z)\\\\\n&= \\int_{A} \\left(\\int_{-\\infty}^\\infty f_{X_1}(y)f_{X_2}(x-y)\\mathrm{d}y\\right)\\mathrm{d}x \\qquad(x=y+z)\\\\\n\\end{align*}\\] と表せるので、\\(X_1+X_2\\) は確率密度関数を持ち \\[\\begin{align*}\nf_{X_1+X_2}(x) &= \\int_{-\\infty}^\\infty f_{X_1}(z)f_{X_2}(x-z)\\mathrm{d} z\n\\end{align*}\\] とすることができる。 これを確率密度関数の畳み込みという。"
  },
  {
    "objectID": "slides/03_multi.html#正規分布の再生性",
    "href": "slides/03_multi.html#正規分布の再生性",
    "title": "確率論",
    "section": "正規分布の再生性",
    "text": "正規分布の再生性\n確率変数 \\(X_1,\\,X_2\\) が独立で \\(X_1\\sim N(\\mu_1,\\,\\sigma_1^2)\\), \\(X_2\\sim N(\\mu_2,\\,\\sigma_2^2)\\) とする。 このとき、 \\[\\begin{align*}\nf_{X_1+X_2}(x) &= \\int_{-\\infty}^\\infty f_{X_1}(z)f_{X_2}(x-z)\\mathrm{d} z\\\\\n&= \\int_{-\\infty}^\\infty \\frac1{\\sqrt{2\\pi\\sigma_1^2}} \\mathrm{e}^{-\\frac{(z-\\mu_1)^2}{2\\sigma_1^2}}\\frac1{\\sqrt{2\\pi\\sigma_2^2}} \\mathrm{e}^{-\\frac{(x-z-\\mu_2)^2}{2\\sigma_2^2}}\\mathrm{d} z\\\\\n&= \\frac1{2\\pi\\sqrt{\\sigma_1^2\\sigma_2^2}}\\int_{-\\infty}^\\infty  \\mathrm{e}^{-\\frac{\\sigma_2^2(z-\\mu_1)^2+\\sigma_1^2(x-z-\\mu_2)^2}{2\\sigma_1^2\\sigma_2^2}}\\mathrm{d} z\\\\\n&= \\frac1{2\\pi\\sqrt{\\sigma_1^2\\sigma_2^2}}\\int_{-\\infty}^\\infty  \\mathrm{e}^{-\\frac{(\\sigma_1^2+\\sigma_2^2)\\left(z-\\frac{\\sigma_2^2\\mu_1+\\sigma_1^2(x-\\mu_2)}{\\sigma_1^2+\\sigma_2^2}\\right)^2 + \\sigma_2^2\\mu_1^2 + \\sigma_1^2(x-\\mu_2)^2 - \\frac{(\\sigma_2^2\\mu_1+\\sigma_1^2(x-\\mu_2))^2}{\\sigma_1^2+\\sigma_2^2}}{2\\sigma_1^2\\sigma_2^2}}\\mathrm{d} z\\\\\n&= \\frac1{\\sqrt{2\\pi(\\sigma_1^2+\\sigma_2^2)}}\\mathrm{e}^{-\\frac{\\sigma_2^2\\mu_1^2 + \\sigma_1^2(x-\\mu_2)^2 - \\frac{(\\sigma_2^2\\mu_1+\\sigma_1^2(x-\\mu_2))^2}{\\sigma_1^2+\\sigma_2^2}}{2\\sigma_1^2\\sigma_2^2}}\\\\\n&= \\frac1{\\sqrt{2\\pi(\\sigma_1^2+\\sigma_2^2)}}\\mathrm{e}^{-\\frac{(x-(\\mu_1+\\mu_2))^2}{2(\\sigma_1^2+\\sigma_2^2)}}\\\\\n\\end{align*}\\] が成り立つので \\(X_1+X_2\\sim N(\\mu_1+\\mu_2,\\,\\sigma_1^2+\\sigma_2^2)\\) であることが分かる。 よって正規分布は再生性を持つ。"
  },
  {
    "objectID": "slides/03_multi.html#今週の課題",
    "href": "slides/03_multi.html#今週の課題",
    "title": "確率論",
    "section": "今週の課題",
    "text": "今週の課題\n以下の問に答えよ\n\n\n共通の確率空間上の離散型確率変数 \\(X\\) と \\(Y\\) が以下の同時確率質量関数を持つとする。 \\[\\begin{align*}\nf_{X,\\,Y}(0,\\,0) &= a,&\nf_{X,\\,Y}(0,\\,1) &= b,&\nf_{X,\\,Y}(0,\\,2) &= c,\\\\\nf_{X,\\,Y}(1,\\,0) &= d,&\nf_{X,\\,Y}(1,\\,1) &= e,&\nf_{X,\\,Y}(1,\\,2) &= f\n\\end{align*}\\] ここで、 \\(a,b,c,d,e,f\\in\\mathbb{R}_{\\ge 0}\\) は \\(a+b+c+d+e+f=1\\) を満たすものとする。 このとき、周辺確率質量関数 \\(f_X\\) と \\(f_Y\\) をもとめよ。\n確率変数 \\(X\\) と \\(Y\\) が独立で \\[\\begin{align*}\nX&\\sim\\mathrm{Ber}(p)& p\\in[0,1]\\\\\nY&\\sim\\mathrm{Poisson}(\\lambda)& \\lambda &gt; 0\n\\end{align*}\\] とする。 このとき、 \\(X+Y\\) の確率質量関数をもとめよ。結果の式は共通因子でくくらなくてよい(採点が楽なので)。"
  },
  {
    "objectID": "slides/06_testings.html#事前分布を仮定しない推定問題",
    "href": "slides/06_testings.html#事前分布を仮定しない推定問題",
    "title": "確率論",
    "section": "事前分布を仮定しない推定問題",
    "text": "事前分布を仮定しない推定問題\nベイズ推定では推定したいパラメータ \\(\\theta\\in\\Theta\\) の事前分布 \\(\\pi(\\theta)\\) を既知として仮定した。\nしかし、現実の問題ではこの事前分布を適切に仮定する方法がない場合もある。\n\n開発中の薬に効果があるかないか\nある患者が病気かどうか\nサイコロに偏りがあるかどうか\n\nといった問題について事前分布をどのように仮定するのが適切か不明瞭である。\n尤度 \\(p(x\\mid\\theta)\\) は既知とし、事前分布は既知でないときに データ \\(x\\in\\mathcal{X}\\) から パラメータ \\(\\theta\\in\\Theta\\) を推定する問題を考える。"
  },
  {
    "objectID": "slides/06_testings.html#伝統的な仮説検定",
    "href": "slides/06_testings.html#伝統的な仮説検定",
    "title": "確率論",
    "section": "伝統的な仮説検定",
    "text": "伝統的な仮説検定\nパラメータの集合を二つの部分集合 \\(H_0\\) と \\(H_1\\) に分割する。 つまり、\\(H_0\\cup H_1 = \\Theta\\), \\(H_0\\cap H_1=\\varnothing\\) である。\nそしてパラメータが \\(H_0\\) に属するか \\(H_1\\) に属するかを知りたいとする。 この二つの集合 \\(H_0\\) と \\(H_1\\) を仮説という。\nその二つの仮説のうちの通常成り立っていると考える方を \\(H_0\\) とし 帰無仮説と呼ぶ。 また、そうでない方を \\(H_1\\) とし 対立仮説と呼ぶ。\n帰無仮説の例として\n\n開発中の薬に効果はない\nある患者が病気ではない\nサイコロに偏りはない\n\nなどがある。 それらに対応する対立仮説はそれぞれ\n\n開発中の薬に効果がある\nある患者が病気である\nサイコロに偏りがある\n\nとなる。 仮説検定の考え方では帰無仮説を棄却するかしないかを決める。 帰無仮説を棄却した場合、対立仮説を正しいと考え、帰無仮説を棄却しなかった場合は何も言えないと結論づける。"
  },
  {
    "objectID": "slides/06_testings.html#単純仮説",
    "href": "slides/06_testings.html#単純仮説",
    "title": "確率論",
    "section": "単純仮説",
    "text": "単純仮説\n仮説 \\(H_0\\) と \\(H_1\\) がそれぞれ一元集合であるとき、それらを単純仮説という。 \\(H_0=\\{\\theta_0\\}\\), \\(H_1=\\{\\theta_1\\}\\) として、 \\(p_0(x)\\coloneqq p(x\\mid \\theta_0)\\) と \\(p_1(x)\\coloneqq p(x\\mid \\theta_1)\\) とする。 データから仮説を推定する関数 \\(E\\colon\\mathcal{X}\\to[0,1]\\) を推定関数という。 各 \\(x\\in\\mathcal{X}\\) について、\\(E(x)\\) は帰無仮説を棄却する確率とする。 この推定関数について二種類の誤り確率を \\[\\begin{align*}\n\\alpha_E &\\coloneqq \\expt{E(X)\\mid \\theta_0}\\\\\n\\beta_E &\\coloneqq 1-\\expt{E(X)\\mid \\theta_1}\\\\\n\\end{align*}\\] と定義する。 このとき、\\(\\alpha_E\\) は帰無仮説が正しいときに帰無仮説を棄却する確率であり、第一種誤り確率もしくは有意水準という。 また、\\(\\beta_E\\) は対立仮説が正しいときに帰無仮説を棄却しない確率であり、第二種誤り確率という。 第一種誤り確率だけを小さくしたければ \\(E(x) = 0\\) とすればよいし、第二種誤り確率だけを小さくしたければ \\(E(x)=1\\) とすればよい。"
  },
  {
    "objectID": "slides/06_testings.html#最強力検定",
    "href": "slides/06_testings.html#最強力検定",
    "title": "確率論",
    "section": "最強力検定",
    "text": "最強力検定\n\nDefinition 1 (最強力検定) 検定関数 \\(E\\colon\\mathcal{X}\\to[0,1]\\) が有意水準 \\(\\alpha\\in[0,1]\\) の最強力検定 \\(\\defiff\\) \\(\\alpha_E=\\alpha\\) であり、任意の \\(F\\colon\\mathcal{X}\\to[0,1]\\) について、\\(\\alpha_F\\le\\alpha\\) ならば \\(\\beta_F\\ge\\beta\\) が成り立つ。\n\n実現可能な誤り確率 \\((\\alpha,\\,\\beta)\\) の集合 \\[\\begin{align*}\n\\left\\{(\\alpha_E,\\,\\beta_E)\\mid E\\colon\\mathcal{X}\\to[0,1]\\right\\}\n\\end{align*}\\] について考える。 この集合は凸集合である。 \\[\\begin{align*}\n\\alpha_{pE + (1-p)F} &= p\\alpha_E + (1-p)\\alpha_F,&\n\\beta_{pE + (1-p)F} &= p\\beta_E + (1-p)\\beta_F\n\\end{align*}\\] であることから、 \\[\\begin{align*}\n\\begin{bmatrix}\n\\alpha_{pE + (1-p)F}& \\beta_{pE + (1-p)F}\n\\end{bmatrix}\n&= p \\begin{bmatrix}\\alpha_E&\\beta_E\\end{bmatrix} + (1-p) \\begin{bmatrix}\\alpha_F&\\beta_F\\end{bmatrix}\n\\end{align*}\\] が確認できる。 また、推定結果を反転させた推定関数 \\(1-E(x)\\) を考えると、 \\[\\begin{align*}\n\\begin{bmatrix}\n\\alpha_{1-E}& \\beta_{1-E}\n\\end{bmatrix}&=\n\\begin{bmatrix}\n1&1\n\\end{bmatrix} -\n\\begin{bmatrix}\n\\alpha_{E}& \\beta_{E}\n\\end{bmatrix}\n\\end{align*}\\] である。"
  },
  {
    "objectID": "slides/06_testings.html#実現可能な-alphabeta-の集合と最強力検定",
    "href": "slides/06_testings.html#実現可能な-alphabeta-の集合と最強力検定",
    "title": "確率論",
    "section": "実現可能な \\((\\alpha,\\,\\beta)\\) の集合と最強力検定",
    "text": "実現可能な \\((\\alpha,\\,\\beta)\\) の集合と最強力検定\n\n\n\n\n\n\n\n\nFigure 1: 実現可能な \\((\\alpha,\\,\\beta)\\) の集合の例\n\n\n\n\n\n凸集合であり、\\(\\begin{bmatrix}\\alpha_E&\\beta_E\\end{bmatrix}\\longmapsto\\begin{bmatrix}1&1\\end{bmatrix} - \\begin{bmatrix}\\alpha_E&\\beta_E\\end{bmatrix}\\) に閉じている。\n下側の曲線が最強力検定に対応する。"
  },
  {
    "objectID": "slides/06_testings.html#尤度比検定",
    "href": "slides/06_testings.html#尤度比検定",
    "title": "確率論",
    "section": "尤度比検定",
    "text": "尤度比検定\nベイズ推定の枠組みではMAP推定関数が誤り確率を最小化する推定関数であった。 このMAP推定関数は \\[\\begin{align*}\nE_\\mathrm{MAP}(x) &=\\begin{cases}\n0&\\text{if } \\frac{p(x\\mid\\theta_0)}{p(x\\mid\\theta_1)}\\ge \\frac{\\pi(\\theta_1)}{\\pi(\\theta_0)}\\\\\n1&\\text{otherwise}\n\\end{cases}\n\\end{align*}\\] と表すことができる。\n一般的に \\(\\eta &gt; 0,\\,\\kappa\\in[0,1]\\) について \\[\\begin{align*}\nE(x) &=\\begin{cases}\n0&\\text{if } \\frac{p(x\\mid\\theta_0)}{p(x\\mid\\theta_1)}&gt; \\eta\\\\\n1&\\text{if } \\frac{p(x\\mid\\theta_0)}{p(x\\mid\\theta_1)}&lt; \\eta\\\\\n\\kappa&\\text{otherwise}\n\\end{cases}\n\\end{align*}\\] という形の推定関数を尤度比検定という。"
  },
  {
    "objectID": "slides/06_testings.html#ネイマンピアソンの補題",
    "href": "slides/06_testings.html#ネイマンピアソンの補題",
    "title": "確率論",
    "section": "ネイマン・ピアソンの補題",
    "text": "ネイマン・ピアソンの補題\n\nLemma 1 (ネイマン・ピアソンの補題) 任意の尤度比検定は最強力検定である(逆も成り立つ)。\n\n\nProof. 尤度比検定\\(E\\)における尤度比の閾値を \\(\\eta&gt; 0\\) とする。 任意の \\(F\\colon \\mathcal{X}\\to[0,1]\\) について \\[\\begin{align*}\n&(F(x) - E(x)) (p_0(x) - \\eta p_1(x))\\ge 0\\qquad\\forall x\\in\\mathcal{X}\\\\\n\\iff&F(x)p_0(x) - E(x)p_0(x) - \\eta F(x) p_1(x) + \\eta E(x) p_1(x)\\ge 0\\qquad\\forall x\\in\\mathcal{X}\\\\\n\\implies&\\alpha_F - \\alpha_E - \\eta (1-\\beta_F)  + \\eta (1-\\beta_E)\\ge 0\\\\\n\\iff&(\\alpha_F - \\alpha_E) + \\eta(\\beta_F-\\beta_E)\\ge 0.\n\\end{align*}\\] よって \\(\\alpha_F\\le\\alpha_E\\) ならば \\(\\beta_F\\ge\\beta_E\\) である。\n\nデータ \\(\\mathcal{X}\\) が連続な場合は確率質量関数の代わりに確率密度関数を考える。"
  },
  {
    "objectID": "slides/06_testings.html#今週の課題",
    "href": "slides/06_testings.html#今週の課題",
    "title": "確率論",
    "section": "今週の課題",
    "text": "今週の課題\n\\(\\mathcal{X}=\\{0,\\,1\\},\\, \\Theta=\\left\\{\\theta_0=\\frac12,\\,\\theta_1=\\frac13\\right\\}\\) とし、\\(k\\in\\{0,\\,1\\}\\)について \\[\\begin{align*}\np_k(0)&\\coloneqq p(0\\mid\\theta_k) = 1-\\theta_k&\np_k(1)&\\coloneqq p(1\\mid\\theta_k) = \\theta_k\n\\end{align*}\\] とする。 このとき、 \\(\\eta&gt; 0,\\,\\kappa\\in[0,1]\\)について、以下の尤度比検定関数 \\(E(x)\\) で仮説検定することを考える。 \\[\\begin{align*}\nE(x)&=\n\\begin{cases}\n0&\\text{if } \\frac{p_0(x)}{p_1(x)} &gt; \\eta\\\\\n1&\\text{if } \\frac{p_0(x)}{p_1(x)} &lt; \\eta\\\\\n\\kappa&\\text{otherwise.}\n\\end{cases}\n\\end{align*}\\] 以下の問に答えよ。\n\n\\(\\eta=1\\)のとき\\((\\alpha_E,\\,\\beta_E)\\)をもとめよ。\n一般の \\(\\eta&gt;0\\) と \\(\\kappa\\in[0,1]\\) について、誤り確率 \\((\\alpha_E,\\,\\beta_E)\\) をもとめよ。\\(\\eta\\) の値で場合分けしてもとめること。\n任意の検定関数 \\(E\\colon \\mathcal{X}\\to[0,1]\\)で実現可能な\\((\\alpha_E,\\, \\beta_E)\\)の範囲を図示せよ。"
  }
]