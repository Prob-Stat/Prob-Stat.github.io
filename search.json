[
  {
    "objectID": "slides/02_rv.html#確率空間の公理",
    "href": "slides/02_rv.html#確率空間の公理",
    "title": "確率論",
    "section": "確率空間の公理",
    "text": "確率空間の公理\n確率空間 \\((\\Omega,\\,P)\\) の公理\n\n\\(\\Omega\\colon\\) (非可算でもよい)集合(標本空間)\n\\(P\\colon 2^\\Omega\\to\\mathbb{R}_{\\ge 0}\\) (確率測度)\n\n\n\n\\(P(\\Omega)=1\\). \n\\(\\forall (A_n\\subseteq\\Omega)_{n\\ge 0}\\), \\(\\forall i\\ne j,\\, A_i\\cap A_j=\\varnothing\\implies P\\left(\\bigcup_{n\\ge0} A_n\\right)=\\sum_{n\\ge0} P(A_n)\\) (完全加法性, \\(\\sigma\\)-加法性).\n\n\n\n本当は正しくないけど"
  },
  {
    "objectID": "slides/02_rv.html#確率空間の例",
    "href": "slides/02_rv.html#確率空間の例",
    "title": "確率論",
    "section": "確率空間の例",
    "text": "確率空間の例\n一回のコイン投げ\n\n\n\\(\\Omega = \\{\\mathrm{H},\\mathrm{T}\\}\\).\n\\(P(A) = \\frac{|A|}2\\qquad\\forall A\\subseteq\\Omega\\).\n\n\n二回の独立なコイン投げ\n\n\n\\(\\Omega = \\{\\mathrm{HH},\\mathrm{HT},\\mathrm{TH},\\mathrm{TT}\\}\\).\n\\(P(A) = \\frac{|A|}4\\qquad\\forall A\\subseteq\\Omega\\).\n\n\n実数\n\n\n\\(\\Omega = [0,1)\\).\n\\(P([a,b)) = b-a\\qquad\\forall A\\subseteq\\Omega\\)."
  },
  {
    "objectID": "slides/02_rv.html#確率変数",
    "href": "slides/02_rv.html#確率変数",
    "title": "確率論",
    "section": "確率変数",
    "text": "確率変数\n実際に知りたい情報は限定されている。\n\\(100\\) 回コインを投げると \\(2^{100}\\) 通りの結果があるが、興味がある情報は例えば以下のものがある。\n\n\n\\(k\\) 回目に表が出たか裏が出たか\n表が出た回数\n二回連続同じ面が出た回数\n連続して何回表が出たか\n\n\n\n確率変数\n\\((\\Omega,\\,P)\\) を確率空間とするとき、関数 \\(X\\colon \\Omega\\to\\mathbb{R}\\) を確率変数とよぶ。 また、実数 \\(a\\in\\mathbb{R}\\) について \\[\\begin{align*}\n\\Pr(X\\le a) &\\coloneqq P(\\left\\{\\omega\\in\\Omega\\mid X(\\omega)\\le a\\right\\})\n\\end{align*}\\] と表す。 \\(\\Pr(X\\ge a),\\,\\Pr(X=a),\\,\\Pr(X&lt;a),\\,\\Pr(X&gt;a)\\) なども同様に定義される。\n\n\n例えば、\\(\\Omega=\\{\\mathrm{HH},\\mathrm{HT},\\mathrm{TH},\\mathrm{TT}\\}\\) のとき、.\n\\[\\begin{align*}\nX_1(\\mathrm{HH}) &= X_1(\\mathrm{HT}) = 1,& X_1(\\mathrm{TH}) = X_1(\\mathrm{TT}) = 0\\\\\nX_2(\\mathrm{HH}) &= X_2(\\mathrm{TH}) = 1,& X_2(\\mathrm{HT}) = X_2(\\mathrm{TT}) = 0\\\\\nX&=X_1+X_2\n\\end{align*}\\]"
  },
  {
    "objectID": "slides/02_rv.html#累積分布関数",
    "href": "slides/02_rv.html#累積分布関数",
    "title": "確率論",
    "section": "累積分布関数",
    "text": "累積分布関数\n確率変数 \\(X\\) の累積分布関数 (cumulative distribution function)\n\\[\\begin{align*}\nF_X(x) &\\coloneqq \\Pr(X\\le x)\\qquad\\forall x\\in\\mathbb{R}\n\\end{align*}\\]\n累積分布関数は定義より単調非減少関数であることが分かる。 累積分布関数は連続とは限らないが右連続であることは以下のように確認できる。\n\\[\\begin{align*}\n\\lim_{n\\to\\infty} \\Pr\\left(X \\le x + \\frac1n\\right) &=\n\\lim_{n\\to\\infty} P\\left(\\left\\{\\omega\\in\\Omega\\mid X(\\omega) \\le x + \\frac1n\\right\\}\\right)\\\\\n&= P\\left(\\bigcap_{n=1}^\\infty \\left\\{\\omega\\in\\Omega\\mid X(\\omega) \\le x + \\frac1n\\right\\}\\right)\\\\\n&= P\\left(\\left\\{\\omega\\in\\Omega\\mid X(\\omega) \\le x\\right\\}\\right)\\\\\n&= \\Pr\\left(X\\le x\\right).\n\\end{align*}\\]\n累積分布関数は以下の性質を持つ。\n\n\\(F_X\\) は単調非減少。\n\\(F_X\\) は右連続。\n\\(\\lim_{x\\to\\infty}F_X(x) = 1\\).\n\\(\\lim_{x\\to-\\infty}F_X(x) = 0\\).\n\n逆にこれらの性質を満たしていれば、何かしらの確率変数 \\(X\\) の累積分布関数とみなせる。"
  },
  {
    "objectID": "slides/02_rv.html#累積分布関数の例",
    "href": "slides/02_rv.html#累積分布関数の例",
    "title": "確率論",
    "section": "累積分布関数の例",
    "text": "累積分布関数の例\n二項分布 \\(\\mathrm{Binomial}(n,p)\\colon\\) 表が出る確率が \\(p\\in[0,1]\\) のコインを独立に \\(n\\) 回投げて表が出る回数\n\\[\\begin{align*}\n\\Pr(X=k) &= \\binom{n}{k} p^k(1-p)^{n-k}\\qquad\\forall k\\in\\{0,1,\\dotsc,n\\}\\\\\nF_X(k) &= \\sum_{i=0}^k \\binom{n}{i} p^i(1-p)^{n-i}.\n\\end{align*}\\]\n\n\n\n\n\n\n\n\n\nFigure 1: 二項分布の累積分布関数"
  },
  {
    "objectID": "slides/02_rv.html#離散型確率変数",
    "href": "slides/02_rv.html#離散型確率変数",
    "title": "確率論",
    "section": "離散型確率変数",
    "text": "離散型確率変数\n離散型確率変数: 像が高々可算無限の確率変数\n任意の \\(A\\subseteq\\mathrm{Image}(X)\\) について、 \\[\\begin{align*}\n\\Pr(X\\in A) &= P\\left(\\{\\omega\\in\\Omega\\mid X(\\omega)\\in A\\}\\right)\\\\\n&= P\\left(\\bigcup_{x\\in A} \\{\\omega\\in\\Omega\\mid X(\\omega)=x\\}\\right)\\\\\n&= \\sum_{x\\in A} P\\left(\\{\\omega\\in\\Omega\\mid X(\\omega)=x\\}\\right)\\\\\n&= \\sum_{x\\in A} \\Pr\\left(X=x\\right)\n\\end{align*}\\]\n確率質量関数 (probability mass function) \\[\\begin{align*}\nf_X(x)&\\coloneqq \\Pr(X=x)\\qquad\\forall x\\in\\mathbb{R}.\n\\end{align*}\\]\nすると \\[\\begin{align*}\n\\Pr(X\\in A) &= \\sum_{x\\in A} f_X(x).\n\\end{align*}\\]"
  },
  {
    "objectID": "slides/02_rv.html#確率質量関数の例",
    "href": "slides/02_rv.html#確率質量関数の例",
    "title": "確率論",
    "section": "確率質量関数の例",
    "text": "確率質量関数の例\n二項分布 \\(\\mathrm{Binomial}(n,p)\\colon\\)\n\\[\\begin{align*}\nf_X(k) &= \\binom{n}{k} p^k(1-p)^{n-k}.\n\\end{align*}\\]\n\n\n\n\n\n\n\n\n\nFigure 2: 二項分布の確率質量関数"
  },
  {
    "objectID": "slides/02_rv.html#連続型確率変数",
    "href": "slides/02_rv.html#連続型確率変数",
    "title": "確率論",
    "section": "連続型確率変数",
    "text": "連続型確率変数\n連続型確率変数: 離散型確率変数でない確率変数\n確率密度関数 (probability density function) \\[\\begin{align*}\n\\Pr(X\\in A) &= \\int_{A} f_X(x) \\mathrm{d}x.\n\\end{align*}\\] を満たす関数 \\(f_X\\colon\\mathbb{R}\\to\\mathbb{R}_{\\ge 0}\\). 離散確率変数に対する \\[\\begin{align*}\n\\Pr(X\\in A) &= \\sum_{x\\in A} f_X(x)\n\\end{align*}\\]\nと同じ形。 一般的には確率密度関数は存在するとは限らない。\n累積分布関数 \\(F_X(x)\\) が微分可能なとき、 \\[\\begin{align*}\nf_X(x) &= \\frac{\\mathrm{d} F_X}{\\mathrm{d}x}\n\\end{align*}\\]\nとおくと \\[\\begin{align*}\n\\int_{-\\infty}^x f_X(z) \\mathrm{d}z &= F_X(x)\n\\end{align*}\\] を満たす。 累積分布関数が連続で微分不可能な点が飛び飛びにある場合も確率密度関数は \\(f_X = F_X'\\) と取れる。 累積分布関数が微分不可能な点は確率密度関数の値を任意に決めてよい。"
  },
  {
    "objectID": "slides/02_rv.html#連続確率変数の例",
    "href": "slides/02_rv.html#連続確率変数の例",
    "title": "確率論",
    "section": "連続確率変数の例",
    "text": "連続確率変数の例\n正規分布(ガウス分布) \\(N(\\mu,\\sigma^2)\\colon\\)\n\\[\\begin{align*}\nf_X(x) &= \\frac1{\\sqrt{2\\pi\\sigma^2}}\\mathrm{e}^{-\\frac{(x-\\mu)^2}{2\\sigma^2}},&\nF_X(x) &= \\int_{-\\infty}^x \\frac1{\\sqrt{2\\pi\\sigma^2}}\\mathrm{e}^{-\\frac{(z-\\mu)^2}{2\\sigma^2}}\\mathrm{d}z\n\\end{align*}\\]\n特に \\(\\mu=0\\), \\(\\sigma=1\\) のとき標準正規分布という。\n\n\n\n\n\n\n\n\n\nFigure 3: 標準正規分布の確率密度関数\n\n\n\n\n\n\n\n\n\n\n\nFigure 4: 標準正規分布の累積分布関数"
  },
  {
    "objectID": "slides/02_rv.html#離散確率変数の例",
    "href": "slides/02_rv.html#離散確率変数の例",
    "title": "確率論",
    "section": "離散確率変数の例",
    "text": "離散確率変数の例\n\n二項分布 \\(\\mathrm{Binomial}(n,p)\\): 表が出る確率が \\(p\\) のコインを \\(n\\) 回独立に投げたとき、表が出る回数の分布 \\[\\Pr(X=k) = \\binom{n}{k} p^k (1-p)^{n-k}.\\]\n幾何分布 \\(\\mathrm{Geometric}(p)\\): 表が出るまでに投げるコインの回数の分布 \\[\\Pr(X=k) = (1-p)^{k-1}p.\\]\n超幾何分布 \\(\\mathrm{HyperGeometric}(N,K,n)\\): 袋の中に \\(N\\) 個のボールがあって、そのうち \\(K\\) 個が当たりとし、 \\(n\\) 個引いたときの当たりの個数の分布 \\[\\Pr(X=k) = \\frac{\\binom{K}{k}\\binom{N-K}{n-k}}{\\binom{N}{n}}.\\]\nポアソン分布 \\(\\mathrm{Poisson}(\\lambda)\\): \\[\n\\Pr(X=k) = \\frac{\\lambda^k}{k!}\\mathrm{e}^{-\\lambda}.\n\\]"
  },
  {
    "objectID": "slides/02_rv.html#幾何分布",
    "href": "slides/02_rv.html#幾何分布",
    "title": "確率論",
    "section": "幾何分布",
    "text": "幾何分布\n幾何分布 \\(\\mathrm{Geometric}(p)\\): 表が出る確率が \\(p\\in[0,1]\\) のコインを独立に何度も投げて表が出るまでに投げる回数\n\\[\nf_X(k) = (1-p)^{k-1}p,\\qquad\\forall k\\ge 1\n\\]\n\n\n\n\n\n\n\n\n\nFigure 5: 幾何分布の確率質量関数\n\n\n\n\n\n\n\n\n\n\n\nFigure 6: 幾何分布の累積分布関数"
  },
  {
    "objectID": "slides/02_rv.html#超幾何分布",
    "href": "slides/02_rv.html#超幾何分布",
    "title": "確率論",
    "section": "超幾何分布",
    "text": "超幾何分布\n超幾何分布 \\(\\mathrm{HyperGeometric}(N,K,n)\\): 袋の中に \\(N\\) 個のボールがあって、そのうち \\(K\\) 個が当たりとし、 \\(n\\) 個引いたときの当たりの個数\n\\[\nf_X(k) = \\frac{\\binom{K}{k}\\binom{N-K}{n-k}}{\\binom{N}{n}},\\qquad\\forall k\\in \\{0,\\dotsc,\\min\\{K, n\\}\\}\n\\]\n\n\n\n\n\n\n\n\n\nFigure 7: 超幾何分布の確率質量関数\n\n\n\n\n\n\n\n\n\n\n\nFigure 8: 超幾何分布の累積分布関数"
  },
  {
    "objectID": "slides/02_rv.html#ポアソン分布",
    "href": "slides/02_rv.html#ポアソン分布",
    "title": "確率論",
    "section": "ポアソン分布",
    "text": "ポアソン分布\n正のパラメータ \\(\\lambda\\in\\mathbb{R}_{&gt;0}\\) について、ポアソン分布 \\(\\mathrm{Poisson}(\\lambda)\\) の確率質量関数は\n\\[\nf_X(k) = \\frac{\\lambda^k}{k!}\\mathrm{e}^{-\\lambda},\\qquad \\forall k\\ge 0.\n\\]\n\n\n\n\n\n\n\n\n\nFigure 9: ポアソン分布の確率質量関数\n\n\n\n\n\n\n\n\n\n\n\nFigure 10: ポアソン分布の累積分布関数"
  },
  {
    "objectID": "slides/02_rv.html#一様分布",
    "href": "slides/02_rv.html#一様分布",
    "title": "確率論",
    "section": "一様分布",
    "text": "一様分布\n実数 \\(a&lt;b\\) について、一様分布 \\(\\mathrm{U}(a,b)\\) の確率密度関数と累積分布関数は\n\\[\\begin{align*}\nf_X(x) &= \\begin{cases}\n\\frac1{b-a}& \\text{if } x\\in[a,b]\\\\\n0&\\text{otherwise}\n\\end{cases},&\nF_X(x) &= \\begin{cases}\n0&\\text{if } x &lt; a\\\\\n\\frac{x-a}{b-a}&\\text{if } x \\in[a,b]\\\\\n1&\\text{otherwise.}\n\\end{cases}\n\\end{align*}\\]\n\n\n\n\n\n\n\n\n\nFigure 11: 一様分布の確率密度関数\n\n\n\n\n\n\n\n\n\n\n\nFigure 12: 一様分布の累積分布関数"
  },
  {
    "objectID": "slides/02_rv.html#正規分布-ガウス分布",
    "href": "slides/02_rv.html#正規分布-ガウス分布",
    "title": "確率論",
    "section": "正規分布 (ガウス分布)",
    "text": "正規分布 (ガウス分布)\nパラメータ \\(\\mu\\in\\mathbb{R},\\,\\sigma\\in\\mathbb{R}_{&gt;0}\\) について、正規分布 \\(N(\\mu,\\sigma^2)\\) の確率密度関数と累積分布関数は \\[\\begin{align*}\nf_X(x) &= \\frac1{\\sqrt{2\\pi\\sigma^2}}\\mathrm{e}^{-\\frac{(x-\\mu)^2}{2\\sigma^2}},&\nF_X(x) &= \\int_{-\\infty}^x \\frac1{\\sqrt{2\\pi\\sigma^2}}\\mathrm{e}^{-\\frac{(z-\\mu)^2}{2\\sigma^2}}\\mathrm{d}z.\n\\end{align*}\\]\n特に \\(\\mu=0\\), \\(\\sigma=1\\) のとき標準正規分布という。\n\n\n\n\n\n\n\n\n\nFigure 13: 標準正規分布の確率密度関数\n\n\n\n\n\n\n\n\n\n\n\nFigure 14: 標準正規分布の累積分布関数"
  },
  {
    "objectID": "slides/02_rv.html#指数分布",
    "href": "slides/02_rv.html#指数分布",
    "title": "確率論",
    "section": "指数分布",
    "text": "指数分布\nパラメータ \\(\\lambda\\in\\mathbb{R}_{&gt;0}\\) について、指数分布 \\(\\mathrm{Exp}(\\lambda)\\) の確率密度関数と累積分布関数は\n\\[\\begin{align*}\nf_X(x) &= \\begin{cases}\n0&\\text{if } x &lt; 0\\\\\n\\lambda\\mathrm{e}^{-\\lambda x}&\\text{otherwise}\n\\end{cases},&\nF_X(x) &= \\begin{cases}\n0&\\text{if } x &lt; 0\\\\\n1-\\mathrm{e}^{-\\lambda x}&\\text{otherwise}\n\\end{cases}\n\\end{align*}\\]\n\n\n\n\n\n\n\n\n\nFigure 15: 指数分布の確率密度関数\n\n\n\n\n\n\n\n\n\n\n\nFigure 16: 指数分布の累積分布関数"
  },
  {
    "objectID": "slides/02_rv.html#確率変数確率分布確率空間",
    "href": "slides/02_rv.html#確率変数確率分布確率空間",
    "title": "確率論",
    "section": "確率変数、確率分布、確率空間",
    "text": "確率変数、確率分布、確率空間\n確率変数 \\(X\\) の累積分布関数が○○分布の累積分布関数と等しいとき、 「確率変数 \\(X\\) は○○分布に従う」という。\n例えば「確率変数 \\(X\\) は二項分布 \\(\\mathrm{Binomial}(n,p)\\) に従う」という。 このとき、\\(X\\sim\\mathrm{Binomial}(n,p)\\) と表す。\n\n確率空間を陽に定義しないで確率変数を考えることも多い。 確率変数が特定の値を取る確率を解析したいときには確率空間の定義は不要。\n\n離散型確率変数は自然に説明できるものが多いので、自然な確率空間を考えることができることが多い。\n\n二項分布: \\(n\\) 回のコイン投げ、もしくは無限回のコイン投げ。\n幾何分布: 無限回のコイン投げ。\n超幾何分布: \\(K\\) 個の当たりと \\(N-K\\) 個のはずれのボールの \\(\\binom{N}{K}\\) 通りの並び順。\nポアソン分布: ？\n\n\n今後は主に確率変数を用いた確率の解析をしていく。 確率空間を陽に考えることは少ない。"
  },
  {
    "objectID": "slides/02_rv.html#xa-の確率密度関数",
    "href": "slides/02_rv.html#xa-の確率密度関数",
    "title": "確率論",
    "section": "\\(X+a\\) の確率密度関数",
    "text": "\\(X+a\\) の確率密度関数\n\nLemma 1 確率密度関数を持つ任意の確率変数 \\(X\\) と \\(a\\in\\mathbb{R}\\) について、 \\[\\begin{align*}\nf_{X+a}(x) &= f_X(x-a)\n\\end{align*}\\] は \\(X+a\\) の確率密度関数になる。\n\n\nProof. 関数 \\(f_Z\\colon \\mathbb{R}\\to\\mathbb{R}_{\\ge 0}\\) が\n\\[\n\\Pr(Z\\le x) = \\int_{-\\infty}^x f_Z(z)\\mathrm{d} z\n\\]\nを満たすとき、\\(f_Z\\) は確率変数 \\(Z\\) の確率密度関数となる。\n任意の \\(a\\in\\mathbb{R}\\) について、 \\[\\begin{align*}\n\\Pr(X+a\\le x) &= \\Pr(X\\le x-a)\\\\\n&= \\int_{-\\infty}^{x-a} f_{X}(z)\\mathrm{d}z\\\\\n&= \\int_{-\\infty}^{x} f_{X}(z'-a)\\mathrm{d}z'\\qquad (z'=z+a).\n\\end{align*}\\]"
  },
  {
    "objectID": "slides/02_rv.html#ax-の確率密度関数",
    "href": "slides/02_rv.html#ax-の確率密度関数",
    "title": "確率論",
    "section": "\\(aX\\) の確率密度関数",
    "text": "\\(aX\\) の確率密度関数\n\nLemma 2 確率密度関数を持つ任意の確率変数 \\(X\\) と \\(a\\in\\mathbb{R}_{\\ne 0}\\) について、 \\[\\begin{align*}\nf_{aX}(x) &= \\frac1{|a|} f_X(x/a)\n\\end{align*}\\] は \\(aX\\) の確率密度関数になる。\n\n\nProof. 関数 \\(f_Z\\colon \\mathbb{R}\\to\\mathbb{R}_{\\ge 0}\\) が\n\\[\n\\Pr(Z\\le x) = \\int_{-\\infty}^x f_Z(z)\\mathrm{d} z\n\\]\nを満たすとき、\\(f_Z\\) は確率変数 \\(Z\\) の確率密度関数となる。\n任意の \\(a&gt;0\\) について、 \\[\\begin{align*}\n\\Pr(aX\\le x) &= \\Pr(X\\le x/a)\\\\\n&= \\int_{-\\infty}^{x/a} f_{X}(z)\\mathrm{d}z\\\\\n&= \\int_{-\\infty}^{x} \\frac1{a} f_{X}(z'/a)\\mathrm{d}z'\\qquad (z'=az).\n\\end{align*}\\] \\(a&lt;0\\) についても同様。"
  },
  {
    "objectID": "slides/02_rv.html#gx-の確率密度関数",
    "href": "slides/02_rv.html#gx-の確率密度関数",
    "title": "確率論",
    "section": "\\(g(X)\\) の確率密度関数",
    "text": "\\(g(X)\\) の確率密度関数\n\nLemma 3 \\(J\\subseteq\\mathbb{R}\\) を有界とは限らない区間とし、\\(g\\colon J\\to\\mathbb{R}\\) を \\(J\\) の内点で微分可能で \\(g'(x)&gt;0\\) とする。 確率変数 \\(X\\) が \\(\\Pr(X\\in J) = 1\\) を満たし確率密度関数を持つとき、 \\[\\begin{align*}\nf_{g(X)}(x) &=\n\\begin{cases}\n\\frac1{g'(g^{-1}(x))} f_X(g^{-1}(x))&\\text{if } x\\in\\mathrm{Image}(g)\\\\\n0&\\text{otherwise}\n\\end{cases}\n\\end{align*}\\] は \\(g(X)\\) の確率密度関数になる。\n\n\nProof. \\(\\Pr(g(X)\\in\\mathrm{Image}(g)) = 1\\) なので、\\(x\\notin\\mathrm{Image}(g)\\) について \\(f_{g(X)}(x) = 0\\) とおいてよい。\n任意の \\(x\\in\\mathrm{Image}(g)\\) について \\[\\begin{align*}\n\\Pr(g(X)\\le x) &= \\Pr(X\\le g^{-1}(x))\\\\\n&= \\int_{-\\infty}^{g^{-1}(x)} f_{X}(z)\\mathrm{d}z\\\\\n&= \\int_{\\inf J}^{g^{-1}(x)} f_{X}(z)\\mathrm{d}z\\\\\n&= \\int_{\\inf \\mathrm{Image}(g)}^{x} f_{X}(g^{-1}(z')) \\frac1{g'(g^{-1}(z'))}\\mathrm{d}z'\\qquad (z'=g(z))\\\\\n&= \\int_{-\\infty}^{x} f_{g(X)}(z')\\mathrm{d}z'.\n\\end{align*}\\]"
  },
  {
    "objectID": "slides/02_rv.html#今週の課題",
    "href": "slides/02_rv.html#今週の課題",
    "title": "確率論",
    "section": "今週の課題",
    "text": "今週の課題\n以下の問に答えよ\n\n\n\\(\\Pr(X=1) = 0.2,\\,\\Pr(X=2)=0.1,\\,\\Pr(X=3)=0.7\\) を満たす確率変数 \\(X\\) の累積分布関数 \\(F_X(x)\\) を \\([0,4]\\) の区間で図示せよ。不連続点で取る値が分かるようにすること。\n\\(U\\sim\\mathrm{U}(0,1)\\) とする。このとき、\\(-2\\log U\\) の確率密度関数をもとめよ。すべての \\(x\\in\\mathbb{R}\\) に対する値を示すこと。"
  },
  {
    "objectID": "slides/06_testings.html#事前分布を仮定しない推定問題",
    "href": "slides/06_testings.html#事前分布を仮定しない推定問題",
    "title": "確率論",
    "section": "事前分布を仮定しない推定問題",
    "text": "事前分布を仮定しない推定問題\nベイズ推定では推定したいパラメータ \\(\\theta\\in\\Theta\\) の事前分布 \\(\\pi(\\theta)\\) を既知として仮定した。\nしかし、現実の問題ではこの事前分布を適切に仮定する方法がない場合もある。\n\n開発中の薬に効果があるかないか\nある患者が病気かどうか\nサイコロに偏りがあるかどうか\n\nといった問題について事前分布をどのように仮定するのが適切か不明瞭である。\n尤度 \\(p(x\\mid\\theta)\\) は既知とし、事前分布は既知でないときに データ \\(x\\in\\mathcal{X}\\) から パラメータ \\(\\theta\\in\\Theta\\) を推定する問題を考える。"
  },
  {
    "objectID": "slides/06_testings.html#伝統的な仮説検定",
    "href": "slides/06_testings.html#伝統的な仮説検定",
    "title": "確率論",
    "section": "伝統的な仮説検定",
    "text": "伝統的な仮説検定\nパラメータの集合を二つの部分集合 \\(H_0\\) と \\(H_1\\) に分割する。 つまり、\\(H_0\\cup H_1 = \\Theta\\), \\(H_0\\cap H_1=\\varnothing\\) である。\nそしてパラメータが \\(H_0\\) に属するか \\(H_1\\) に属するかを知りたいとする。 この二つの集合 \\(H_0\\) と \\(H_1\\) を仮説という。\nその二つの仮説のうちの通常成り立っていると考える方を \\(H_0\\) とし 帰無仮説と呼ぶ。 また、そうでない方を \\(H_1\\) とし 対立仮説と呼ぶ。\n帰無仮説の例として\n\n開発中の薬に効果はない\nある患者が病気ではない\nサイコロに偏りはない\n\nなどがある。 それらに対応する対立仮説はそれぞれ\n\n開発中の薬に効果がある\nある患者が病気である\nサイコロに偏りがある\n\nとなる。 仮説検定の考え方では帰無仮説を棄却するかしないかを決める。 帰無仮説を棄却した場合、対立仮説を正しいと考え、帰無仮説を棄却しなかった場合は何も言えないと結論づける。"
  },
  {
    "objectID": "slides/06_testings.html#単純仮説",
    "href": "slides/06_testings.html#単純仮説",
    "title": "確率論",
    "section": "単純仮説",
    "text": "単純仮説\n仮説 \\(H_0\\) と \\(H_1\\) がそれぞれ一元集合であるとき、それらを単純仮説という。 \\(H_0=\\{\\theta_0\\}\\), \\(H_1=\\{\\theta_1\\}\\) として、 \\(p_0(x)\\coloneqq p(x\\mid \\theta_0)\\) と \\(p_1(x)\\coloneqq p(x\\mid \\theta_1)\\) とする。 データから仮説を推定する関数 \\(E\\colon\\mathcal{X}\\to[0,1]\\) を推定関数という。 各 \\(x\\in\\mathcal{X}\\) について、\\(E(x)\\) は帰無仮説を棄却する確率とする。 この推定関数について二種類の誤り確率を \\[\\begin{align*}\n\\alpha_E &\\coloneqq \\expt{E(X)\\mid \\theta_0}\\\\\n\\beta_E &\\coloneqq 1-\\expt{E(X)\\mid \\theta_1}\\\\\n\\end{align*}\\] と定義する。 このとき、\\(\\alpha_E\\) は帰無仮説が正しいときに帰無仮説を棄却する確率であり、第一種誤り確率もしくは有意水準という。 また、\\(\\beta_E\\) は対立仮説が正しいときに帰無仮説を棄却しない確率であり、第二種誤り確率という。 第一種誤り確率だけを小さくしたければ \\(E(x) = 0\\) とすればよいし、第二種誤り確率だけを小さくしたければ \\(E(x)=1\\) とすればよい。"
  },
  {
    "objectID": "slides/06_testings.html#最強力検定",
    "href": "slides/06_testings.html#最強力検定",
    "title": "確率論",
    "section": "最強力検定",
    "text": "最強力検定\n\nDefinition 1 (最強力検定) 検定関数 \\(E\\colon\\mathcal{X}\\to[0,1]\\) が有意水準 \\(\\alpha\\in[0,1]\\) の最強力検定 \\(\\defiff\\) \\(\\alpha_E=\\alpha\\) であり、任意の \\(F\\colon\\mathcal{X}\\to[0,1]\\) について、\\(\\alpha_F\\le\\alpha\\) ならば \\(\\beta_F\\ge\\beta\\) が成り立つ。\n\n実現可能な誤り確率 \\((\\alpha,\\,\\beta)\\) の集合 \\[\\begin{align*}\n\\left\\{(\\alpha_E,\\,\\beta_E)\\mid E\\colon\\mathcal{X}\\to[0,1]\\right\\}\n\\end{align*}\\] について考える。 この集合は凸集合である。 \\[\\begin{align*}\n\\alpha_{pE + (1-p)F} &= p\\alpha_E + (1-p)\\alpha_F,&\n\\beta_{pE + (1-p)F} &= p\\beta_E + (1-p)\\beta_F\n\\end{align*}\\] であることから、 \\[\\begin{align*}\n\\begin{bmatrix}\n\\alpha_{pE + (1-p)F}& \\beta_{pE + (1-p)F}\n\\end{bmatrix}\n&= p \\begin{bmatrix}\\alpha_E&\\beta_E\\end{bmatrix} + (1-p) \\begin{bmatrix}\\alpha_F&\\beta_F\\end{bmatrix}\n\\end{align*}\\] が確認できる。 また、推定結果を反転させた推定関数 \\(1-E(x)\\) を考えると、 \\[\\begin{align*}\n\\begin{bmatrix}\n\\alpha_{1-E}& \\beta_{1-E}\n\\end{bmatrix}&=\n\\begin{bmatrix}\n1&1\n\\end{bmatrix} -\n\\begin{bmatrix}\n\\alpha_{E}& \\beta_{E}\n\\end{bmatrix}\n\\end{align*}\\] である。"
  },
  {
    "objectID": "slides/06_testings.html#実現可能な-alphabeta-の集合と最強力検定",
    "href": "slides/06_testings.html#実現可能な-alphabeta-の集合と最強力検定",
    "title": "確率論",
    "section": "実現可能な \\((\\alpha,\\,\\beta)\\) の集合と最強力検定",
    "text": "実現可能な \\((\\alpha,\\,\\beta)\\) の集合と最強力検定\n\n\n\n\n\n\n\n\nFigure 1: 実現可能な \\((\\alpha,\\,\\beta)\\) の集合の例\n\n\n\n\n\n凸集合であり、\\(\\begin{bmatrix}\\alpha_E&\\beta_E\\end{bmatrix}\\longmapsto\\begin{bmatrix}1&1\\end{bmatrix} - \\begin{bmatrix}\\alpha_E&\\beta_E\\end{bmatrix}\\) に閉じている。\n下側の曲線が最強力検定に対応する。"
  },
  {
    "objectID": "slides/06_testings.html#尤度比検定",
    "href": "slides/06_testings.html#尤度比検定",
    "title": "確率論",
    "section": "尤度比検定",
    "text": "尤度比検定\nベイズ推定の枠組みではMAP推定関数が誤り確率を最小化する推定関数であった。 このMAP推定関数は \\[\\begin{align*}\nE_\\mathrm{MAP}(x) &=\\begin{cases}\n0&\\text{if } \\frac{p(x\\mid\\theta_0)}{p(x\\mid\\theta_1)}\\ge \\frac{\\pi(\\theta_1)}{\\pi(\\theta_0)}\\\\\n1&\\text{otherwise}\n\\end{cases}\n\\end{align*}\\] と表すことができる。\n一般的に \\(\\eta &gt; 0,\\,\\kappa\\in[0,1]\\) について \\[\\begin{align*}\nE(x) &=\\begin{cases}\n0&\\text{if } \\frac{p(x\\mid\\theta_0)}{p(x\\mid\\theta_1)}&gt; \\eta\\\\\n1&\\text{if } \\frac{p(x\\mid\\theta_0)}{p(x\\mid\\theta_1)}&lt; \\eta\\\\\n\\kappa&\\text{otherwise}\n\\end{cases}\n\\end{align*}\\] という形の推定関数を尤度比検定という。"
  },
  {
    "objectID": "slides/06_testings.html#ネイマンピアソンの補題",
    "href": "slides/06_testings.html#ネイマンピアソンの補題",
    "title": "確率論",
    "section": "ネイマン・ピアソンの補題",
    "text": "ネイマン・ピアソンの補題\n\nLemma 1 (ネイマン・ピアソンの補題) 任意の尤度比検定は最強力検定である(逆も成り立つ)。\n\n\nProof. 尤度比検定\\(E\\)における尤度比の閾値を \\(\\eta&gt; 0\\) とする。 任意の \\(F\\colon \\mathcal{X}\\to[0,1]\\) について \\[\\begin{align*}\n&(F(x) - E(x)) (p_0(x) - \\eta p_1(x))\\ge 0\\qquad\\forall x\\in\\mathcal{X}\\\\\n\\iff&F(x)p_0(x) - E(x)p_0(x) - \\eta F(x) p_1(x) + \\eta E(x) p_1(x)\\ge 0\\qquad\\forall x\\in\\mathcal{X}\\\\\n\\implies&\\alpha_F - \\alpha_E - \\eta (1-\\beta_F)  + \\eta (1-\\beta_E)\\ge 0\\\\\n\\iff&(\\alpha_F - \\alpha_E) + \\eta(\\beta_F-\\beta_E)\\ge 0.\n\\end{align*}\\] よって \\(\\alpha_F\\le\\alpha_E\\) ならば \\(\\beta_F\\ge\\beta_E\\) である。\n\nデータ \\(\\mathcal{X}\\) が連続な場合は確率質量関数の代わりに確率密度関数を考える。"
  },
  {
    "objectID": "slides/06_testings.html#今週の課題",
    "href": "slides/06_testings.html#今週の課題",
    "title": "確率論",
    "section": "今週の課題",
    "text": "今週の課題\n\\(\\mathcal{X}=\\{0,\\,1\\},\\, \\Theta=\\left\\{\\theta_0=\\frac12,\\,\\theta_1=\\frac13\\right\\}\\) とし、\\(k\\in\\{0,\\,1\\}\\)について \\[\\begin{align*}\np_k(0)&\\coloneqq p(0\\mid\\theta_k) = 1-\\theta_k&\np_k(1)&\\coloneqq p(1\\mid\\theta_k) = \\theta_k\n\\end{align*}\\] とする。 このとき、 \\(\\eta&gt; 0,\\,\\kappa\\in[0,1]\\)について、以下の尤度比検定関数 \\(E(x)\\) で仮説検定することを考える。 \\[\\begin{align*}\nE(x)&=\n\\begin{cases}\n0&\\text{if } \\frac{p_0(x)}{p_1(x)} &gt; \\eta\\\\\n1&\\text{if } \\frac{p_0(x)}{p_1(x)} &lt; \\eta\\\\\n\\kappa&\\text{otherwise.}\n\\end{cases}\n\\end{align*}\\] 以下の問に答えよ。\n\n\\(\\eta=1\\)のとき\\((\\alpha_E,\\,\\beta_E)\\)をもとめよ。\n一般の \\(\\eta&gt;0\\) と \\(\\kappa\\in[0,1]\\) について、誤り確率 \\((\\alpha_E,\\,\\beta_E)\\) をもとめよ。\\(\\eta\\) の値で場合分けしてもとめること。\n任意の検定関数 \\(E\\colon \\mathcal{X}\\to[0,1]\\)で実現可能な\\((\\alpha_E,\\, \\beta_E)\\)の範囲を図示せよ。"
  },
  {
    "objectID": "slides/10_markov.html#確率過程とマルコフ連鎖",
    "href": "slides/10_markov.html#確率過程とマルコフ連鎖",
    "title": "確率論",
    "section": "確率過程とマルコフ連鎖",
    "text": "確率過程とマルコフ連鎖\n共通の確率空間 \\((\\Omega,\\,P)\\) 上の長さ無限の確率変数列 \\(X_0,X_1,X_2,\\dotsc\\) を離散時間確率過程という。 各時刻 \\(t=0,1,2,\\dotsc,\\) について、 \\(X_t\\) を時刻 \\(t\\) における状態と考える。\n離散時間確率過程 \\(X_0,X_1,\\dotsc,\\) の各確率変数の像が有限集合 \\(S\\) であり、 任意の \\(t\\in\\mathbb{Z}_{\\ge 0}\\) と \\(x_0,\\dotsc, x_{t+1}\\in S\\) について \\[\\begin{align*}\n\\Pr(X_{t+1} = x_{t+1}\\mid X_{t} = x_t,\\dotsc,\\,X_1=x_1,\\,X_0=x_0)\n&= \\Pr(X_{t+1} = x\\mid X_{t} = x_t)\n\\end{align*}\\] を満たすとき、それを有限状態マルコフ連鎖という。 さらに、 \\[\\begin{align*}\n\\Pr(X_{t+1} = x_{t+1}\\mid X_{t} = x_t)\n\\end{align*}\\] が \\(t\\in\\mathbb{Z}_{\\ge 0}\\) に依存しないとき時間的に均一な有限状態マルコフ連鎖という。 以下では時間的に均一な有限状態マルコフ連鎖を考える。"
  },
  {
    "objectID": "slides/10_markov.html#確率行列と状態遷移図",
    "href": "slides/10_markov.html#確率行列と状態遷移図",
    "title": "確率論",
    "section": "確率行列と状態遷移図",
    "text": "確率行列と状態遷移図\n有限状態マルコフ連鎖の場合、状態 \\(S\\) は実数の有限部分集合と考えるより、単に有限集合と考えた方が自然な場合も多い。 例えば \\(S = \\{ 晴れ、曇り、雨\\}\\) という例が考えられる。 このとき、状態集合を便宜上 \\(S=\\{1,2,\\dotsc,n\\}\\) とおき、 \\[\\begin{align*}\np_{i,j} &= \\Pr(X_{t+1} = j\\mid X_{t} = i)\\qquad \\forall i,\\,j\\in S\n\\end{align*}\\] とする。 この \\(p_{i,j}\\) を \\((i,j)\\) 成分に持つ \\(n\\times n\\) 行列 \\(T\\) を遷移行列という。 遷移行列は非負行列であり、行和が1である。 一般に、この二つの条件を満たす正方行列を確率行列という。 確率行列は遷移行列とみなすことができる。\n一方で、初期確率(時刻0における確率)からなる行ベクトル \\(\\pi\\in\\mathbb{R}^{|S|}\\) を初期状態ベクトルという。 つまり、行ベクトル \\(\\pi\\) の \\(i\\in S\\) 成分を \\(\\pi_i\\) とすると、 \\[\\begin{align*}\n\\pi_i &= \\Pr(X_0=i)\\qquad i\\in S\n\\end{align*}\\] である。\n初期状態ベクトル \\(\\pi\\) と確率行列 \\(T\\) からマルコフ連鎖は定義される。"
  },
  {
    "objectID": "slides/10_markov.html#天気のマルコフ連鎖",
    "href": "slides/10_markov.html#天気のマルコフ連鎖",
    "title": "確率論",
    "section": "天気のマルコフ連鎖",
    "text": "天気のマルコフ連鎖\n状態集合 \\(S=\\{晴れ、曇り、雨\\}\\) 上のマルコフ連鎖を考える。 \\[\\begin{align*}\n\\Pr(X_0 = 晴れ) = 1/3\\qquad\n\\Pr(X_0 = 曇り) &= 1/2\\qquad\n\\Pr(X_0 = 雨) = 1/6\\\\\n\\Pr(X_{t+1} = 晴れ\\mid X_t=晴れ) &= 1/2\\\\\n\\Pr(X_{t+1} = 曇り\\mid X_t=晴れ) &= 1/3\\\\\n\\Pr(X_{t+1} = 雨\\mid X_t=晴れ) &= 1/6\\\\\n\\Pr(X_{t+1} = 晴れ\\mid X_t=曇り) &= 1/4\\\\\n\\Pr(X_{t+1} = 曇り\\mid X_t=曇り) &= 1/2\\\\\n\\Pr(X_{t+1} = 雨\\mid X_t=曇り) &= 1/4\\\\\n\\Pr(X_{t+1} = 晴れ\\mid X_t=雨) &= 1/3\\\\\n\\Pr(X_{t+1} = 曇り\\mid X_t=雨) &= 1/3\\\\\n\\Pr(X_{t+1} = 雨\\mid X_t=雨) &= 1/3\\\\\n\\end{align*}\\] と初期確率と遷移確率が与えられているとする。 このとき、 \\[\\begin{align*}\n晴れ&\\longleftrightarrow 1&\n曇り&\\longleftrightarrow 2&\n雨&\\longleftrightarrow 3&\n\\end{align*}\\] と対応させると、初期状態ベクトル \\(\\pi\\) と遷移行列 \\(T\\) は \\[\\begin{align*}\n\\pi&=\n\\begin{bmatrix}\n1/3&1/2&1/6\n\\end{bmatrix}&\nT&=\n\\begin{bmatrix}\n1/2&1/3&1/6\\\\\n1/4&1/2&1/4\\\\\n1/3&1/3&1/3\n\\end{bmatrix}\n\\end{align*}\\] である。"
  },
  {
    "objectID": "slides/10_markov.html#状態遷移図",
    "href": "slides/10_markov.html#状態遷移図",
    "title": "確率論",
    "section": "状態遷移図",
    "text": "状態遷移図\n確率の遷移確率を有向グラフで表したものを状態遷移図という。 上記の天気のマルコフ連鎖の状態遷移図は以下の通りである。 状態遷移図において遷移確率が0の有向辺は通常は描かない。 \\[\\begin{align*}\nT&=\n\\begin{bmatrix}\n1/2&1/3&1/6\\\\\n1/4&1/2&1/4\\\\\n1/3&1/3&1/3\n\\end{bmatrix}\n\\end{align*}\\]\n\n\n\n\n\n\n\nMarkov\n\n\n\n1\n\n晴れ\n\n\n\n1-&gt;1\n\n\n1/2\n\n\n\n2\n\n曇り\n\n\n\n1-&gt;2\n\n\n1/3\n\n\n\n3\n\n雨\n\n\n\n1-&gt;3\n\n\n1/6\n\n\n\n2-&gt;1\n\n\n1/4\n\n\n\n2-&gt;2\n\n\n1/2\n\n\n\n2-&gt;3\n\n\n1/4\n\n\n\n3-&gt;1\n\n\n1/3\n\n\n\n3-&gt;2\n\n\n1/3\n\n\n\n3-&gt;3\n\n\n1/3"
  },
  {
    "objectID": "slides/10_markov.html#時刻-t-の確率分布",
    "href": "slides/10_markov.html#時刻-t-の確率分布",
    "title": "確率論",
    "section": "時刻 \\(t\\) の確率分布",
    "text": "時刻 \\(t\\) の確率分布\n初期状態ベクトル \\(\\pi\\) と遷移行列 \\(T\\) が与えられているとき、\\(X_1\\) の確率は \\[\\begin{align*}\n\\Pr(X_1=j) &= \\sum_{i\\in S} \\Pr(X_0=i) \\Pr(X_1=j\\mid X_0=i)\\\\\n&=\\sum_{i\\in S} \\pi_i\\, p_{i, j}\\\\\n&=(\\pi T)_j\n\\end{align*}\\] と表せる。よって、 \\[\\begin{align*}\n\\Pr(X_t=j) &= (\\pi T^t)_j\n\\end{align*}\\] である。\n任意の遷移行列 \\(T\\) とすべて1の列ベクトル \\(\\mathrm{1}\\in\\mathbb{R}^{|S|}\\) について、 \\[\\begin{align*}\nT \\mathrm{1} = \\mathrm{1}\n\\end{align*}\\] である。  よって \\(I-T\\) は正則ではないので固有値1を持ち、対応する左固有ベクトル \\(\\mu\\) を持つ。 つまり、 \\[\\begin{align*}\n\\mu T = \\mu\n\\end{align*}\\] を満たす非零行ベクトル \\(\\mu\\) が存在する。 非負で成分の和が1の行ベクトル \\(\\mu\\) で \\(\\mu T = \\mu\\) を満たすものを定常確率ベクトルもしくは定常分布という。 現時点では定常確率ベクトルの存在は明らかではないが、任意の遷移行列 \\(T\\) について定常確率ベクトルが存在する。"
  },
  {
    "objectID": "slides/10_markov.html#天気のマルコフ連鎖の定常確率ベクトル",
    "href": "slides/10_markov.html#天気のマルコフ連鎖の定常確率ベクトル",
    "title": "確率論",
    "section": "天気のマルコフ連鎖の定常確率ベクトル",
    "text": "天気のマルコフ連鎖の定常確率ベクトル\n\\[\\begin{align*}\nT&=\n\\begin{bmatrix}\n1/2&1/3&1/6\\\\\n1/4&1/2&1/4\\\\\n1/3&1/3&1/3\n\\end{bmatrix}\n\\end{align*}\\] のとき、 \\[\\begin{align*}\nI-T&=\n\\begin{bmatrix}\n1/2&-1/3&-1/6\\\\\n-1/4&1/2&-1/4\\\\\n-1/3&-1/3&2/3\n\\end{bmatrix}\n\\end{align*}\\] の左カーネルとして \\[\\begin{align*}\n\\mu&=\n\\frac1{25}\\begin{bmatrix}\n9&10&6\n\\end{bmatrix}\n\\end{align*}\\] が取れる。これは非負で成分の和が1なので、定常確率ベクトルである。 \\(I-T\\) のランクは2であり、これが唯一の定常確率ベクトルである。\n一方でこの例の \\(T\\) は対角化不可能である。"
  },
  {
    "objectID": "slides/10_markov.html#確率行列の固有値",
    "href": "slides/10_markov.html#確率行列の固有値",
    "title": "確率論",
    "section": "確率行列の固有値",
    "text": "確率行列の固有値\n\nLemma 1 任意の確率行列の任意の固有値の絶対値は1以下である。\n\n\nProof. 遷移行列 \\(T\\) の固有値 \\(\\lambda\\in\\mathbb{C}\\) に対応する固有ベクトルを \\(v\\) とすると \\[\\begin{align*}\nTv &= \\lambda v\n\\end{align*}\\] が成り立つ。 \\(v\\) の成分で絶対値最大のものを第 \\(i\\) 成分とする。 第 \\(i\\) 成分に注目すると \\[\\begin{align*}\n\\sum_{j\\in S}T_{i,j}v_j &= \\lambda v_i\n\\end{align*}\\] が成り立つ。ここで \\[\\begin{align*}\n|\\lambda| |v_i| &= \\left|\\sum_{j\\in S}T_{i,j}v_j\\right|\\\\\n&\\le \\sum_{j\\in S}T_{i,j}\\left|v_j\\right|\\qquad(\\text{三角不等式})\\\\\n&\\le \\sum_{j\\in S}T_{i,j}\\left|v_i\\right|\\qquad(|v_j|\\le|v_i|)\\\\\n&=\\left|v_i\\right|\n\\end{align*}\\] より、 \\(|\\lambda|\\le 1\\) である。"
  },
  {
    "objectID": "slides/10_markov.html#マルコフ連鎖の例-グラフ上のランダムウォーク",
    "href": "slides/10_markov.html#マルコフ連鎖の例-グラフ上のランダムウォーク",
    "title": "確率論",
    "section": "マルコフ連鎖の例: グラフ上のランダムウォーク",
    "text": "マルコフ連鎖の例: グラフ上のランダムウォーク\n\nDefinition 1 (グラフ) 有限集合 \\(V\\) と集合 \\(E\\subseteq \\{\\{u,v\\}\\mid u,\\, v\\in V, u\\ne v\\}\\) のペア \\(G=(V,\\,E)\\) を(無向単純)グラフという。 \\(V\\) の元を頂点、\\(E\\) の元を辺と呼ぶ。\n\nグラフ \\(G=(V,\\,E)\\) と \\(v\\in V\\) について、 \\[\\begin{align*}\nN(v)&\\coloneqq\\{u\\in V\\mid \\{u,v\\}\\in E\\}\n\\end{align*}\\] を頂点 \\(v\\) の近傍という。また、 \\[\\begin{align*}\nd_v&\\coloneqq|N(v)|\n\\end{align*}\\] を \\(v\\) の次数という。 次数0の頂点を孤立頂点という。\n\nDefinition 2 (グラフ上のランダムウォーク) 孤立頂点を持たないグラフ \\(G=(V=\\{1,2,\\dotsc,n\\},\\,E)\\) 上のランダムウォークは \\(S=V\\) であり、 任意の初期確率ベクトル \\(\\pi\\) と \\[\\begin{align*}\np_{i,j} &=\n\\begin{cases}\n\\frac1{d_i}&\\text{if } \\{i,j\\}\\in E\\\\\n0&\\text{otherwise}\n\\end{cases}\n\\end{align*}\\] で定義される。"
  },
  {
    "objectID": "slides/10_markov.html#遷移行列の対角化",
    "href": "slides/10_markov.html#遷移行列の対角化",
    "title": "確率論",
    "section": "遷移行列の対角化",
    "text": "遷移行列の対角化\n\nLemma 2 グラフ上のランダムウォークの遷移行列は対角化可能であり、固有値はすべて実数である。\n\n\nProof. グラフ \\(G\\) の次数行列を \\[\\begin{align*}\nD_{i,j} &= d_i\\delta_{i,j}\n\\end{align*}\\] と定義する。 ここで \\(\\delta_{i,j}\\) はクロネッカーのデルタである。 \\[\\begin{align*}\nQ &= \\sqrt{D} P \\sqrt{D}^{-1}\n\\end{align*}\\] とすると、その \\((i,j)\\) 成分は \\[\\begin{align*}\nQ_{i,j} &= \\sqrt{d_i} p_{i,j} \\frac1{\\sqrt{d_j}}\\\\\n&= \\begin{cases}\n\\sqrt{d_i} \\frac1{d_i} \\frac1{\\sqrt{d_j}} = \\frac1{\\sqrt{d_id_j}}&\\text{if } \\{i,j\\}\\in E\\\\\n0&\\text{otherwise}\n\\end{cases}\n\\end{align*}\\] である。よって\\(Q\\) は実対称行列であり、スペクトル分解定理より、直交行列で対角化でき、すべての固有値は実数である。 つまり、ある直交行列 \\(V\\) と実対角行列 \\(\\Lambda\\) が存在して \\[\\begin{align*}\nQ &= V\\Lambda V^T\n\\end{align*}\\] である。 よって、 \\(P = \\sqrt{D}^{-1}Q\\sqrt{D} = \\sqrt{D}^{-1}V\\Lambda V^T\\sqrt{D}\\) が成り立ち、\\(P\\) も対角化可能であり、固有値はすべて実数である。"
  },
  {
    "objectID": "slides/10_markov.html#定常分布への収束",
    "href": "slides/10_markov.html#定常分布への収束",
    "title": "確率論",
    "section": "定常分布への収束",
    "text": "定常分布への収束\n遷移行列が \\(T=U\\Lambda U^{-1}\\) と対角化できるとき、\\(t\\) ステップ後の確率分布は \\[\\begin{align*}\n\\pi T^t &= \\pi (U \\Lambda U^{-1})^t\\\\\n&= \\pi U \\Lambda^t U^{-1}\n\\end{align*}\\] と表せる。 \\(T\\) の固有値の絶対値は 1 以下であるので、\\(t\\to\\infty\\) 極限では \\(\\Lambda^t\\) は固有値 \\(\\pm1\\) の部分だけが残る。 特に固有値1が一つだけであり、固有値 \\(-1\\) を持たないとき、初期分布 \\(\\pi\\) によらず、唯一の定常分布 \\(\\mu\\) に収束する。 \\[\\begin{align*}\n\\lim_{t\\to\\infty} \\pi T^t  &= \\mu\n\\end{align*}\\] どういうグラフについて絶対値1の固有値が一つになるか考える。"
  },
  {
    "objectID": "slides/10_markov.html#固有値1の個数-12",
    "href": "slides/10_markov.html#固有値1の個数-12",
    "title": "確率論",
    "section": "固有値1の個数 1/2",
    "text": "固有値1の個数 1/2\n\nLemma 3 グラフ上のランダムウォークの遷移行列 \\(T\\) に含まれる固有値1の個数はグラフの連結成分の個数である。\n\n\nProof. まず、「固有値1の個数 \\(\\ge\\) グラフの連結成分の個数」を証明する。 グラフの連結成分 \\(C\\subseteq V\\) について、列ベクトル \\(\\mathrm{1}_C\\) をインデックスが \\(C\\) に含まれるとき1、そうでないとき 0 と定義する。 このとき、\\(T\\mathrm{1}_C=\\mathrm{1}_C\\) であるので、固有値1の右固有ベクトルとなる。 各連結成分 \\(C\\) について \\(\\mathrm{1}_C\\) は線形独立であるので、「固有値1の個数 \\(\\ge\\) グラフの連結成分の個数」が示された。"
  },
  {
    "objectID": "slides/10_markov.html#固有値1の個数-22",
    "href": "slides/10_markov.html#固有値1の個数-22",
    "title": "確率論",
    "section": "固有値1の個数 2/2",
    "text": "固有値1の個数 2/2\n\nProof. 次に、「固有値1の個数 \\(\\le\\) グラフの連結成分の個数」を証明する。 \\(v\\) を固有値1に対応する固有ベクトルとすると、 \\[\\begin{align*}\nTv &=  v\n\\end{align*}\\] が成り立つ。 これは \\[\\begin{align*}\n\\sum_{j\\in S}T_{i,j} v_j &=  v_i\\qquad\\forall i\\in V\n\\end{align*}\\] を意味する。 グラフの連結成分 \\(C\\subseteq V\\) を固定する。 そして、 \\[\\begin{align*}\ni &\\in \\arg\\max_{j\\in C} v_j\n\\end{align*}\\] とおく。 このとき、 \\[\\begin{align*}\nv_i &= \\sum_{j\\in N(i)}T_{i,j} v_j \\le \\sum_{j\\in N(i)}T_{i,j} v_i = v_i\n\\end{align*}\\] という不等式が得られるが、この不等式が等号で満たされなければならない。 よって、\\(j\\in N(i)\\) について \\(v_j=v_i\\) であることが必要である。 よって \\(j\\in C\\) について \\(v_j=v_i\\) である必要がある。 したがって、グラフの連結成分を \\(C_1,\\dotsc,C_k\\) とすると \\[\\begin{align*}\nv&\\in\\mathrm{span}(\\mathrm{1}_{C_1},\\dotsc,\\mathrm{1}_{C_k})\n\\end{align*}\\] である。 以上のことから「固有値1の個数 \\(\\le\\) グラフの連結成分の個数」が示された。"
  },
  {
    "objectID": "slides/10_markov.html#固有値-1の個数-12",
    "href": "slides/10_markov.html#固有値-1の個数-12",
    "title": "確率論",
    "section": "固有値-1の個数 1/2",
    "text": "固有値-1の個数 1/2\n\nLemma 4 グラフ上のランダムウォークの遷移行列 \\(T\\) に含まれる固有値-1の個数はグラフの連結二部グラフの個数である。\n\n\nProof. 執筆中\n\nよって、グラフが連結していて二部グラフでない場合は遷移行列は固有値1を一つだけ持ち、固有値-1を持たない。"
  },
  {
    "objectID": "slides/10_markov.html#今週の課題",
    "href": "slides/10_markov.html#今週の課題",
    "title": "確率論",
    "section": "今週の課題",
    "text": "今週の課題\nグラフ\n\n\n\n\n\n\n\nMarkov\n\n\n\n1\n\n1\n\n\n\n2\n\n2\n\n\n\n1--2\n\n\n\n\n3\n\n3\n\n\n\n2--3\n\n\n\n\n4\n\n4\n\n\n\n3--4\n\n\n\n\n4--1\n\n\n\n\n4--2\n\n\n\n\n\n\n\n\n\n上のランダムウォークについて以下の問に答えよ。\n\n\n遷移行列を示せ。\n時刻0で確率1で状態1であるとき、時刻1,2,3における確率分布をもとめよ。\n定常確率ベクトルをもとめよ。"
  },
  {
    "objectID": "slides/04_moments.html#期待値",
    "href": "slides/04_moments.html#期待値",
    "title": "確率論",
    "section": "期待値",
    "text": "期待値\n\nDefinition 1 (期待値) 離散型確率変数 \\(X\\) の期待値は\n\\[\\begin{align*}\n\\expt{X}\n% &= \\sum_{\\omega \\in \\Omega} X(\\omega) P(\\{\\omega\\})\\\\\n%&= \\sum_{x\\in \\mathrm{Image}(X)} x P(\\{\\omega\\mid X(\\omega)=x\\})\\\\\n&\\coloneqq \\sum_{x\\in \\mathrm{Image}(X)} x \\Pr(X=x)\\\\\n&= \\sum_{x\\in \\mathrm{Image}(X)} x f_X(x)\n\\end{align*}\\]\nと定義される。ここで、右辺の和が絶対収束しない場合は(適当な順番で和を取って収束したとしても)期待値は定義されない。\n連続型確率変数 \\(X\\) が確率密度関数 \\(f_X\\) を持つとき、その期待値は\n\\[\n\\expt{X}\\coloneqq \\int_{-\\infty}^\\infty x f_X(x) \\mathrm{d}x\n\\]\nと定義される。 ただし、広義積分で上記の積分が存在する場合でも、 \\[\n\\int_{-\\infty}^\\infty |x| f_X(x) \\mathrm{d}x\n\\] が存在しない場合には期待値は定義されない。\n\n連続型確率変数の期待値に関する様々な証明はルベーグ積分の知識を必要とするのでこの授業では扱わない。 以下、証明はすべて離散確率変数の場合に限って与えて分かった気になることにする。"
  },
  {
    "objectID": "slides/04_moments.html#確率変数の和の期待値",
    "href": "slides/04_moments.html#確率変数の和の期待値",
    "title": "確率論",
    "section": "確率変数の和の期待値",
    "text": "確率変数の和の期待値\n\nLemma 1 確率変数 \\(X,\\,Y\\) について \\[\\begin{align*}\n\\expt{X+Y}&=\\expt{X}+\\expt{Y}.\n\\end{align*}\\]\n\n\nProof. \\[\\begin{align*}\n\\expt{X+Y} &= \\sum_{z} z f_{X+Y}(z)\\\\\n&= \\sum_{z} z \\sum_x f_{X,\\,Y}(x, z-x)\\\\\n&= \\sum_{x,\\,y} (x+y) f_{X,\\,Y}(x, y)\\qquad (y=z-x)\\\\\n&= \\sum_{x,\\,y} xf_{X,\\,Y}(x,y) + \\sum_{x,\\,y} yf_{X,\\,Y}(x,y)\\\\\n&= \\sum_{x} xf_{X}(x) + \\sum_{y} yf_{Y}(y)\\\\\n&= \\expt{X} + \\expt{Y}.\n\\end{align*}\\]"
  },
  {
    "objectID": "slides/04_moments.html#確率変数の積の期待値",
    "href": "slides/04_moments.html#確率変数の積の期待値",
    "title": "確率論",
    "section": "確率変数の積の期待値",
    "text": "確率変数の積の期待値\n\nLemma 2 確率変数 \\(X\\) と \\(Y\\) が独立のとき、 \\[\\begin{align*}\n\\expt{XY}&=\\expt{X}\\,\\expt{Y}.\n\\end{align*}\\]\n\n\nProof. \\[\\begin{align*}\n\\expt{XY} &= \\sum_{z} z f_{XY}(z)\\\\\n&= \\sum_{z} z \\sum_{x\\ne 0}f_{X,\\,Y}(x,z/x)\\\\\n&= \\sum_{z} z \\sum_{x\\ne 0}f_{X}(x)f_Y(z/x)\\\\\n&= \\sum_{x\\ne 0,\\, y} xy f_{X}(x)f_Y(y)\\qquad(y=z/x)\\\\\n&= \\sum_{x,\\, y} xy f_{X}(x)f_Y(y)\\\\\n&= \\left(\\sum_{x} xf_{X}(x)\\right)\\left(\\sum_y yf_Y(y)\\right)\\\\\n&= \\expt{X}\\,\\expt{Y}\n\\end{align*}\\]"
  },
  {
    "objectID": "slides/04_moments.html#期待値の簡潔な表現",
    "href": "slides/04_moments.html#期待値の簡潔な表現",
    "title": "確率論",
    "section": "期待値の簡潔な表現",
    "text": "期待値の簡潔な表現\n\nLemma 3 (Law of the unconscious statistician (LOTUS)) 任意の関数 \\(g\\colon\\mathbb{R}\\to\\mathbb{R}\\) について、\n\n\\(X\\) が離散型確率変数のとき、 \\[\\begin{align*}\n\\expt{g(X)} &= \\sum_{x} g(x) f_X(x).\n\\end{align*}\\]\n\\(X\\) が連続型確率変数で確率密度関数を持つとき、 \\[\\begin{align*}\n\\expt{g(X)} &= \\int_{-\\infty}^\\infty g(x) f_X(x) \\mathrm{d}x.\n\\end{align*}\\]\n\n\n\nProof. \\(X\\) を離散型確率変数とする。 \\[\\begin{align*}\n\\expt{g(X)}\n%&= \\sum_{x} x f_{g(X)}(x)\\\\\n&= \\sum_{x} x \\Pr(g(X) = x)\n= \\sum_{x} x P(\\{\\omega\\in\\Omega\\mid g(X(\\omega)) = x\\})\\\\\n&= \\sum_{x} x P\\left(\\bigcup_{y\\in\\mathrm{Image}(X)\\colon\\, g(y) = x}\\{\\omega\\in\\Omega\\mid X(\\omega) = y\\}\\right)\\\\\n&= \\sum_{x}\\sum_{y\\in\\mathrm{Image}(X)\\colon\\, g(y) = x} x P\\left(\\{\\omega\\in\\Omega\\mid X(\\omega) = y\\}\\right)\\\\\n&= \\sum_{y\\in\\mathrm{Image}(X)} g(y) f_X(y).\n\\end{align*}\\]"
  },
  {
    "objectID": "slides/04_moments.html#期待値の性質",
    "href": "slides/04_moments.html#期待値の性質",
    "title": "確率論",
    "section": "期待値の性質",
    "text": "期待値の性質\n\nProposition 1 (期待値の性質) 任意の確率変数 \\(X\\) と \\(a\\in\\mathbb{R}\\) について \\[\\begin{align*}\n\\expt{X+a} &= \\expt{X}+a\\\\\n\\expt{aX} &= a\\expt{X}.\n\\end{align*}\\]"
  },
  {
    "objectID": "slides/04_moments.html#マルコフの不等式",
    "href": "slides/04_moments.html#マルコフの不等式",
    "title": "確率論",
    "section": "マルコフの不等式",
    "text": "マルコフの不等式\n\nTheorem 1 (マルコフの不等式) 任意の非負確率変数 \\(X\\) と \\(a&gt;0\\) について \\[\n\\Pr(X\\ge a)\\le\\frac{\\expt{X}}{a}.\n\\]\n\n\nProof. \\[\\begin{align*}\n\\expt{X} &= \\sum_{x\\in \\mathrm{Image}(X)} f_X(x) x\\\\\n&= \\sum_{\\mathrm{Image}(X)\\colon\\, x\\ge a} f_X(x) x + \\sum_{\\mathrm{Image}(X)\\colon\\, x &lt; a} f_X(x) x\\\\\n&\\ge \\sum_{\\mathrm{Image}(X)\\colon\\, x\\ge a} f_X(x) x\\qquad\\qquad (\\Pr(X\\ge 0)=1)\\\\\n&\\ge \\sum_{\\mathrm{Image}(X)\\colon\\, x\\ge a} f_X(x) a\\\\\n&= \\Pr(X\\ge a) a.\n\\end{align*}\\]"
  },
  {
    "objectID": "slides/04_moments.html#分散",
    "href": "slides/04_moments.html#分散",
    "title": "確率論",
    "section": "分散",
    "text": "分散\n\nDefinition 2 (分散) 確率変数 \\(X\\) が期待値を持つとき、その分散を\n\\[\n\\var{X}\\coloneqq  \\expt{(X-\\expt{X})^2}\n\\]\nと定義する。 また、分散の平方根を標準偏差という。\n\n確率変数 \\(X\\) が分散を持つとき、\n\\[\\begin{align*}\n\\var{X} &= \\expt{(X-\\expt{X})^2}\\\\\n&= \\expt{X^2-2X\\expt{X}+\\expt{X}^2}\\\\\n&= \\expt{X^2}-2\\expt{X}\\expt{X}+\\expt{X}^2\\\\\n&= \\expt{X^2}-\\expt{X}^2\n\\end{align*}\\]\nである。 分散は定義より非負の値を持つ。\n\nProposition 2 (分散の性質) 任意の確率変数 \\(X\\) と \\(a\\in\\mathbb{R}\\) について \\[\\begin{align*}\n\\var{X+a} &= \\var{X}\\\\\n\\var{aX} &= a^2\\var{X}.\n\\end{align*}\\]\n\n分散は直感的には期待値からのはずれ具合を表す値である。"
  },
  {
    "objectID": "slides/04_moments.html#チェビシェフの不等式",
    "href": "slides/04_moments.html#チェビシェフの不等式",
    "title": "確率論",
    "section": "チェビシェフの不等式",
    "text": "チェビシェフの不等式\n\nTheorem 2 (チェビシェフの不等式) 任意の確率変数 \\(X\\) と \\(a&gt;0\\) について \\[\n\\Pr(|X-\\expt{X}|\\ge a)\\le\\frac{\\var{X}}{a^2}.\n\\]\n\n\nProof. \\[\\begin{align*}\n\\Pr(|X-\\expt{X}|\\ge a)&= \\Pr((X-\\expt{X})^2\\ge a^2)\\\\\n&\\le\n\\frac{\\expt{(X-\\expt{X})^2}}{a^2} = \\frac{\\var{X}}{a^2}.\n\\end{align*}\\]"
  },
  {
    "objectID": "slides/04_moments.html#互いに独立な確率変数の和",
    "href": "slides/04_moments.html#互いに独立な確率変数の和",
    "title": "確率論",
    "section": "互いに独立な確率変数の和",
    "text": "互いに独立な確率変数の和\n\nLemma 4 (互いに独立な確率変数の和) 確率変数 \\(X_1,\\,X_2,\\dotsc,X_n\\) が互いに独立のとき\n\\[\\begin{align*}\n\\var{X_1+\\dotsb+X_n} &= \\var{X_1} +\\dotsb + \\var{X_n}.\n\\end{align*}\\]\n\n\nProof. \\[\\begin{align*}\n\\var{X_1+\\dotsb+X_n} &= \\expt{\\left((X_1+\\dotsb+X_n) - \\expt{X_1+\\dotsb+X_n}\\right)^2}\\\\\n&= \\expt{\\left((X_1- \\expt{X_1}) + \\dotsb + (X_n-\\expt{X_n})\\right)^2}\\\\\n&= \\expt{\\sum_i (X_i- \\expt{X_i})^2  + 2\\sum_{i &lt; j}\\left(X_i-\\expt{X_i}\\right)\\left(X_j-\\expt{X_j}\\right)}\\\\\n&= \\sum_i \\expt{(X_i- \\expt{X_i})^2} +  2\\sum_{i &lt; j}\\expt{\\left(X_i-\\expt{X_i}\\right)\\left(X_j-\\expt{X_j}\\right)}\\\\\n&= \\sum_i \\expt{(X_i- \\expt{X_i})^2} +  2\\sum_{i &lt; j}\\expt{X_i-\\expt{X_i}}\\expt{X_j-\\expt{X_j}}\\\\\n&= \\sum_i \\expt{(X_i- \\expt{X_i})^2}\n=\\sum_i \\var{X_i}.\n\\end{align*}\\]"
  },
  {
    "objectID": "slides/04_moments.html#確率変数の平均",
    "href": "slides/04_moments.html#確率変数の平均",
    "title": "確率論",
    "section": "確率変数の平均",
    "text": "確率変数の平均\n\nExample 1 互いに独立な確率変数 \\(X_1,\\dotsc,X_n\\) のそれぞれが確率変数 \\(X\\) と同分布であるとし、 \\[\\begin{align*}\nY&\\coloneqq \\frac1{n} (X_1+\\dotsb+X_n)\n\\end{align*}\\] と定義する。 このとき、 \\[\\begin{align*}\n\\expt{Y} &= \\expt{X}\\\\\n\\var{Y} &= \\frac1{n}\\var{X}\n\\end{align*}\\] である。互いに独立な確率変数の平均を取ると期待値は変わらず、分散は小さくなる。\nチェビシェフの不等式を適用すると、\\(Y\\) は \\(n\\) を大きくすると期待値周辺に集中していくことが分かる。"
  },
  {
    "objectID": "slides/04_moments.html#共分散",
    "href": "slides/04_moments.html#共分散",
    "title": "確率論",
    "section": "共分散",
    "text": "共分散\n\nDefinition 3 (共分散) 確率変数 \\(X,Y\\) が期待値を持つとき、その共分散を\n\\[\\begin{align*}\n\\cov{X}{Y} &\\coloneqq \\expt{(X-\\expt{X})(Y-\\expt{Y})}\\\\\n&= \\expt{XY}-\\expt{X}\\,\\expt{Y}\n\\end{align*}\\]\nと定義する。 共分散がゼロである確率変数のペアを無相関であるという。\n\n定義より、\\(\\cov{X}{X}=\\var{X}\\) であることが分かる。\n\nProposition 3 独立確率変数 \\(X,Y\\) は無相関である。"
  },
  {
    "objectID": "slides/04_moments.html#無相関だけど独立ではない例",
    "href": "slides/04_moments.html#無相関だけど独立ではない例",
    "title": "確率論",
    "section": "無相関だけど独立ではない例",
    "text": "無相関だけど独立ではない例\n逆に無相関であっても独立とは限らない。\n\nExample 2 確率変数 \\(X\\) を \\[\\begin{align*}\nf_X(0)= f_X(+1)= f_X(-1)= \\frac13\n\\end{align*}\\] を満たすものとし、\\(Y=X^2\\) とする。 このとき、 \\[\\begin{align*}\n\\cov{X}{Y} &= \\expt{XY} - \\expt{X}\\expt{Y}\\\\\n&= \\expt{X^3} - \\expt{X}\\expt{X^2}\\\\\n&= \\expt{X} - \\expt{X}\\expt{X^2}\\\\\n&= \\expt{X}(1-\\expt{X^2})\\\\\n&= 0\n\\end{align*}\\] なので、\\(X\\) と \\(Y\\) は無相関である。 一方で \\[\\begin{align*}\nf_{Y}(0) &= \\frac13&\nf_{Y}(1) &= \\frac23\\\\\nf_{X,\\,Y}(0, 0) &= \\frac13&\nf_{X,\\,Y}(1, 1) &= \\frac13&\nf_{X,\\,Y}(-1, 1) &= \\frac13&\n\\end{align*}\\] なので \\(X\\) と \\(Y\\) は独立ではない。"
  },
  {
    "objectID": "slides/04_moments.html#共分散と分散の関係",
    "href": "slides/04_moments.html#共分散と分散の関係",
    "title": "確率論",
    "section": "共分散と分散の関係",
    "text": "共分散と分散の関係\n共分散は正の値も負の値も取り得る。 大雑把に言うと、\n\n\\(X\\) と \\(Y\\) の共分散が正 \\(\\iff\\) \\(X\\) が大きいとき \\(Y\\) も大きい\n\\(X\\) と \\(Y\\) の共分散が負 \\(\\iff\\) \\(X\\) が大きいとき \\(Y\\) は小さい\n\nという意味になる。\n\nLemma 5 任意の確率変数 \\(X_1,\\dotsc,X_n\\) について \\[\\begin{align*}\n\\var{\\sum_i X_i} &= \\sum_i \\var{X_i} + 2\\sum_{i &lt; j} \\cov{X_i}{X_j}.\n\\end{align*}\\]\n\n\nProof. Lemma 4 の証明参照。"
  },
  {
    "objectID": "slides/04_moments.html#モーメントとモーメント母関数",
    "href": "slides/04_moments.html#モーメントとモーメント母関数",
    "title": "確率論",
    "section": "モーメントとモーメント母関数",
    "text": "モーメントとモーメント母関数\n\nDefinition 4 (モーメント) 確率変数 \\(X\\) と正の整数 \\(n\\ge 1\\) について、\n\\[\n\\mu_n(X)\\coloneqq \\expt{X^n}\n\\]\nを \\(X\\) の \\(n\\) 次モーメントという。\n\n\nDefinition 5 (モーメント母関数(積率母関数)) 確率変数 \\(X\\) について、\n\\[\nM_X(t) \\coloneqq \\expt{\\mathrm{e}^{tX}}\\qquad t\\in\\mathbb{R}\n\\]\nを \\(X\\) のモーメント母関数という。 すべての \\(t\\in\\mathbb{R}\\) で \\(M_X(t)\\) が存在しない場合もある。 また、\n\\[\nK_X(t) \\coloneqq \\log M_X(t)\n\\] を \\(X\\) のキュムラント母関数という。\n\n\n定義より、\\(M_X(0) = 1\\), \\(K_X(0)=0\\) である。\nまた、独立確率変数 \\(X,\\,Y\\) について \\[\\begin{align*}\nM_{X+Y}(t) &= \\expt{\\mathrm{e}^{t(X+Y)}} = \\expt{\\mathrm{e}^{tX}\\cdot\\mathrm{e}^{tY}}\n= \\expt{\\mathrm{e}^{tX}}\\cdot\\expt{\\mathrm{e}^{tY}} = M_X(t)M_Y(t)\n\\end{align*}\\] である。同様に \\(K_{X+Y}(t) = K_X(t) + K_Y(t)\\) である。"
  },
  {
    "objectID": "slides/04_moments.html#モーメントの母関数",
    "href": "slides/04_moments.html#モーメントの母関数",
    "title": "確率論",
    "section": "モーメントの母関数",
    "text": "モーメントの母関数\n\nTheorem 3 確率変数 \\(X\\) について、ある \\(\\epsilon &gt;0\\) が存在し、モーメント母関数 \\(M_X(t)\\) が \\(t\\in(-\\epsilon,\\epsilon)\\) で存在するとき、\n\\[\\begin{align*}\nM_X(t) &=\\sum_{n\\ge 0}\\frac{\\expt{X^n}}{n!}t^n\\qquad\\forall t\\in(-\\epsilon,\\epsilon)\\\\\n\\mu_n(X) &= \\left.\\frac{\\mathrm{d}^n M_X(t)}{\\mathrm{d} t^n}\\right|_{t=0}.\n\\end{align*}\\]\n\n\nProof. 前半の証明を与える。 離散型確率変数 \\(X\\) について、 \\[\\begin{align*}\nM_X(t) &= \\expt{\\mathrm{e}^{tX}}\n= \\sum_x \\mathrm{e}^{tx} f_X(x)\n= \\sum_x \\left(\\sum_{n\\ge0}\\frac{(tx)^n}{n!}\\right) f_X(x)\n\\end{align*}\\] である。 ここで、任意の \\(t\\in(-\\epsilon,\\epsilon)\\) について \\[\\begin{align*}\n\\sum_x \\sum_{n\\ge0}\\left|\\frac{(tx)^n}{n!} f_X(x)\\right|\n&= \\sum_x \\sum_{n\\ge0}\\frac{|tx|^n}{n!} f_X(x)\n= \\sum_x \\mathrm{e}^{|tx|} f_X(x)\n\\le \\sum_x (\\mathrm{e}^{tx}+\\mathrm{e}^{-tx}) f_X(x)\\\\\n&= \\expt{\\mathrm{e}^{tX}} + \\expt{\\mathrm{e}^{-tX}}\n= M_X(t) + M_X(-t) &lt; \\infty\n\\end{align*}\\] よって、この無限和は任意の \\(t\\in(-\\epsilon,\\epsilon)\\) について絶対収束する。 そのため、和の順序を変えても収束値は変化しない。 \\[\\begin{align*}\nM_X(t) &=\n\\sum_x \\left(\\sum_{n\\ge0}\\frac{(tx)^n}{n!}\\right) f_X(x)\n= \\sum_{n\\ge 0} \\sum_{x}\\frac{(tx)^n}{n!}f_X(x)\n= \\sum_{n\\ge 0} \\frac{\\sum_xx^n f_X(x)}{n!}t^n\n= \\sum_{n\\ge 0} \\frac{\\expt{X^n}}{n!}t^n\\qquad\\forall t\\in(-\\epsilon,\\epsilon).\n\\end{align*}\\]"
  },
  {
    "objectID": "slides/04_moments.html#キュムラント母関数",
    "href": "slides/04_moments.html#キュムラント母関数",
    "title": "確率論",
    "section": "キュムラント母関数",
    "text": "キュムラント母関数\n\nCorollary 1 確率変数 \\(X\\) について、ある \\(\\epsilon &gt;0\\) が存在し、モーメント母関数 \\(M_X(t)\\) が \\(t\\in(-\\epsilon,\\epsilon)\\) で存在するとき、\n\\[\\begin{align*}\n\\left.\\frac{\\mathrm{d} K_X(t)}{\\mathrm{d} t}\\right|_{t=0} &= \\expt{X},&\n\\left.\\frac{\\mathrm{d}^2 K_X(t)}{\\mathrm{d} t^2}\\right|_{t=0} &=  \\var{X}.\n\\end{align*}\\]\n\n\nProof. \\[\\begin{align*}\n\\left.\\frac{\\mathrm{d} K_X(t)}{\\mathrm{d} t}\\right|_{t=0} &= \\left.\\frac{M'_X(t)}{M_X(t)}\\right|_{t=0}=\\expt{X}\\\\\n\\left.\\frac{\\mathrm{d}^2 K_X(t)}{\\mathrm{d} t^2}\\right|_{t=0} &= \\left.\\frac{M''_X(t)M_X(t) - M'_X(t)^2}{M_X(t)^2}\\right|_{t=0} = M''_X(0) - M'_X(0)^2 = \\var{X}.\n\\end{align*}\\]\n\nまた、重要度は低くなるが、\n\\[\\begin{align*}\n\\left.\\frac{\\mathrm{d}^3 K_X(t)}{\\mathrm{d} t^3}\\right|_{t=0} &= \\expt{(X - \\expt{X})^3}\\\\\n\\left.\\frac{\\mathrm{d}^4 K_X(t)}{\\mathrm{d} t^4}\\right|_{t=0} &= \\expt{(X - \\expt{X})^4} - 3\\var{X}^2\n\\end{align*}\\]\nが成り立つ(覚えなくてよい)。 一般に以下を \\(X\\) の \\(n\\) 次キュムラント と呼ぶ。 \\[\\begin{align*}\n\\kappa_n(X) &\\coloneqq \\left.\\frac{\\mathrm{d}^n K_X(t)}{\\mathrm{d} t^n}\\right|_{t=0}.\n\\end{align*}\\]"
  },
  {
    "objectID": "slides/04_moments.html#モーメント母関数の一致",
    "href": "slides/04_moments.html#モーメント母関数の一致",
    "title": "確率論",
    "section": "モーメント母関数の一致",
    "text": "モーメント母関数の一致\n\nTheorem 4 確率変数 \\(X\\) と \\(Y\\) のモーメント母関数が0を含む開区間 \\((-\\epsilon,\\,\\epsilon)\\) で存在し、それらが等しいとき、\\(X\\) の分布と \\(Y\\) の分布は等しい。\n\n証明は確率変数の像が有限の場合に与える(ウェブ資料参照)。\n\nTheorem 4 より、モーメント母関数には確率変数の分布のすべての情報が含まれていると言える。 ただし、モーメント母関数は原点まわりで存在しないこともあるので、分布の情報をすべて含む関数としては特性関数 \\[\\begin{align*}\n\\varphi_X(t) &\\coloneqq \\expt{\\mathrm{e}^{itX}}\\qquad\\forall t\\in\\mathbb{R}\n\\end{align*}\\] の方が優秀である。 特性関数は常に存在する。 一方でモーメント母関数は確率の集中を示す文脈では中心的な役割を果たす。"
  },
  {
    "objectID": "slides/04_moments.html#今週の課題",
    "href": "slides/04_moments.html#今週の課題",
    "title": "確率論",
    "section": "今週の課題",
    "text": "今週の課題\n\\(\\lambda&gt;0\\) について \\(X\\sim\\mathrm{Poisson}(\\lambda)\\) とする。 以下の問に答えよ\n\n\n\\(X\\) のキュムラント母関数をもとめよ。\n\\(\\expt{X}\\) と \\(\\var{X}\\) をもとめよ。"
  },
  {
    "objectID": "slides/09_clt.html#大数の法則と確率の集中",
    "href": "slides/09_clt.html#大数の法則と確率の集中",
    "title": "確率論",
    "section": "大数の法則と確率の集中",
    "text": "大数の法則と確率の集中\n\n\n\n\n\n\n\n\n\nFigure 1: 二項分布の確率質量関数\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 2: 二項分布の累積分布関数"
  },
  {
    "objectID": "slides/09_clt.html#大数の法則と確率の集中-1",
    "href": "slides/09_clt.html#大数の法則と確率の集中-1",
    "title": "確率論",
    "section": "大数の法則と確率の集中",
    "text": "大数の法則と確率の集中\n\n\n\n\n\n\n\n\n\nFigure 3: 二項分布の確率質量関数\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 4: 二項分布の累積分布関数"
  },
  {
    "objectID": "slides/09_clt.html#大数の法則と確率の集中-2",
    "href": "slides/09_clt.html#大数の法則と確率の集中-2",
    "title": "確率論",
    "section": "大数の法則と確率の集中",
    "text": "大数の法則と確率の集中\n\n\n\n\n\n\n\n\n\nFigure 5: 二項分布の確率質量関数\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 6: 二項分布の累積分布関数"
  },
  {
    "objectID": "slides/09_clt.html#期待値周辺",
    "href": "slides/09_clt.html#期待値周辺",
    "title": "確率論",
    "section": "期待値周辺",
    "text": "期待値周辺\n\n\n\n\n\n\n\n\n\nFigure 7: 二項分布の確率質量関数\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 8: 二項分布の累積分布関数"
  },
  {
    "objectID": "slides/09_clt.html#期待値周辺-1",
    "href": "slides/09_clt.html#期待値周辺-1",
    "title": "確率論",
    "section": "期待値周辺",
    "text": "期待値周辺\n\n\n\n\n\n\n\n\n\nFigure 9: 二項分布の確率質量関数\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 10: 二項分布の累積分布関数"
  },
  {
    "objectID": "slides/09_clt.html#期待値周辺-2",
    "href": "slides/09_clt.html#期待値周辺-2",
    "title": "確率論",
    "section": "期待値周辺",
    "text": "期待値周辺\n\n\n\n\n\n\n\n\n\nFigure 11: 二項分布の確率質量関数\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 12: 二項分布の累積分布関数"
  },
  {
    "objectID": "slides/09_clt.html#法則収束",
    "href": "slides/09_clt.html#法則収束",
    "title": "確率論",
    "section": "法則収束",
    "text": "法則収束\n\nDefinition 1 (確率変数の法則収束) 確率変数の列 \\((X_n)_{n=1,2,\\dotsc,}\\) を考える。これらの確率変数は確率空間 \\((\\Omega,\\,P)\\) を共有している必要はない(同時確率を考えるわけではないので)。 確率変数の列 \\((X_n)_{n=1,2,\\dotsc,}\\) が確率変数 \\(X\\) に法則収束する \\(\\defiff\\) \\(X\\) の累積分布関数 \\(F_X\\) のすべての連続点 \\(x\\in\\mathbb{R}\\) について \\[\\begin{align*}\n\\lim_{n\\to\\infty} F_{X_n}(x)= F_X(x)\n\\end{align*}\\]\nまた、このとき \\(X_n\\overset{d}{\\to} X\\) と表す。"
  },
  {
    "objectID": "slides/09_clt.html#中心極限定理",
    "href": "slides/09_clt.html#中心極限定理",
    "title": "確率論",
    "section": "中心極限定理",
    "text": "中心極限定理\n\nTheorem 1 (中心極限定理) 確率変数 \\(X\\) が分散を持つとする。 確率変数 \\(X_1,\\dotsc,X_N\\) が独立で \\(X\\) と同じ分布に従うとする。 また、確率変数 \\(Z\\) は期待値0分散1の正規分布 \\(N(0,1)\\) に従うものとする。 このとき、 \\[\\begin{align*}\n\\frac1{\\sqrt{N\\var{X}}}\\left(\\sum_{k=1}^N X_k-N\\expt{X}\\right)\n&\\overset{d}{\\longrightarrow} Z\\qquad\\text{as } N\\to\\infty.\n\\end{align*}\\]\n\n確率変数 \\(X_k\\) を期待値0分散1に正規化した確率変数 \\[\\begin{align*}\nY_k &\\coloneqq \\frac{X_k -\\expt{X}}{\\sqrt{\\var{X}}}\n\\end{align*}\\] を使うと、 \\[\\begin{align*}\n\\frac{\\sum_k Y_k}{\\sqrt{N}}\n&= Z\\qquad\\text{as } N\\to\\infty\n\\end{align*}\\] と表せる。"
  },
  {
    "objectID": "slides/09_clt.html#特性関数",
    "href": "slides/09_clt.html#特性関数",
    "title": "確率論",
    "section": "特性関数",
    "text": "特性関数\n\nDefinition 2 確率変数 \\(X\\) について、特性関数 \\(\\varphi_X\\colon\\mathbb{R}\\to\\mathbb{C}\\) を以下で定義する。 \\[\\begin{align*}\n\\varphi_X(t) &\\coloneqq \\expt{\\mathrm{e}^{itX}}.\n\\end{align*}\\]\n\n\nTheorem 2 確率変数 \\(X,\\,Y\\) について \\[\\begin{align*}\n\\varphi_X = \\varphi_Y &\\iff F_X = F_Y.\n\\end{align*}\\]"
  },
  {
    "objectID": "slides/09_clt.html#特性関数の応用",
    "href": "slides/09_clt.html#特性関数の応用",
    "title": "確率論",
    "section": "特性関数の応用",
    "text": "特性関数の応用\n\nLemma 1 (正規分布の再生性) 独立確率変数 \\(X\\sim N(\\mu_0,\\,\\sigma_0^2)\\) と \\(Y\\sim N(\\mu_1,\\,\\sigma_1^2)\\) について \\(X+Y\\sim N(\\mu_0+\\mu_1,\\,\\sigma_0^2+\\sigma_1^2)\\).\n\n\nProof. \\[\\begin{align*}\n\\varphi_X(t) &= \\mathrm{e}^{i\\mu_0 t - \\frac12\\sigma_0^2 t^2}&\n\\varphi_Y(t) &= \\mathrm{e}^{i\\mu_1 t - \\frac12\\sigma_1^2 t^2}\n\\end{align*}\\] より、 \\[\\begin{align*}\n\\varphi_{X+Y}(t) &= \\varphi_X(t)\\varphi_Y(t) =\n\\mathrm{e}^{i(\\mu_0+\\mu_1) t - \\frac12(\\sigma_0^2+\\sigma_1^2) t^2}\n\\end{align*}\\] であるが、これは \\(N(\\mu_0+\\mu_1,\\,\\sigma_0^2+\\sigma_1^2)\\) の特性関数である。 よって、Theorem 2 より \\(X+Y\\sim N(\\mu_0+\\mu_1,\\,\\sigma_0^2+\\sigma_1^2)\\).\n\n\nLemma 2 (ポアソン分布の再生性) 独立確率変数 \\(X\\sim \\mathrm{Poisson}(\\lambda_0)\\) と \\(Y\\sim \\mathrm{Poisson}(\\lambda_1)\\) について \\(X+Y\\sim \\mathrm{Poisson}(\\lambda_0+\\lambda_1)\\).\n\n\nProof. \\[\\begin{align*}\n\\varphi_X(t) &= \\mathrm{e}^{\\lambda_0(\\mathrm{e}^{it}-1)}&\n\\varphi_Y(t) &= \\mathrm{e}^{\\lambda_1(\\mathrm{e}^{it}-1)}&\n\\end{align*}\\] より、 \\[\\begin{align*}\n\\varphi_{X+Y}(t) &= \\varphi_X(t)\\varphi_Y(t) =\n\\mathrm{e}^{(\\lambda_0+\\lambda_1)(\\mathrm{e}^{it}-1)}&\n\\end{align*}\\] であるが、これは \\(\\mathrm{Poisson}(\\lambda_0+\\lambda_1)\\) の特性関数である。 よって、Theorem 2 より \\(X+Y\\sim \\mathrm{Poisson}(\\lambda_0+\\lambda_1)\\)."
  },
  {
    "objectID": "slides/09_clt.html#レヴィの連続性定理",
    "href": "slides/09_clt.html#レヴィの連続性定理",
    "title": "確率論",
    "section": "レヴィの連続性定理",
    "text": "レヴィの連続性定理\n中心極限定理の証明の概要を紹介する。\nTheorem 2 は特性関数が確率分布と一対一に対応していることを主張していた。\n\nTheorem 3 (レヴィの連続性定理) 確率変数の列 \\((X_n)_{n=1,2,\\dotsc,}\\) を考える。これらの確率変数は確率空間 \\((\\Omega,\\,P)\\) を共有している必要はない(同時確率を考えるわけではないので)。 確率変数列の特性関数列 \\((\\varphi_{X_n})_{n=1,2,\\dotsc}\\) が各点収束すると仮定する。 このとき、\n\\[\\begin{align*}\n\\varphi(t) &\\coloneqq \\lim_{n\\to\\infty} \\varphi_{X_n}(t).\n\\end{align*}\\]\nとおくと、ある確率変数 \\(X\\) が存在し、\\(\\varphi_X(t) = \\varphi(t)\\) であり、\\((X_n)_n\\) は \\(X\\) に法則収束する。"
  },
  {
    "objectID": "slides/09_clt.html#テイラーの定理",
    "href": "slides/09_clt.html#テイラーの定理",
    "title": "確率論",
    "section": "テイラーの定理",
    "text": "テイラーの定理\n\nTheorem 4 (テイラーの定理) 実関数 \\(f\\colon \\mathbb{R}\\to\\mathbb{R}\\) が \\(a\\in\\mathbb{R}\\) で \\(k\\ge 1\\) 回微分可能なとき、ある関数 \\(h\\colon\\mathbb{R}\\to\\mathbb{R}\\) で \\(\\lim_{x\\to a}h(x) = 0\\) であるものが存在し、 \\[\\begin{align*}\nf(x) &= \\sum_{s=0}^k\\frac{f^{(s)}(a)}{s!}(x-a)^s + h(x)(x-a)^k.\n\\end{align*}\\]"
  },
  {
    "objectID": "slides/09_clt.html#中心極限定理の証明の概要",
    "href": "slides/09_clt.html#中心極限定理の証明の概要",
    "title": "確率論",
    "section": "中心極限定理の証明の概要",
    "text": "中心極限定理の証明の概要\nTheorem 3 より \\[\\begin{align*}\n\\lim_{N\\to\\infty} \\varphi_{\\frac{\\sum_k Y_k}{\\sqrt{N}}}(t) &= \\varphi_Z(t) = \\mathrm{e}^{-\\frac{t^2}2}\n\\end{align*}\\] を示せば十分である。\n\\[\\begin{align*}\n\\varphi_{\\frac{\\sum_k Y_k}{\\sqrt{N}}}(t)\n&= \\varphi_{\\sum_k Y_k}\\left(\\frac{t}{\\sqrt{N}}\\right)\\\\\n&= \\varphi_{Y}\\left(\\frac{t}{\\sqrt{N}}\\right)^N\\\\\n&= \\left(\\varphi_Y(0) + \\varphi'_Y(0)\\frac{t}{\\sqrt{N}} + \\frac{\\varphi''_Y(0)}2 \\left(\\frac{t}{\\sqrt{N}}\\right)^2 + o\\left(\\frac{1}{N}\\right)\\right)^N\\\\\n&= \\left(1 - \\frac{1}2 \\frac{t^2}{N} + o\\left(\\frac{1}{N}\\right)\\right)^N\\\\\n&\\to \\mathrm{e}^{-\\frac{t^2}2}.\n\\end{align*}\\]"
  },
  {
    "objectID": "slides/09_clt.html#今週の課題",
    "href": "slides/09_clt.html#今週の課題",
    "title": "確率論",
    "section": "今週の課題",
    "text": "今週の課題\n表が出る確率が \\(p\\) のコインを \\(N\\) 回投げて表が出る回数が区間 \\(\\left[pN-a\\sqrt{N},\\, pN+a\\sqrt{N}\\right]\\) に入る確率が \\(N\\to\\infty\\) 極限で \\[\\begin{align*}\n\\int_{-b}^b\\frac1{\\sqrt{2\\pi}} \\mathrm{e}^{-\\frac12 x^2}\\mathrm{d}x\n\\end{align*}\\] に収束するような \\(b&gt;0\\) を \\(p\\) と \\(a\\) を使って表せ。"
  },
  {
    "objectID": "slides/05_bayes.html#統計的推論推定",
    "href": "slides/05_bayes.html#統計的推論推定",
    "title": "確率論",
    "section": "統計的推論推定",
    "text": "統計的推論推定\n統計的推論とは現実の推定問題を確率論に基づきモデル化し、誤り確率を最小化するように推論する方法論である。 統計的推論には大きく分けて二種類の流派がある。\n\nベイズ主義: 推論する対象の分布(事前分布)を仮定する。\n頻度主義: 推論する対象の分布(事前分布)を仮定しない。\n\n例えば統計的推論は以下のような問題に適用されている。\n\n新薬の有効性\nウェブ広告のクリック率の推定\n工場で製造される製品の不良率の推定"
  },
  {
    "objectID": "slides/05_bayes.html#ベイズ推定",
    "href": "slides/05_bayes.html#ベイズ推定",
    "title": "確率論",
    "section": "ベイズ推定",
    "text": "ベイズ推定\n\n\\(\\mathcal{X}\\colon\\) データが取り得る値の集合\n\\(\\Theta\\colon\\) 分布のパラメータが取り得る値の集合\n\n簡単のため、\\(\\mathcal{X}\\) と \\(\\Theta\\) は高々可算集合とする。\nデータ \\(x\\in\\mathcal{X}\\) からパラメータ \\(\\theta\\in\\Theta\\) を推定する問題を考える。 このとき、\\(x\\) と \\(\\theta\\) が何かしらの確率分布に従っていると仮定する。 パラメータ \\(\\theta\\) に対する \\(x\\) の確率質量関数を \\(p(x\\mid \\theta)\\) と表す。 また、パラメータ \\(\\theta\\) の確率質量関数を \\(\\pi(\\theta)\\) と表す。 つまり、パラメータ \\(\\theta\\in\\Theta\\) とデータ \\(x\\in\\mathcal{X}\\) が選ばれる確率は \\[\\begin{align*}\n\\pi(\\theta) p(x\\mid\\theta)\n\\end{align*}\\] である。 また、 \\[\\begin{align*}\np(x) &= \\sum_{\\theta\\in\\Theta}\\pi(\\theta)p(x\\mid\\theta),&\np(\\theta\\mid x)&\\coloneqq \\frac{\\pi(\\theta)p(x\\mid\\theta)}{p(x)}\n\\end{align*}\\] と定義する。 ベイズ推定の文脈では\n\n\\(\\pi(\\theta)\\colon\\) 事前確率\n\\(p(x\\mid \\theta)\\colon\\) 尤度\n\\(p(\\theta\\mid x)\\colon\\) 事後確率\n\nと呼ぶ。"
  },
  {
    "objectID": "slides/05_bayes.html#最大事後確率推定",
    "href": "slides/05_bayes.html#最大事後確率推定",
    "title": "確率論",
    "section": "最大事後確率推定",
    "text": "最大事後確率推定\nこのとき、得られたデータ \\(x\\in\\mathcal{X}\\) からパラメータ \\(\\theta\\in\\Theta\\) を推定する関数 \\(\\widehat{\\theta}\\colon \\mathcal{X}\\to\\Theta\\) の誤り確率は \\[\\begin{align*}\nP_{\\mathrm{err}}(\\widehat{\\theta})\n&\\coloneqq \\sum_{\\theta\\in\\Theta} \\pi(\\theta) \\sum_{x\\in\\mathcal{X}} p(x\\mid\\theta) \\,\\mathbb{I}\\{\\widehat{\\theta}(x)\\ne\\theta\\}\\\\\n&= \\sum_{\\theta\\in\\Theta} \\pi(\\theta) \\sum_{x\\in\\mathcal{X}} p(x\\mid\\theta) (1-\\mathbb{I}\\{\\widehat{\\theta}(x)=\\theta\\})\\\\\n%&= 1- \\sum_{\\theta\\in\\Theta} \\pi(\\theta) \\sum_{x\\in\\mathcal{X}} p(x\\mid\\theta)\\, \\mathbb{I}\\{\\widehat{\\theta}(x)=\\theta\\}\\\\\n&= 1- \\sum_{x\\in\\mathcal{X}}\\sum_{\\theta\\in\\Theta} \\pi(\\theta)  p(x\\mid\\theta)\\, \\mathbb{I}\\{\\widehat{\\theta}(x)=\\theta\\}\\\\\n&= 1- \\sum_{x\\in\\mathcal{X}}\\pi\\left(\\widehat{\\theta}(x)\\right)  p\\left(x\\mid\\widehat{\\theta}(x)\\right)\\\\\n&\\ge 1- \\sum_{x\\in\\mathcal{X}} \\max_{\\theta\\in\\Theta} \\pi\\left(\\theta\\right)  p\\left(x\\mid\\theta\\right)\n\\end{align*}\\] と下から抑えることができ、 \\[\\begin{align*}\n\\widehat{\\theta}_{\\mathrm{MAP}}(x) &\\coloneqq\n  \\arg\\max_{\\theta\\in\\Theta}p\\left(\\theta\\mid x\\right)\\\\\n&= \\arg\\max_{\\theta\\in\\Theta}p\\left(\\theta\\mid x\\right)  p\\left(x\\right)\\\\\n&= \\arg\\max_{\\theta\\in\\Theta}\\pi\\left(\\theta\\right)  p\\left(x\\mid\\theta\\right)\\\\\n\\end{align*}\\] という推定関数により等号が達成される。 この推定関数を最大事後確率(maximum a posteriori; MAP)推定関数と呼ぶ。 事後確率の最大化の代わりに同時確率の最大化と理解してもよい。"
  },
  {
    "objectID": "slides/05_bayes.html#最尤推定",
    "href": "slides/05_bayes.html#最尤推定",
    "title": "確率論",
    "section": "最尤推定",
    "text": "最尤推定\nMAP推定は誤り確率を最小化する推定方法であるが、事前確率 \\(\\pi(\\theta)\\) を仮定しないと用いることができない。 一方で尤度を最大化する推定関数 \\[\\begin{align*}\n\\widehat{\\theta}_{\\mathrm{ML}}(x) &\\coloneqq\n  \\arg\\max_{\\theta\\in\\Theta}p\\left(x\\mid\\theta\\right)\n\\end{align*}\\] を最尤(maximam likelihood; ML)推定関数という。 \\(\\Theta\\) が有限集合で、事前確率が一様分布 \\(\\pi(\\theta)=\\frac1{|\\Theta|}\\) のとき、最尤推定は最大事後確率推定と一致する。"
  },
  {
    "objectID": "slides/05_bayes.html#二つの分布の識別",
    "href": "slides/05_bayes.html#二つの分布の識別",
    "title": "確率論",
    "section": "二つの分布の識別",
    "text": "二つの分布の識別\n特にパラメータが二値である場合を考える。ここでは \\(\\Theta=\\{0,1\\}\\) とする。 また、 \\[\\begin{align*}\np^{(0)}(x) &\\coloneqq p(x\\mid 0)&\np^{(1)}(x) &\\coloneqq p(x\\mid 1)\n\\end{align*}\\] とする。 このとき、 \\[\\begin{align*}\nP_{\\mathrm{err}}(\\widehat{\\theta}_\\mathrm{MAP})\n&= 1- \\sum_{x\\in\\mathcal{X}} \\max_{\\theta\\in\\{0,1\\}} \\pi\\left(\\theta\\right)  p\\left(x\\mid\\theta\\right)\\\\\n&= 1- \\sum_{x\\in\\mathcal{X}} \\max \\left\\{\\pi(0)  p^{(0)}\\left(x\\right),\\,\\pi(1)  p^{(1)}\\left(x\\right)\\right\\}\\\\\n\\end{align*}\\] である。 ここで、 \\[\\begin{align*}\n\\begin{split}\n\\max\\{a,b\\} - \\min\\{a,b\\} &= |\\,a-b\\,|\\\\\n\\max\\{a,b\\} + \\min\\{a,b\\} &= a+b\n\\end{split}\n\\qquad\\forall a,b\\in\\mathbb{R}\n\\end{align*}\\] であるので、 \\[\\begin{align*}\n\\max\\{a,b\\} &= \\frac12(a+b+|\\,a-b\\,|)\\qquad\\forall a,b\\in\\mathbb{R}.\n\\end{align*}\\] よって、 \\[\\begin{align*}\n%\\max_{\\theta\\in\\{0,1\\}} \\{\\pi\\left(\\theta\\right)  p\\left(x\\mid\\theta\\right)\\}\n\\max \\left\\{\\pi(0)  p^{(0)}\\left(x\\right),\\,\\pi(1)  p^{(1)}\\left(x\\right)\\right\\}\n&= \\frac12\\left(p(x) +\n\\left|\\,\\pi\\left(0\\right)  p^{(0)}\\left(x\\right) - \\pi\\left(1\\right)  p^{(1)}\\left(x\\right) \\,\\right|\\right).\n\\end{align*}\\]"
  },
  {
    "objectID": "slides/05_bayes.html#全変動距離",
    "href": "slides/05_bayes.html#全変動距離",
    "title": "確率論",
    "section": "全変動距離",
    "text": "全変動距離\n\\[\\begin{align*}\nP_{\\mathrm{err}}(\\widehat{\\theta}_\\mathrm{MAP})\n&= 1- \\sum_{x\\in\\mathcal{X}} \\max \\left\\{\\pi(0)  p^{(0)}\\left(x\\right),\\,\\pi(1)  p^{(1)}\\left(x\\right)\\right\\}\\\\\n&= 1- \\sum_{x\\in\\mathcal{X}} \\frac12\\left(p(x) +\n\\left|\\,\\pi\\left(0\\right)  p^{(0)}\\left(x\\right) - \\pi\\left(1\\right)  p^{(1)}\\left(x\\right) \\,\\right|\\right)\\\\\n&= 1-  \\frac12\\left(1 +\n\\sum_{x\\in\\mathcal{X}}\\left|\\,\\pi\\left(0\\right)  p^{(0)}\\left(x\\right) - \\pi\\left(1\\right)  p^{(1)}\\left(x\\right) \\,\\right|\\right)\\\\\n&= \\frac12\\left(1 -\n\\sum_{x\\in\\mathcal{X}}\\left|\\,\\pi\\left(0\\right)  p^{(0)}\\left(x\\right) - \\pi\\left(1\\right)  p^{(1)}\\left(x\\right) \\,\\right|\\right).\n\\end{align*}\\]\n\nDefinition 1 (全変動距離) 高々可算集合 \\(\\mathcal{X}\\) 上の関数 \\(f\\) について、 \\(\\|f\\|_1 \\coloneqq \\sum_{x\\in\\mathcal{X}} \\left|\\, f(x)\\,\\right|\\) と定義する。 また、\\(\\mathcal{X}\\) 上の確率質量関数 \\(p^{(0)}\\), \\(p^{(1)}\\) について、全変動距離を以下で定義する。 \\[\\begin{align*}\nd_{\\mathrm{TV}}(p^{(0)},\\, p^{(1)}) &\\coloneqq \\frac12\\left\\|\\, p^{(0)}-p^{(1)}\\,\\right\\|_1\n\\end{align*}\\]\n\nこれらの記法を用いると、 \\[\\begin{align*}\nP_{\\mathrm{err}}(\\widehat{\\theta}_\\mathrm{MAP})&=\\frac12\\left(1-\\left\\|\\pi(0)p^{(0)} - \\pi(1)p^{(1)}\\right\\|_1\\right)\n\\end{align*}\\] と表せる。また、\\(\\pi(0)=\\pi(1)=1/2\\) のとき、 \\[\\begin{align*}\nP_{\\mathrm{err}}(\\widehat{\\theta}_\\mathrm{MAP})&=\\frac12\\left(1-d_{\\mathrm{TV}}(p^{(0)},\\,p^{(1)})\\right).\n\\end{align*}\\]"
  },
  {
    "objectID": "slides/05_bayes.html#損失関数とベイズリスク",
    "href": "slides/05_bayes.html#損失関数とベイズリスク",
    "title": "確率論",
    "section": "損失関数とベイズリスク",
    "text": "損失関数とベイズリスク\nパラメータが取り得る値の集合が実数の部分集合 \\(\\Theta\\subseteq\\mathbb{R}\\) であると仮定する。 真のパラメータとその推定値の間の「誤差」を表す関数 \\(L\\colon\\Theta\\times\\mathbb{R}\\to\\mathbb{R}_{\\ge 0}\\) を損失関数と呼ぶ。 また、期待損失 \\(R\\colon\\Theta\\times(\\mathcal{X}\\to\\mathbb{R})\\to\\mathbb{R}_{\\ge 0}\\) を \\[\\begin{align*}\nR(\\theta,\\,\\widehat{\\theta}) &\\coloneqq \\expt{L(\\theta,\\,\\widehat{\\theta}(X))\\mid\\theta}\\\\\n&=\\sum_{x\\in\\mathcal{X}} L(\\theta,\\,\\widehat{\\theta}(x)) p(x\\mid\\theta)\n\\end{align*}\\] と定義する。 また、ベイズリスク \\(\\rho\\colon \\mathcal{P}(\\Theta)\\times(\\mathcal{X}\\to\\mathbb{R})\\to\\mathbb{R}_{\\ge 0}\\) を \\[\\begin{align*}\n\\rho(\\pi, \\widehat{\\theta})&\\coloneqq  \\expt{L(\\theta,\\,\\widehat{\\theta}(X))}\\\\\n&=\\sum_{\\theta\\in\\Theta}\\sum_{x\\in\\mathcal{X}} L(\\theta,\\,\\widehat{\\theta}(x)) p(x\\mid\\theta)\\pi(\\theta)\n\\end{align*}\\] と定義する。 \\(\\Theta\\subseteq\\mathbb{R}\\) が非可算無限集合の場合は \\(\\pi(\\theta)\\) を確率密度関数とし、 \\[\\begin{align*}\n\\rho(\\pi, \\widehat{\\theta})&\\coloneqq  \\expt{L(\\theta,\\,\\widehat{\\theta}(X))}\\\\\n&=\\int\\sum_{x\\in\\mathcal{X}} L(\\theta,\\,\\widehat{\\theta}(x)) p(x\\mid\\theta)\\pi(\\theta)\\mathrm{d}\\theta\n\\end{align*}\\] と定義する。 このとき、 \\(p(x\\mid\\theta)\\) は条件付き確率というより、\\(\\theta\\in\\Theta\\) というパラメータを持った確率質量関数(\\(\\theta\\in\\Theta\\) から定まる確率質量関数)と理解すれば十分である。"
  },
  {
    "objectID": "slides/05_bayes.html#損失関数の例",
    "href": "slides/05_bayes.html#損失関数の例",
    "title": "確率論",
    "section": "損失関数の例",
    "text": "損失関数の例\n例えば \\(\\Theta\\) が高々可算集合で、 \\[\\begin{align*}\nL(\\theta,\\,\\theta') &= \\mathbb{I}\\{\\theta\\ne \\theta'\\}\\qquad\\forall\\theta,\\theta'\\in\\Theta\n\\end{align*}\\] と定義すると、ベイズリスク \\(\\rho(\\pi, \\widehat{\\theta})\\) は推定関数 \\(\\widehat{\\theta}\\) の誤り確率 \\(P_\\mathrm{err}(\\widehat{\\theta})\\) である。\nその他の重要な損失関数の例として二乗誤差がある。 \\[\\begin{align*}\nL(\\theta,\\,\\theta') &= (\\theta-\\theta')^2.\n\\end{align*}\\]"
  },
  {
    "objectID": "slides/05_bayes.html#ベイズリスクの最小化",
    "href": "slides/05_bayes.html#ベイズリスクの最小化",
    "title": "確率論",
    "section": "ベイズリスクの最小化",
    "text": "ベイズリスクの最小化\n損失関数 \\(L\\) を定めたときに、ベイズリスクを最小化する推定関数 \\[\\begin{align*}\n\\widehat{\\theta} &= \\arg\\min_{\\widehat{\\theta}} \\rho(\\pi, \\widehat{\\theta})\\\\\n\\iff \\widehat{\\theta}(x) &= \\arg\\min_{\\theta'\\in\\Theta} \\sum_{\\theta\\in\\Theta} L(\\theta,\\,\\theta') p(x\\mid\\theta)\\pi(\\theta)\\qquad\\forall x\\in\\mathcal{X}\\\\\n\\iff \\widehat{\\theta}(x) &= \\arg\\min_{\\theta'\\in\\Theta} \\sum_{\\theta\\in\\Theta} L(\\theta,\\,\\theta') p(\\theta\\mid x)p(x)\\qquad\\forall x\\in\\mathcal{X}\\\\\n\\iff \\widehat{\\theta}(x) &= \\arg\\min_{\\theta'\\in\\Theta} \\sum_{\\theta\\in\\Theta} L(\\theta,\\,\\theta') p(\\theta\\mid x)\\qquad\\forall x\\in\\mathcal{X}\\\\\n\\end{align*}\\] ここで、 \\[\\begin{align*}\n\\expt{L(\\theta,\\,\\theta')\\mid x}&=  \\sum_{\\theta\\in\\Theta} L(\\theta,\\,\\theta') p(\\theta\\mid x)\\qquad\\forall x\\in\\mathcal{X}\n\\end{align*}\\] を損失関数の事後平均という。 各 \\(x\\in\\mathcal{X}\\) について、\\(\\theta'=\\widehat{\\theta}(x)\\) が損失関数の事後平均を最小化するとき、ベイズリスクを最小化する。"
  },
  {
    "objectID": "slides/05_bayes.html#損失関数が凸で微分可能な場合",
    "href": "slides/05_bayes.html#損失関数が凸で微分可能な場合",
    "title": "確率論",
    "section": "損失関数が凸で微分可能な場合",
    "text": "損失関数が凸で微分可能な場合\n損失関数が \\(L(\\theta,\\,\\theta')\\) が \\(\\theta\\in\\Theta\\) を固定したときに \\(\\theta'\\) について凸関数であるとき、事後平均 \\(\\expt{L(\\theta,\\,\\theta')\\mid x}\\) も \\(\\theta'\\) について凸関数となる(凸関数の非負倍は凸関数であり、凸関数の和は凸関数なので)。 さらに、\\(L(\\theta,\\,\\theta')\\) が \\(\\theta'\\) について微分可能なとき、 \\[\\begin{align*}\n\\frac{\\partial \\expt{L(\\theta,\\,\\theta')\\mid x}}{\\partial\\, \\theta'}&=  \\sum_{\\theta\\in\\Theta} \\frac{\\partial L(\\theta,\\,\\theta')}{\\partial\\, \\theta'} p(\\theta\\mid x)=0\\qquad\\forall x\\in\\mathcal{X}\n\\end{align*}\\] を満たす \\(\\theta'\\) を \\(\\widehat{\\theta}(x)\\) として選択するのが最適である。 二乗誤差 \\(L(\\theta,\\,\\theta')=(\\theta-\\theta')^2\\) のとき、この条件は \\[\\begin{align*}\n0&=\\sum_{\\theta} 2(\\theta'-\\theta) p(\\theta\\mid x)\n=2\\left(\\theta' - \\sum_{\\theta}\\theta p(\\theta\\mid x)\\right)\n\\end{align*}\\] となり、 \\[\\begin{align*}\n\\widehat{\\theta}(x) &= \\sum_\\theta \\theta p(\\theta\\mid x)\\qquad \\forall x\\in\\mathcal{X}\n\\end{align*}\\] とするのが最適であることが分かる。この右辺の値をパラメータ \\(\\theta\\) の事後平均という。"
  },
  {
    "objectID": "slides/05_bayes.html#今週の課題",
    "href": "slides/05_bayes.html#今週の課題",
    "title": "確率論",
    "section": "今週の課題",
    "text": "今週の課題\n\\(\\Theta=\\{0,1\\}\\), \\(\\mathcal{X}=\\{0,1\\}\\) とする。 事前確率と尤度を \\[\\begin{align*}\n\\pi(0) &= 1/3&\\pi(1)=2/3\\\\\np(x=0\\mid \\theta=0) &= 1/3&\np(x=1\\mid \\theta=0) &= 2/3\\\\\np(x=0\\mid \\theta=1) &= 1/4&\np(x=1\\mid \\theta=1) &= 3/4\n\\end{align*}\\] とする。\nこのとき、以下の問に答えよ\n\n\nMAP推定関数 \\(\\widehat{\\theta}_{\\mathrm{MAP}}(x)\\) と最尤推定関数 \\(\\widehat{\\theta}_{\\mathrm{ML}}(x)\\) をもとめよ。\n損失関数を \\[\\begin{align*}\nL(0,0) &= L(1,1) = 0,& L(0,1) &= 1,& L(1,0) &= 3\n\\end{align*}\\] としたときにベイズリスクを最小化する推定量 \\(\\widehat{\\theta}(x)\\) をもとめよ。"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Home",
    "section": "",
    "text": "確率・統計基礎の授業ページです。"
  },
  {
    "objectID": "slides.html",
    "href": "slides.html",
    "title": "Slides",
    "section": "",
    "text": "講義スライド\n\n集合論と確率空間\n確率変数\n複数の確率変数\n期待値、分散、モーメント\nベイズ推定\n仮説検定\n大数の法則\nクラメールの定理\n中心極限定理\nマルコフ連鎖"
  },
  {
    "objectID": "slides/07_large_numbers.html#大数の弱法則",
    "href": "slides/07_large_numbers.html#大数の弱法則",
    "title": "確率論",
    "section": "大数の弱法則",
    "text": "大数の弱法則\n表が出る確率が \\(1/2\\) のコインを100回独立に投げたときに表が出る回数は大体50回くらいになるだろう。 それを一般的な形で述べたものが大数の法則である。\n\nTheorem 1 (大数の弱法則(分散有限を仮定)) 確率変数 \\(X\\) が分散を持つとする。 確率変数 \\(X_1,\\dotsc,X_N\\) が独立同分布で \\(X\\) と同じ分布に従うとする。 このとき、任意の \\(\\epsilon&gt;0\\) について \\[\\begin{align*}\n\\lim_{N\\to\\infty}\\Pr\\left(\\left|\\frac1N\\sum_{i=1}^N X_i-\\expt{X}\\right|\\ge\\epsilon\\right) &= 0\n\\end{align*}\\] が成り立つ。\n\n\nProof. \\[\\begin{align*}\n\\Pr\\left(\\left|\\frac1n\\sum_{i=1}^N X_i-\\expt{X}\\right|\\ge\\epsilon\\right)\n&=  \\Pr\\left(\\left(\\frac1N\\sum_{i=1}^N X_i-\\expt{X}\\right)^2\\ge\\epsilon^2\\right) \\\\\n&=  \\Pr\\left(\\left(\\sum_{i=1}^N X_i-N\\expt{X}\\right)^2\\ge\\epsilon^2N^2\\right) \\\\\n&\\le \\frac{N\\var{X}}{\\epsilon^2N^2}\n= \\frac{\\var{X}}{\\epsilon^2N}\\longrightarrow 0.\n\\end{align*}\\]"
  },
  {
    "objectID": "slides/07_large_numbers.html#チェルノフ上界",
    "href": "slides/07_large_numbers.html#チェルノフ上界",
    "title": "確率論",
    "section": "チェルノフ上界",
    "text": "チェルノフ上界\n上記の大数の弱法則の証明では確率が0に収束するスピートは \\(O(1/N)\\) であった。 より詳しく確率が0にいくスピードを解析しよう。\n\nLemma 1 (チェルノフ上界) 任意の確率変数 \\(X\\) と \\(a\\in\\mathbb{R}\\) について、 \\[\\begin{align*}\n\\Pr\\left(X\\ge a\\right) &\\le \\frac{M_X(t)}{\\mathrm{e}^{at}}=\\mathrm{e}^{K_X(t)-at}\\qquad\\forall t\\ge 0\\\\\n\\Pr\\left(X\\le a\\right) &\\le \\frac{M_X(t)}{\\mathrm{e}^{at}}=\\mathrm{e}^{K_X(t)-at}\\qquad\\forall t\\le 0.\n\\end{align*}\\]\n\n\nProof. \\(t=0\\) のときは不等式の右辺は1となるので、不等式は自明に成り立つ。 任意の \\(t&gt;0\\) について、 \\[\\begin{align*}\n\\Pr\\left(X\\ge a\\right) &= \\Pr\\left(\\mathrm{e}^{tX}\\ge \\mathrm{e}^{ta}\\right)\\\\\n&\\le \\frac{M_X(t)}{\\mathrm{e}^{at}}\\qquad(\\text{マルコフの不等式}).\n\\end{align*}\\] が成り立つ。 もう一つの不等式も同様に示すことができる。\n\nマルコフの不等式は非負の確率変数にしか適用できないが、チェルノフ上界は任意の確率変数に適用できる。"
  },
  {
    "objectID": "slides/07_large_numbers.html#確率変数の和に対するチェルノフ上界",
    "href": "slides/07_large_numbers.html#確率変数の和に対するチェルノフ上界",
    "title": "確率論",
    "section": "確率変数の和に対するチェルノフ上界",
    "text": "確率変数の和に対するチェルノフ上界\n\nLemma 2 (確率変数の和に対するチェルノフ上界) 任意の確率変数 \\(X\\) と \\(a\\in\\mathbb{R}\\) について、 \\[\\begin{align*}\n\\Pr\\left(\\frac1N\\sum_{i=1}^N X_i\\ge a\\right) &\\le \\mathrm{e}^{-(at-K_X(t))N}\\qquad\\forall t\\ge 0\\\\\n\\Pr\\left(\\frac1N\\sum_{i=1}^N X_i\\le a\\right) &\\le \\mathrm{e}^{-(at-K_X(t))N}\\qquad\\forall t\\le 0.\n\\end{align*}\\]\n\n\nProof. \\[\\begin{align*}\n\\Pr\\left(\\frac1N\\sum_{i=1}^N X_i\\ge a\\right) &= \\Pr\\left(\\sum_{i=1}^N X_i\\ge aN\\right)\\\\\n&\\le \\mathrm{e}^{K_{\\sum_i X_i}(t) - atN}\\\\\n&= \\mathrm{e}^{(K_X(t) - at)N}\\\\\n\\end{align*}\\]\n\nこのようにチェルノフ上界を使うと \\(N\\) について指数関数の上界が得られる。 係数 \\(at-K_X(t)\\) が正であれば、確率は指数関数的に小さいことになる。 ここで、最適な \\(t\\) を選ぶことで、この係数 \\(at-K_X(t)\\) を最大化することを考える。"
  },
  {
    "objectID": "slides/07_large_numbers.html#キュムラント母関数の定義域",
    "href": "slides/07_large_numbers.html#キュムラント母関数の定義域",
    "title": "確率論",
    "section": "キュムラント母関数の定義域",
    "text": "キュムラント母関数の定義域\nキュムラント母関数 \\[\\begin{align*}\nK_X(t) &= \\log\\expt{\\mathrm{e}^{tX}}\n\\end{align*}\\] の性質を改めて考えよう。\nまず、\\(K_X(0)=0\\) である。\nある \\(t&gt;0\\) について、 \\(M_X(t)\\) が存在すると仮定すると、任意の \\(s\\in(0,t)\\) について \\[\\begin{align*}\nM_X(s) &= \\expt{\\mathrm{e}^{sX}}\\\\\n&= \\expt{\\mathrm{e}^{sX} \\mathbb{1}_{\\{X\\ge 0\\}}}\n+ \\expt{\\mathrm{e}^{sX} \\mathbb{1}_{\\{X&lt; 0\\}}}\\\\\n&\\le \\expt{\\mathrm{e}^{tX} \\mathbb{1}_{\\{X\\ge 0\\}}} + 1\\\\\n&\\le M_X(t) + 1 &lt; \\infty\n\\end{align*}\\] なので、\\(M_X(s)\\) も存在する。 同様に、ある \\(t&lt;0\\) について、 \\(M_X(t)\\) が存在すると仮定すると、任意の \\(s\\in(t,0)\\) について \\(M_X(s)\\) も存在する。 よって、\\(M_X(t)\\) や \\(K_X(t)\\) が存在する範囲は0を含む区間となる。 ここでいう区間とは一般的に空集合、もしくは \\(a&lt; b\\) について、 \\[\\begin{align*}\n[a,\\,a]\\quad\n(a,\\,b)\\quad\n[a,\\,b)\\quad\n(a,\\,b]\\quad\n[a,\\,b]\\quad\n(a,\\,\\infty)\\quad\n[a,\\,\\infty)\\quad\n(-\\infty,\\, b)\\quad\n(-\\infty,\\, b]\\quad\n(-\\infty,\\,\\infty)\n\\end{align*}\\] のいずれかの形の集合を指す。 この区間を \\(\\mathrm{dom}(K_X)\\) と表す。"
  },
  {
    "objectID": "slides/07_large_numbers.html#キュムラント母関数の微分",
    "href": "slides/07_large_numbers.html#キュムラント母関数の微分",
    "title": "確率論",
    "section": "キュムラント母関数の微分",
    "text": "キュムラント母関数の微分\n証明はしないが、キュムラント母関数 \\(K_X(t)\\) は \\(\\mathrm{dom}(K_X)\\) の内点で何回でも微分可能であり、無限和や積分を取る前に微分しても構わない。\n\\[\\begin{align*}\n\\frac{\\mathrm{d} K_X(t)}{\\mathrm{d}t} &= \\frac{\\expt{X\\mathrm{e}^{tX}}}{\\expt{\\mathrm{e}^{tX}}}\\\\\n\\frac{\\mathrm{d}^2 K_X(t)}{\\mathrm{d}t^2} &= \\frac{\\expt{X^2\\mathrm{e}^{tX}}\\expt{\\mathrm{e}^{tX}}-\\expt{X\\mathrm{e}^{tX}}^2}{\\expt{\\mathrm{e}^{tX}}^2}\\\\\n&= \\frac{\\expt{X^2\\mathrm{e}^{tX}}}{\\expt{\\mathrm{e}^{tX}}}-\\left(\\frac{\\expt{X\\mathrm{e}^{tX}}}{\\expt{\\mathrm{e}^{tX}}}\\right)^2\\\\\n&= \\frac{\\expt{\\left(X-\\frac{\\expt{X\\mathrm{e}^{tX}}}{\\expt{\\mathrm{e}^{tX}}}\\right)^2\\mathrm{e}^{tX}}}{\\expt{\\mathrm{e}^{tX}}}\\ge 0\n\\end{align*}\\]  また、\\(X\\)が決定的(\\(\\Pr(X=\\expt{X})=1\\))でない限り、\\(K_X\\) は \\(\\mathrm{dom}(K_X)\\) で狭義凸である。"
  },
  {
    "objectID": "slides/07_large_numbers.html#キュムラント母関数の性質",
    "href": "slides/07_large_numbers.html#キュムラント母関数の性質",
    "title": "確率論",
    "section": "キュムラント母関数の性質",
    "text": "キュムラント母関数の性質\nよって \\(X\\) のキュムラント母関数 \\(K_X(t)\\) が原点付近で存在すると仮定すると、\\(K_X(t)\\) は\n\n0を含む区間で定義され、\n原点を通り、\n凸関数で、\n原点の傾きは \\(\\expt{X}\\)\n\nであることが分かる。\nまた、キュムラント母関数の簡単な性質として以下が成り立つ。 任意の独立確率変数 \\(X\\) と \\(Y\\) と \\(a\\in\\mathbb{R}\\) について \\[\\begin{align*}\nK_{X+a}(t) &= \\log\\expt{\\mathrm{e}^{t(X+a)}} = \\log\\left(\\expt{\\mathrm{e}^{tX}}\\cdot \\mathrm{e}^{ta}\\right) = K_X(t) + at\\\\%\\quad\\text{for } t\\in\\mathrm{dom}(K_X)\\\\\nK_{aX}(t) &= \\log\\expt{\\mathrm{e}^{t(aX)}} = K_X(at)\\\\%\\qquad\\text{if } at\\in\\mathrm{dom}(K_X)\\\\\nK_{X+Y}(t) &= \\log\\expt{\\mathrm{e}^{t(X+Y)}} =\\log\\left(\\expt{\\mathrm{e}^{tX}}\\expt{\\mathrm{e}^{tY}}\\right) = K_X(t) + K_Y(t).\n%&\\hspace{17em}\\text{for } t\\in\\mathrm{dom}(K_X)\\cap\\mathrm{dom}(K_Y)\n\\end{align*}\\]"
  },
  {
    "objectID": "slides/07_large_numbers.html#ルジャンドル変換",
    "href": "slides/07_large_numbers.html#ルジャンドル変換",
    "title": "確率論",
    "section": "ルジャンドル変換",
    "text": "ルジャンドル変換\nチェルノフ上界に現れる係数 \\(at-K_X(t)\\) の最大化はルジャンドル変換を用いて \\(K_X^*(a)\\) と表せる。 ルジャンドル変換を定義する際は \\(+\\infty\\) という値を許して \\((-\\infty,\\,+\\infty]\\) を値域として考えると都合がよい。 このように \\(+\\infty\\) を値として許した場合にも凸性を通常の関数と同じように定義する。 一般に区間上で定義された凸関数を実数全体に拡張し、元の定義域の外で \\(+\\infty\\) を取ることにするとやはり凸関数になる。 また、\\(f\\colon\\mathbb{R}\\to(-\\infty,\\,+\\infty]\\) の有効領域を \\[\\begin{align*}\n\\mathrm{dom}(f) &\\coloneqq\\left\\{x\\in\\mathbb{R}\\mid f(x)&lt;+\\infty\\right\\}\n\\end{align*}\\] と定義する。 凸関数の有効領域は区間になる。\n\nDefinition 1 (ルジャンドル変換)  \n\n凸関数 \\(f\\colon \\mathbb{R}\\to (-\\infty,\\,+\\infty]\\) のルジャンドル変換 \\(f^*\\colon \\mathbb{R}\\to (-\\infty,\\,+\\infty]\\) を以下で定義する。 \\[\\begin{align*}\nf^*(a) &\\coloneqq \\sup_{t\\in \\mathbb{R}}\\left\\{at-f(t)\\right\\}.\n\\end{align*}\\]"
  },
  {
    "objectID": "slides/07_large_numbers.html#ルジャンドル変換の理解",
    "href": "slides/07_large_numbers.html#ルジャンドル変換の理解",
    "title": "確率論",
    "section": "ルジャンドル変換の理解",
    "text": "ルジャンドル変換の理解\nルジャンドル変換において \\(f\\) は凸関数なので、\\(at-f(t)\\) は凹関数(上に凸の関数)になる。 簡単のため \\(f\\) が \\(\\mathrm{dom}(f)\\) の内点で微分可能であると仮定しよう。 このとき、\n\n\\(at-f(t)\\) の微分が 0 になる点、つまり \\(f'(t_a) = a\\) を満たす \\(t_a\\in \\mathrm{dom}(f)^\\circ\\) が存在するとき、\\(t_a\\) で \\(at-f(t)\\) は最大化される。\nそのような \\(t_a\\in \\mathrm{dom}(f)^\\circ\\) が存在しないときは、\\(\\mathrm{dom}(f)\\) の端への極限で \\(\\sup\\) が達成される。\n\n凸関数は \\(\\mathrm{dom}(f)\\) の上では接線の集合で表すことができる。 接線 \\(ax+b\\) は傾き \\(a\\) と切片 \\(b\\) のペアで表すことができる。 傾き \\(a\\) を持つ \\(f\\) の接線は \\[\\begin{align*}\na(x-t_a) + f(t_a) &= ax - (at_a - f(t_a)) = ax - f^*(a)\n\\end{align*}\\] この傾き \\(a\\) から接線の切片の \\(-1\\)倍である \\(-b\\) への関数が \\(f^*\\) である。\n例えば \\(f\\) が0で微分可能であるとき \\[\\begin{align*}\nf^*(f'(0)) &= 0\n\\end{align*}\\] である。"
  },
  {
    "objectID": "slides/07_large_numbers.html#ルジャンドル変換の理解-1",
    "href": "slides/07_large_numbers.html#ルジャンドル変換の理解-1",
    "title": "確率論",
    "section": "ルジャンドル変換の理解",
    "text": "ルジャンドル変換の理解\nまた、ルジャンドル変換 \\(f^*\\) は凸関数である。\n\nLemma 3 凸関数 \\(f\\colon \\mathbb{R}\\to (-\\infty,\\,+\\infty]\\) のルジャンドル変換 \\(f^*\\colon \\mathbb{R}\\to (-\\infty,\\,+\\infty]\\) は凸関数である。\n\n\nProof. 任意の \\(a_1,a_2\\in \\mathbb{R}\\) と \\(\\lambda\\in[0,1]\\) について \\[\\begin{align*}\nf^*(\\lambda a_1+ (1-\\lambda)a_2) &= \\sup_{t\\in \\mathbb{R}}\\left\\{(\\lambda a_1+(1-\\lambda)a_2)t - f(t)\\right\\}\\\\\n&= \\sup_{t\\in \\mathbb{R}}\\left\\{\\lambda (a_1t - f(t))+(1-\\lambda)(a_2t - f(t))\\right\\}\\\\\n&\\le \\sup_{t\\in \\mathbb{R}}\\left\\{\\lambda (a_1t - f(t))\\right\\}+\\sup_{t\\in \\mathbb{R}}\\left\\{(1-\\lambda)(a_2t - f(t))\\right\\}\\\\\n&\\le \\lambda f^*(a_1) + (1-\\lambda) f^*(a_2).\n\\end{align*}\\]\n\nルジャンドル変換を凸でない関数 \\(f\\) についても同様に定義した場合でも、ルジャンドル変換 \\(f^*\\) は同様に凸関数となる。"
  },
  {
    "objectID": "slides/07_large_numbers.html#今週の課題",
    "href": "slides/07_large_numbers.html#今週の課題",
    "title": "確率論",
    "section": "今週の課題",
    "text": "今週の課題\n以下の凸関数をルジャンドル変換せよ\n\n\\(f(t) = t^2 + bt + c\\).\n\\(f(t) = \\mathrm{e}^t\\)."
  },
  {
    "objectID": "slides/01_probability.html#確率論とは",
    "href": "slides/01_probability.html#確率論とは",
    "title": "確率論",
    "section": "確率論とは",
    "text": "確率論とは\n\n\n世の中のランダムな事象を数学的に記述したもの。\n統計・機械学習の基礎となっている。\n確率論はコルモゴロフが1933年に導入した測度論的確率論によって定式化するのが一般的。"
  },
  {
    "objectID": "slides/01_probability.html#統計学とは",
    "href": "slides/01_probability.html#統計学とは",
    "title": "確率論",
    "section": "統計学とは",
    "text": "統計学とは\n統計学はデータから未来を予測したり意思決定をするための方法論。\n\nこの薬は効果がありますか？\nこのユーザーにどの製品が売れますか？\nこの時間の道路の混雑具合は？\n\n確率論は統計学の基礎となる。"
  },
  {
    "objectID": "slides/01_probability.html#確率論の数学モデルとは",
    "href": "slides/01_probability.html#確率論の数学モデルとは",
    "title": "確率論",
    "section": "確率論の数学モデルとは？",
    "text": "確率論の数学モデルとは？\n\n測度論！\n\n\n\n確率は面積(\\(=\\)測度)のようなもの。\n数学的にに様々な結果(大数の法則、大偏差原理、中心極限定理)が証明できる。\nとても重要だが勉強するのは3年生以降(解析学要論Ⅱ、確率論)。\nこの授業では測度論には深入りせず、数学的に厳密な議論なごまかしながら確率・統計について学ぶ。"
  },
  {
    "objectID": "slides/01_probability.html#この授業の進め方",
    "href": "slides/01_probability.html#この授業の進め方",
    "title": "確率論",
    "section": "この授業の進め方",
    "text": "この授業の進め方\n\n\n講義資料は https://prob-stat.github.io/ にすべてある。ここだけ見ればOK。\nその他の連絡事項はTACTを通じて行う。\n毎回課題を出す。提出はTACTを用いる。\n成績は課題50% 期末試験50%.\n課題の内容と授業資料は上記のページにあるので、授業は出席しなくても構わない。"
  },
  {
    "objectID": "slides/01_probability.html#集合",
    "href": "slides/01_probability.html#集合",
    "title": "確率論",
    "section": "集合",
    "text": "集合\n集合 \\(=\\) 「ものの集まり」\n\\[\\begin{align*}\nA &= \\{1,2,3\\}&\nB &= \\{赤、青、黄、緑\\}\n\\end{align*}\\]\n集合を構成するものを要素もしくは元という。\n\n\\(x\\in A\\): 要素 \\(x\\) は集合 \\(A\\) に含まれる。\n\\(x\\notin A\\): 要素 \\(x\\) は集合 \\(A\\) に含まない。\n\\(|A|\\): 集合 \\(A\\) の要素数\n\n要素数が無限の集合を考えることもできる。 例えば\n\\[\\begin{align*}\nA&=\\{n\\in\\mathbb{N}\\mid \\textsf{$n$ は偶数}\\},& B&=\\{x\\in\\mathbb{R}\\mid \\textsf{$x$ は無理数} \\}\n\\end{align*}\\]\nという集合は無限集合の例となる。\n\n\\(\\varnothing\\): 空集合 \\(\\coloneqq\\) 要素数が 0 の集合 。"
  },
  {
    "objectID": "slides/01_probability.html#集合の関係",
    "href": "slides/01_probability.html#集合の関係",
    "title": "確率論",
    "section": "集合の関係",
    "text": "集合の関係\n集合 \\(A\\) の要素がすべて集合 \\(B\\) に含まれるとき、\\(A\\) を \\(B\\) の部分集合 という。\n\\[\\begin{align*}\nA\\subseteq B &\\defiff \\forall x\\,(x\\in A\\implies x \\in B)&\\textsf{($A$ は $B$ の部分集合)}\\\\\nA\\supseteq B &\\defiff B\\subseteq A&\\textsf{($A$ は $B$ の上位集合)}\\\\\nA = B &\\defiff (A\\subseteq B\\land A\\supseteq B)& \\textsf{($A$ と $B$ は等しい)}\\\\\nA \\ne B &\\defiff \\lnot(A = B)& \\textsf{($A$ と $B$ は等しくない)}\n\\end{align*}\\]\nまた、\n\\[\\begin{align*}\nA\\subsetneq B &\\defiff (A\\subseteq B \\land A\\ne B)&\\textsf{($A$ は $B$ の真部分集合)}\\\\\nA\\supsetneq B &\\defiff B\\subsetneq A&\\textsf{($A$ は $B$ の真上位集合)}\n\\end{align*}\\]\nとする。 部分集合や上位集合のような集合間の関係を包含関係という。 集合 \\(A,\\,B\\) について、\\(A\\subseteq B\\) と \\(B\\subseteq A\\) のどちらかが成り立つとき、「\\(A\\) と \\(B\\) の間に包含関係が成り立 つ」という。\n包含関係は以下の三条件を満たす(半順序の公理)。\n\n(反射律) \\(\\quad A\\subseteq A\\).\n(反対称律) \\(\\quad (A\\subseteq B\\land B\\subseteq A) \\iff A = B\\).\n(推移律) \\(\\quad (A\\subseteq B\\land B\\subseteq C)\\implies A\\subseteq C\\)."
  },
  {
    "objectID": "slides/01_probability.html#集合の演算",
    "href": "slides/01_probability.html#集合の演算",
    "title": "確率論",
    "section": "集合の演算",
    "text": "集合の演算\n複数の集合から新しい集合を作る演算がある。\n\\[\\begin{align*}\nA\\cup B &\\coloneqq\\left\\{x\\mid x\\in A \\textsf{ または } x \\in B\\right\\}\\qquad\\textsf{(和集合)}\\\\\nA\\cap B &\\coloneqq \\left\\{x\\mid x\\in A \\textsf{ かつ } x \\in B\\right\\}\\qquad\\textsf{(積集合)}\\\\\nA\\setminus B &\\coloneqq \\left\\{x\\mid x\\in A \\textsf{ かつ } x \\notin B\\right\\}\\qquad\\textsf{(差集合)}\n\\end{align*}\\]\nこれらの演算は以下の法則を満たす。\n\n(交換法則) \\(\\quad A\\cup B = B\\cup A, \\quad A\\cap B = B\\cap A\\).\n(結合法則) \\(\\quad (A\\cup B)\\cup C = A\\cup (B\\cup C), \\quad (A\\cap B)\\cap C=A\\cap(B\\cap C)\\).\n(分配法則) \\(\\quad A\\cup(B\\cap C) = (A\\cup B)\\cap (A\\cup C),\\quad A\\cap (B\\cup C) = (A\\cap B)\\cup (A\\cap C)\\).\n(冪等法則) \\(\\quad A \\cup A = A, \\quad A\\cap A = A\\).\n(吸収法則) \\(\\quad A \\cup (A\\cap B) = A, \\quad A\\cap (A\\cup B) = A\\).\n\\(A\\cup \\varnothing = A,\\quad A\\cap\\varnothing = \\varnothing\\).\n\n和集合と積集合は結合法則満たすことから、括弧を使わずに \\(A\\cup B\\cup C\\) と表すことができる。\n集合 \\(A\\) と \\(B\\) が \\(A\\cap B=\\varnothing\\) を満たすとき、確率論文脈では、「\\(A\\) と \\(B\\) は排反である」(集合論文脈では「互いに素である」)という。"
  },
  {
    "objectID": "slides/01_probability.html#補集合",
    "href": "slides/01_probability.html#補集合",
    "title": "確率論",
    "section": "補集合",
    "text": "補集合\nまた、全体の集合 \\(\\Omega\\) というのが文脈上存在する場合は、\n\\[\\begin{align*}\nA^\\mathrm{c} &\\coloneqq \\Omega\\setminus A\\qquad\\textsf{(補集合)}\n\\end{align*}\\]\nと定義する。\n補集合に関連して以下の法則を満たす。\n\n\\(\\Omega^\\mathrm{c} = \\varnothing,\\quad \\varnothing^\\mathrm{c} = \\Omega\\).\n\\(A\\cup \\Omega = \\Omega,\\quad A\\cap\\Omega = A\\).\n\\(A\\cup A^\\mathrm{c} = \\Omega,\\quad A\\cap A^\\mathrm{c} =\\varnothing\\).\n(二重補集合の法則) \\(\\quad (A^\\mathrm{c})^\\mathrm{c} = A\\).\n(ド・モルガンの法則) \\(\\quad(A\\cup B)^\\mathrm{c} = A^\\mathrm{c} \\cap B^\\mathrm{c},\\quad(A\\cap B)^\\mathrm{c} = A^\\mathrm{c} \\cup B^\\mathrm{c}\\)"
  },
  {
    "objectID": "slides/01_probability.html#集合族",
    "href": "slides/01_probability.html#集合族",
    "title": "確率論",
    "section": "集合族",
    "text": "集合族\n集合 \\(\\Omega\\) について \\(2^\\Omega\\) を \\(\\Omega\\) のすべての部分集合からなる集合を表す。\n\\[\\begin{align*}\n2^\\Omega &\\coloneqq \\left\\{A\\subseteq\\Omega\\right\\}.\n\\end{align*}\\]\nこれを \\(\\Omega\\) の冪集合という。 例えば \\(\\Omega=\\{1,2,3\\}\\) のとき、\n\\[\n2^\\Omega = \\left\\{\\varnothing, \\{1\\}, \\{2\\}, \\{3\\}, \\{1,2\\},\\{2,3\\},\\{1,3\\},\\{1,2,3\\}\\right\\}\n\\]\nである。 \\(\\Omega\\) が有限集合のとき、\\(|2^\\Omega|=2^{|\\Omega|}\\) が成り立つ。 また、\\(2^\\Omega\\) の部分集合を \\(\\Omega\\) 上の(部分)集合族と呼ぶ。 集合 \\(\\Lambda\\) の各 \\(\\lambda\\in\\Lambda\\) に対して集合 \\(A_\\lambda\\subseteq\\Omega\\) が存在するとき、集合族\n\\[\n\\left\\{A_\\lambda\\subseteq\\Omega\\mid \\lambda\\in\\Lambda\\right\\}\\subseteq 2^\\Omega\n\\]\nを添字集合 \\(\\Lambda\\) で添字付けられた \\(\\Omega\\) 上の集合族という。\n添字集合が有限集合の場合は集合族全体の和集合や積集合は二つの集合の和集合と積集合の定義を繰り返し用いることで定義できる。 それらは以下のように表す。\n\\[\n\\bigcup_{\\lambda\\in\\Lambda} A_\\lambda \\quad,\\quad\n\\bigcap_{\\lambda\\in\\Lambda} A_\\lambda.\n\\]"
  },
  {
    "objectID": "slides/01_probability.html#ドモルガンの法則",
    "href": "slides/01_probability.html#ドモルガンの法則",
    "title": "確率論",
    "section": "ド・モルガンの法則",
    "text": "ド・モルガンの法則\n添字集合 \\(\\Lambda\\) が無限集合の場合は和集合と積集合を以下で定義する。\n\\[\\begin{align*}\n\\bigcup_{\\lambda\\in\\Lambda} A_\\lambda\n&\\coloneqq\n\\left\\{x\\in\\Omega\\mid \\exists \\lambda\\in\\Lambda,\\quad x\\in A_\\lambda\\right\\}\\\\\n\\bigcap_{\\lambda\\in\\Lambda} A_\\lambda\n&\\coloneqq\n\\left\\{x\\in\\Omega\\mid \\forall \\lambda\\in\\Lambda,\\quad x\\in A_\\lambda\\right\\}\n\\end{align*}\\]\nこの定義は \\(\\Lambda\\) が有限集合の場合も正しいものである。 この場合もド・モルガンの法則は成り立つ。つまり、\n\\[\\begin{align*}\n\\left(\\bigcup_{\\lambda\\in\\Lambda} A_\\lambda\\right)^\\mathrm{c}\n&=\n\\bigcap_{\\lambda\\in\\Lambda} A_\\lambda^\\mathrm{c},&\n\\left(\\bigcap_{\\lambda\\in\\Lambda} A_\\lambda\\right)^\\mathrm{c}\n&=\n\\bigcup_{\\lambda\\in\\Lambda} A_\\lambda^\\mathrm{c}\n\\end{align*}\\]\nが成り立つ。\n証明: \\(x\\in\\Omega\\) について、 \\[\\begin{align*}\nx\\in\\left(\\bigcup_{\\lambda\\in\\Lambda} A_\\lambda\\right)^\\mathrm{c}\n&\\iff x\\notin\\left(\\bigcup_{\\lambda\\in\\Lambda} A_\\lambda\\right)\\\\\n&\\iff \\lnot\\left(\\exists\\lambda\\in\\Lambda,\\quad x\\in A_\\lambda\\right)\\\\\n&\\iff \\forall\\lambda\\in\\Lambda,\\quad x\\notin A_\\lambda\\\\\n&\\iff \\forall\\lambda\\in\\Lambda,\\quad x\\in A_\\lambda^\\mathrm{c}\\\\\n&\\iff x\\in\\bigcap_{\\lambda\\in\\Lambda} A_\\lambda^{\\mathrm{c}}.\n\\end{align*}\\]"
  },
  {
    "objectID": "slides/01_probability.html#標本空間と確率",
    "href": "slides/01_probability.html#標本空間と確率",
    "title": "確率論",
    "section": "標本空間と確率",
    "text": "標本空間と確率\n\n\\(\\Omega\\colon\\) 集合。これの部分集合に確率が与えられる\n\\(P\\colon 2^\\Omega\\to\\mathbb{R}_{\\ge 0}.\\) 確率を与える関数\n\n\nExample 1  \n\n\n\\(\\Omega=\\{表,裏\\}\\).\n\\(P(\\varnothing)= 0,\\, P(\\{\\mathrm{表}\\})=P(\\{\\mathrm{裏}\\})=\\frac12,\\,P(\\{\\mathrm{表},\\mathrm{裏}\\})=1\\).\n\n\n\n\n\\(\\Omega=\\{1,2,3,4,5,6\\}\\).\n\\(P(A) = \\frac{|A|}6\\quad\\forall A\\subseteq\\Omega\\).\n\n\n\n\n\\(\\Omega=\\{晴,雨,雪\\}\\).\n\\(P(\\varnothing)= 0,\\, P(\\{晴\\})=0.7,\\, P(\\{雨\\})=0.2,\\,P(\\{雪\\})=0.1\\), \\(P(\\{晴,雨\\})=0.9,\\, P(\\{雨,雪\\})=0.3,\\, P(\\{雪,晴\\})=0.8\\), \\(P(\\{晴,雨,雪\\})=1\\)."
  },
  {
    "objectID": "slides/01_probability.html#確率論の公理有限版",
    "href": "slides/01_probability.html#確率論の公理有限版",
    "title": "確率論",
    "section": "確率論の公理有限版",
    "text": "確率論の公理有限版\n\n\\(\\Omega\\colon\\) 有限集合(標本空間)\n\\(P\\colon 2^\\Omega\\to\\mathbb{R}_{\\ge 0}\\) (確率測度)\n\n確率の公理\n\n\\(P(\\Omega)=1\\).\n\\(\\forall A, B\\subseteq\\Omega\\), \\(A\\cap B=\\varnothing\\implies P(A\\cup B)=P(A)+P(B)\\) (有限加法性).\n\nこの公理を満たすペア \\((\\Omega,\\, P)\\) を確率空間という。\n例えば\n\\[\n   P(\\{\\text{\"晴\"}, \\text{\"雨\"}\\}) = P(\\{\\text{\"晴\"}\\}) + P(\\{\\text{\"雨\"}\\})\n\\] という等式は「晴れもしくは雨になる確率 \\(=\\) 晴れになる確率 \\(+\\) 雨になる確率」という意味の等式になる。\nこのように \\(\\Omega\\) が有限集合の場合、各 \\(\\omega\\in\\Omega\\) に対する一つの要素の確率 \\(P(\\{\\omega\\})\\) から \\(P\\) が定まる。\n\n\\(\\Omega\\) を無限集合にしたい場合はどうする？"
  },
  {
    "objectID": "slides/01_probability.html#確率論の公理可算版",
    "href": "slides/01_probability.html#確率論の公理可算版",
    "title": "確率論",
    "section": "確率論の公理可算版",
    "text": "確率論の公理可算版\n\n\\(\\Omega\\colon\\) 高々可算集合(標本空間)\n\\(P\\colon 2^\\Omega\\to\\mathbb{R}_{\\ge 0}\\) (確率測度)\n\n確率の公理\n\n\\(P(\\Omega)=1\\). \n\\(\\forall (A_n\\subseteq\\Omega)_{n\\ge 0}\\), \\(\\forall i\\ne j,\\, A_i\\cap A_j=\\varnothing\\implies P\\left(\\bigcup_{n\\ge0} A_n\\right)=\\sum_{n\\ge0} P(A_n)\\) (完全加法性, \\(\\sigma\\)-加法性).\n\n無限和 \\(\\sum_{n\\ge0} P(A_n)\\) において \\(P(A_n)\\ge 0\\) なので、この無限和が存在するときは絶対収束する。 よって和の順序を並び変えても収束値は変わらないことが分かる。実際、左辺にある \\(\\bigcup_{n\\ge 0} A_n\\) は事象 \\(A_n\\) の並び順によらない。\n\\(\\Omega\\) が高々可算集合の場合、任意の \\(A\\subseteq\\Omega\\) も高々可算集合なので、\n\\[\\begin{align*}\nP(A) &= P\\left(\\bigcup_{\\omega\\in A} \\{\\omega\\}\\right)\\\\\n&= \\sum_{\\omega\\in A} P(\\{\\omega\\})\n\\end{align*}\\] が成り立つ。 よって各 \\(\\omega\\in\\Omega\\) に対する一つの要素の確率 \\(P(\\{\\omega\\})\\) から \\(P\\) が定まる。"
  },
  {
    "objectID": "slides/01_probability.html#確率論の公理最終版",
    "href": "slides/01_probability.html#確率論の公理最終版",
    "title": "確率論",
    "section": "確率論の公理最終版?",
    "text": "確率論の公理最終版?\nこれでよいのか？\n\n\\(\\Omega\\colon\\) (非可算でもよい)集合(標本空間)\n\\(P\\colon 2^\\Omega\\to\\mathbb{R}_{\\ge 0}\\) (確率測度)\n\n確率の公理\n\n\\(P(\\Omega)=1\\). \n\\(\\forall (A_n\\subseteq\\Omega)_{n\\ge 0}\\), \\(\\forall i\\ne j,\\, A_i\\cap A_j=\\varnothing\\implies P\\left(\\bigcup_{n\\ge0} A_n\\right)=\\sum_{n\\ge0} P(A_n)\\) (完全加法性, \\(\\sigma\\)-加法性).\n\n\nこれで大丈夫？"
  },
  {
    "objectID": "slides/01_probability.html#ダメ完全加法性選択公理",
    "href": "slides/01_probability.html#ダメ完全加法性選択公理",
    "title": "確率論",
    "section": "ダメ(完全加法性+選択公理)",
    "text": "ダメ(完全加法性+選択公理)\n\n\\(\\Omega=[0,1)\\).\n\\(\\forall c\\in\\Omega,\\, A\\subseteq\\Omega,\\, P(A+c) = P(A)\\) where \\(A+c\\coloneqq\\{a+c-\\lfloor a+c\\rfloor\\mid a\\in A\\}\\).\n\n選択公理を仮定するとそのような確率空間は存在しない。\n\\(\\Omega\\) の上の同値関係を \\(x\\sim y\\stackrel{\\mathrm{def}}{\\iff} x-y \\in\\mathbb{Q}\\)と定義する。\n\\(\\Omega\\) の上の同値類から一つずつ要素を選んで集合 \\(V\\) を作る(選択公理)。\n\\[\\begin{align*}\n1 = P([0,1)) &= P\\left(\\bigcup_{q\\in\\mathbb{Q}\\cap[0,1)} (V + q)\\right)\\\\\n&= \\sum_{q\\in\\mathbb{Q}\\cap[0,1)} P\\left(V + q\\right)\\qquad\\textsf{(完全加法性)}\\\\\n&= \\sum_{q\\in\\mathbb{Q}\\cap[0,1)} P\\left(V\\right)\\qquad\\textsf{(平行移動不変性).}\n\\end{align*}\\] 同じ値を無限回足して1にはできない。"
  },
  {
    "objectID": "slides/01_probability.html#ちゃんとした確率論の公理",
    "href": "slides/01_probability.html#ちゃんとした確率論の公理",
    "title": "確率論",
    "section": "ちゃんとした確率論の公理",
    "text": "ちゃんとした確率論の公理\n確率空間 \\((\\Omega, \\mathcal{F}, P)\\)\n\n\\(\\Omega\\colon\\) 集合(標本空間)\n\\(\\mathcal{F}\\subseteq 2^\\Omega\\) (事象の集合、可測集合)\n\\(P\\colon\\mathcal{F}\\to\\mathbb{R}_{\\ge 0}\\) (確率測度、確率は \\(\\mathcal{F}\\) の要素にのみ定義される！)\n\n可測集合 \\(\\mathcal{F}\\) の公理(\\(\\sigma\\)-加法族、完全加法族)\n\n\\(\\varnothing\\in\\mathcal{F}\\).\n\\(A\\in\\mathcal{F}\\implies \\Omega\\setminus A\\in\\mathcal{F}\\).\n\\((A_n\\in\\mathcal{F})_{n\\ge 0}\\implies \\bigcup_{n\\ge 0} A_n\\in\\mathcal{F}\\) (完全加法性, \\(\\sigma\\)-加 法性).\n\n確率の公理\n\n\\(P(\\Omega)=1\\).\n\\(\\forall (A_n\\in\\mathcal{F})_{n=1,\\dotsc}\\), \\(\\forall i\\ne j,\\, A_i\\cap A_j=\\varnothing\\implies P\\left(\\bigcup_{n=1}^\\infty A_n\\right)=\\sum_{n=1}^\\infty P(A_n)\\) (完全加法性, \\(\\sigma\\)-加法性).\n\nつまり、確率が定義される対象を \\(\\mathcal{F}\\) に限定する。\nさっきの例に現れた選択公理で作った集合 \\(V\\) を \\(\\mathcal{F}\\) に含めなければ、矛盾なく確率を定義できる。"
  },
  {
    "objectID": "slides/01_probability.html#この授業の方針",
    "href": "slides/01_probability.html#この授業の方針",
    "title": "確率論",
    "section": "この授業の方針",
    "text": "この授業の方針\nここまでのまとめ\n\n\\(\\Omega\\) が高々可算の場合は \\(\\mathcal{F}=2^\\Omega\\)とできる。\n\\(\\Omega\\) が非可算の場合は(平行移動で不変などの条件を課すと)すべての部分集合を可測とできない場合がある (要選択公理)。\n\nこの授業では \\(\\mathcal{F}=2^\\Omega\\)のつもりですすめる。\n\\(\\Omega\\) の部分集合を事象と呼ぶ。\n実際に考えるような確率空間では非可測な集合\\(A\\notin\\mathcal{F}\\)は選択公理を使わないと構成できない。\n普通に考える集合は全部可測。\nこの授業は測度論の授業ではないので、非可測な集合については考えないことにする。\n今後、確率空間は \\((\\Omega,\\,\\mathcal{F},\\,P)\\) じゃなくて \\((\\Omega,\\,P)\\) とする。"
  },
  {
    "objectID": "slides/01_probability.html#確率空間の性質",
    "href": "slides/01_probability.html#確率空間の性質",
    "title": "確率論",
    "section": "確率空間の性質",
    "text": "確率空間の性質\n確率空間 \\((\\Omega,\\, P)\\) と任意の \\(A,\\,B\\subseteq \\Omega\\) について以下が成り立つ。\n\n\\(P(A^\\mathrm{c}) = 1 - P(A)\\).\n\\(B\\subseteq A\\implies P(B)\\le P(A)\\)\n\\(P(A\\cup B) = P(A) + P(B) - P(A\\cap B)\\).\n\\(P(A\\cup B) \\le P(A) + P(B)\\qquad\\) (ブールの不等式、union bound).\n\n\nProof. \n\n\\[\n1 = P(\\Omega) = P(A \\cup A^\\mathrm{c}) = P(A) + P(A^\\mathrm{c}).\n\\]\n\\[\nP(A) = P(B\\cup (A\\setminus B)) = P(B) + P(A\\setminus B) \\ge P(B).\n\\]\n\\[\\begin{align*}\nP(A\\cup B) &= P(A \\cup (B\\setminus A)) = P(A) + P(B\\setminus A)\\\\\nP(B) &= P((B\\setminus A) \\cup (A\\cap B)) = P(B\\setminus A) + P(A\\cap B)\n\\end{align*}\\] より、 \\(P(B\\setminus A)\\) を消去することで得られる。\n3 より自明"
  },
  {
    "objectID": "slides/01_probability.html#ユニオンバウンド",
    "href": "slides/01_probability.html#ユニオンバウンド",
    "title": "確率論",
    "section": "ユニオンバウンド",
    "text": "ユニオンバウンド\n\nLemma 1 (ユニオンバウンド) 確率空間 \\((\\Omega,\\, P)\\) と \\((A_n\\subseteq\\Omega)_{n\\ge 0}\\) について、 \\[\nP\\left(\\bigcup_{n\\ge 0} A_n\\right) \\le \\sum_{n\\ge 0} P(A_n).\n\\]\n\n\nProof. \\(B_0 \\coloneqq A_0\\), \\(B_n \\coloneqq A_n \\setminus \\bigcup_{k=0}^{n-1} A_k\\) とおくと、\n\\[\\begin{align*}\nP\\left(\\bigcup_{n\\ge 0} A_n\\right) &= P\\left(\\bigcup_{n\\ge 0} B_n\\right)\\\\\n&= \\sum_{n\\ge 0} P\\left(B_n\\right)\\\\\n&\\le \\sum_{n\\ge 0} P\\left(A_n\\right).\n\\end{align*}\\]"
  },
  {
    "objectID": "slides/01_probability.html#確率測度の連続性",
    "href": "slides/01_probability.html#確率測度の連続性",
    "title": "確率論",
    "section": "確率測度の連続性",
    "text": "確率測度の連続性\n\nTheorem 1 (確率測度の連続性) 確率空間 \\((\\Omega,\\, P)\\) と事象列 \\(A_0\\subseteq A_1\\subseteq \\dotsb \\subseteq \\Omega\\) について \\[\\begin{align*}\nP\\left(\\bigcup_{n\\ge 0} A_n\\right) = \\lim_{n\\to\\infty} P(A_n).\n\\end{align*}\\] また、事象列 \\(\\Omega\\supseteq A_0\\supseteq A_1\\supseteq \\dotsb\\) について \\[\\begin{align*}\nP\\left(\\bigcap_{n\\ge 0} A_n\\right) = \\lim_{n\\to\\infty} P(A_n).\n\\end{align*}\\]\n\n\nProof. 事象列 \\(A_0\\subseteq A_1\\subseteq \\dotsb \\subseteq \\Omega\\) について考える。 \\(B_0\\coloneqq A_0\\), \\(n\\ge 1\\)について\\(B_n\\coloneqq A_n\\setminus A_{n-1}\\)とおく。 このとき、\\(i\\ne j\\)について \\(B_i\\cap B_j=\\varnothing\\)。 また \\(k\\ge 0\\) について、\\(\\bigcup_{n=0}^k B_n = \\bigcup_{n=0}^kA_n = A_k\\) が成り立つ.\n\\[\\begin{align*}\nP\\left(\\bigcup_{n\\ge 0} A_n\\right)&= P\\left(\\bigcup_{n\\ge 0} B_n\\right) =\\sum_{n\\ge 0} P(B_n)\\\\\n&=\\lim_{k\\to\\infty} \\sum_{n=0}^k P(B_n)\n=\\lim_{k\\to\\infty} P\\left(\\bigcup_{n=0}^k B_n\\right)\n=\\lim_{k\\to\\infty} P(A_k).\n\\end{align*}\\]\n事象列 \\(\\Omega\\supseteq A_0\\supseteq A_1\\supseteq \\dotsb\\) の場合についてはド・モルガンの法則を使うことで前半の結果に帰着でき証明できる。"
  },
  {
    "objectID": "slides/01_probability.html#今週の課題",
    "href": "slides/01_probability.html#今週の課題",
    "title": "確率論",
    "section": "今週の課題",
    "text": "今週の課題\n\\(\\Omega = \\{1,2,3,4,5,6\\}\\) とし、ある \\(P\\colon\\Omega\\to\\mathbb{R}_{\\ge 0}\\) について \\((\\Omega,\\,P)\\) を確率空間とする。 事象 \\(A,\\,B,\\,C\\) を\n\\[\\begin{align*}\nA&=\\left\\{1,2,3,4\\right\\},&\nB&=\\left\\{2,4,5\\right\\},&\nC&=\\left\\{1,3,5,6\\right\\}\n\\end{align*}\\] とするとき、以下の問に答えよ\n\n\n\\(A\\cup B\\),  \\(A\\cap B\\),  \\(A\\setminus B\\),  \\((A\\cup B)\\cap C\\) をもとめよ。\n\\(P(\\{1,3\\})\\),  \\(P(\\{2,4\\})\\),  \\(P(\\{5\\})\\),  \\(P(\\{6\\})\\) を \\(P(A),\\,P(B),\\,P(C)\\) を用いて表せ。"
  },
  {
    "objectID": "slides/08_cramer.html#二項分布の確率質量関数",
    "href": "slides/08_cramer.html#二項分布の確率質量関数",
    "title": "確率論",
    "section": "二項分布の確率質量関数",
    "text": "二項分布の確率質量関数\n\n\n\n\n\n\n\n\n\nFigure 1: 二項分布の確率質量関数"
  },
  {
    "objectID": "slides/08_cramer.html#二項分布の確率質量関数-1",
    "href": "slides/08_cramer.html#二項分布の確率質量関数-1",
    "title": "確率論",
    "section": "二項分布の確率質量関数",
    "text": "二項分布の確率質量関数\n\n\n\n\n\n\n\n\n\nFigure 2: 二項分布の確率質量関数"
  },
  {
    "objectID": "slides/08_cramer.html#二項分布の確率質量関数-2",
    "href": "slides/08_cramer.html#二項分布の確率質量関数-2",
    "title": "確率論",
    "section": "二項分布の確率質量関数",
    "text": "二項分布の確率質量関数\n\n\n\n\n\n\n\n\n\nFigure 3: 二項分布の確率質量関数"
  },
  {
    "objectID": "slides/08_cramer.html#二項分布の確率質量関数-3",
    "href": "slides/08_cramer.html#二項分布の確率質量関数-3",
    "title": "確率論",
    "section": "二項分布の確率質量関数",
    "text": "二項分布の確率質量関数\n\n\n\n\n\n\n\n\n\nFigure 4: 二項分布の確率質量関数"
  },
  {
    "objectID": "slides/08_cramer.html#確率変数の和に対するチェルノフ上界",
    "href": "slides/08_cramer.html#確率変数の和に対するチェルノフ上界",
    "title": "確率論",
    "section": "確率変数の和に対するチェルノフ上界",
    "text": "確率変数の和に対するチェルノフ上界\n\nLemma 1 (確率変数の和に対するチェルノフ上界) 任意の確率変数 \\(X\\) と \\(a\\in\\mathbb{R}\\) について、 \\[\\begin{align*}\n\\Pr\\left(\\frac1N\\sum_{i=1}^N X_i\\ge a\\right) &\\le \\mathrm{e}^{-(at-K_X(t))N}\\qquad\\forall t\\ge 0\\\\\n\\Pr\\left(\\frac1N\\sum_{i=1}^N X_i\\le a\\right) &\\le \\mathrm{e}^{-(at-K_X(t))N}\\qquad\\forall t\\le 0.\n\\end{align*}\\]\n\nこの上界を最小化すると、 \\[\\begin{align*}\n\\Pr\\left(\\frac1N\\sum_{i=1}^N X_i\\ge a\\right) &\\le \\mathrm{e}^{-\\sup_{t\\ge 0}\\{at-K_X(t)\\}N}\\\\\n\\Pr\\left(\\frac1N\\sum_{i=1}^N X_i\\le a\\right) &\\le \\mathrm{e}^{-\\sup_{t\\le 0}\\{at-K_X(t)\\}N}\n\\end{align*}\\]"
  },
  {
    "objectID": "slides/08_cramer.html#キュムラント母関数の存在する範囲",
    "href": "slides/08_cramer.html#キュムラント母関数の存在する範囲",
    "title": "確率論",
    "section": "キュムラント母関数の存在する範囲",
    "text": "キュムラント母関数の存在する範囲\nキュムラント母関数 \\[\\begin{align*}\nK_X(t) &= \\log M_X(t) = \\log\\expt{\\mathrm{e}^{tX}}\n\\end{align*}\\] の性質を改めて考えよう。 期待値が発散する場合は \\(+\\infty\\) に値を取るとみなして \\(K_X\\colon \\mathbb{R}\\to(-\\infty,\\,+\\infty]\\) と考えることにする。\nまず、\\(K_X(0)=0\\) である。 ある \\(t&gt;0\\) について、 \\(M_X(t)&lt;+\\infty\\) と仮定すると、任意の \\(s\\in(0,t)\\) について \\[\\begin{align*}\nM_X(s) &= \\expt{\\mathrm{e}^{sX}}\\\\\n&= \\expt{\\mathrm{e}^{sX} \\mathbb{1}_{\\{X\\ge 0\\}}}\n+ \\expt{\\mathrm{e}^{sX} \\mathbb{1}_{\\{X&lt; 0\\}}}\\\\\n&\\le \\expt{\\mathrm{e}^{tX} \\mathbb{1}_{\\{X\\ge 0\\}}} + 1\\\\\n&\\le M_X(t) + 1 &lt; +\\infty\n\\end{align*}\\] である。 同様に、ある \\(t&lt;0\\) について、 \\(M_X(t)&lt;+\\infty\\) と仮定すると、任意の \\(s\\in(t,0)\\) について \\(M_X(s)&lt;+\\infty\\) である。 よって、\\(M_X(t)\\) や \\(K_X(t)\\) が有限となる範囲は0を含む区間となる。 ここでいう区間とは一般的に空集合、もしくは \\(a&lt; b\\) について、 \\[\\begin{align*}\n[a,\\,a]\\quad\n(a,\\,b)\\quad\n[a,\\,b)\\quad\n(a,\\,b]\\quad\n[a,\\,b]\\quad\n(a,\\,+\\infty)\\quad\n[a,\\,+\\infty)\\quad\n(-\\infty,\\, b)\\quad\n(-\\infty,\\, b]\\quad\n(-\\infty,\\,+\\infty)\n\\end{align*}\\] のいずれかの形の集合を指す。 この区間を \\[\\begin{align*}\n\\mathrm{dom}(K_X) &\\coloneqq\\left\\{t\\in\\mathbb{R}\\mid K_X(t)&lt;+\\infty\\right\\}\n\\end{align*}\\] と表す。 区間は1次元の凸集合と一言で理解できる。"
  },
  {
    "objectID": "slides/08_cramer.html#キュムラント母関数の凸性",
    "href": "slides/08_cramer.html#キュムラント母関数の凸性",
    "title": "確率論",
    "section": "キュムラント母関数の凸性",
    "text": "キュムラント母関数の凸性\n\\[\\begin{align*}\nK_X(t) &= \\log M_X(t) = \\log\\expt{\\mathrm{e}^{tX}}\n\\end{align*}\\] 証明はしないが、キュムラント母関数 \\(K_X(t)\\) は \\(\\mathrm{dom}(K_X)\\) の内点で何回でも微分可能であり、無限和や積分を取る前に微分しても構わない。\n\\[\\begin{align*}\n\\frac{\\mathrm{d} K_X(t)}{\\mathrm{d}t} &= \\frac{\\expt{X\\mathrm{e}^{tX}}}{\\expt{\\mathrm{e}^{tX}}}\\\\\n\\frac{\\mathrm{d}^2 K_X(t)}{\\mathrm{d}t^2} &= \\frac{\\expt{X^2\\mathrm{e}^{tX}}\\expt{\\mathrm{e}^{tX}}-\\expt{X\\mathrm{e}^{tX}}^2}{\\expt{\\mathrm{e}^{tX}}^2}\\\\\n&= \\frac{\\expt{X^2\\mathrm{e}^{tX}}}{\\expt{\\mathrm{e}^{tX}}}-\\left(\\frac{\\expt{X\\mathrm{e}^{tX}}}{\\expt{\\mathrm{e}^{tX}}}\\right)^2\\\\\n&= \\frac{\\expt{\\left(X-\\frac{\\expt{X\\mathrm{e}^{tX}}}{\\expt{\\mathrm{e}^{tX}}}\\right)^2\\mathrm{e}^{tX}}}{\\expt{\\mathrm{e}^{tX}}}\\ge 0\n\\end{align*}\\]\n\nまた、\\(X\\)が決定的(\\(\\Pr(X=\\expt{X})=1\\))でない限り、\\(K_X\\) は \\(\\mathrm{dom}(K_X)\\) で狭義凸である。"
  },
  {
    "objectID": "slides/08_cramer.html#キュムラント母関数の性質まとめ",
    "href": "slides/08_cramer.html#キュムラント母関数の性質まとめ",
    "title": "確率論",
    "section": "キュムラント母関数の性質まとめ",
    "text": "キュムラント母関数の性質まとめ\nよって \\(X\\) のキュムラント母関数 \\(K_X(t)\\) は\n\n0を含む区間で定義され、\n原点を通り、\n凸関数で、\n\\(K_X(t)\\) が原点付近で存在すると仮定すると、原点の傾きは \\(\\expt{X}\\)\n\nであることが分かる。\n\n\n\n\n\n\nNote\n\n\n関数 \\(f\\colon\\mathbb{R}\\to(-\\infty,\\,+\\infty]\\) が下半連続であるとは、 任意の \\(\\alpha\\in\\mathbb{R}\\) について \\(\\{t\\in\\mathbb{R}\\mid f(t)\\le\\alpha\\}\\) が閉集合であることをいう。 キュムラント母関数は下半連続の凸関数である。\n\n\n\nまた、キュムラント母関数の簡単な性質として以下が成り立つ(今回は使わない)。 任意の独立確率変数 \\(X\\) と \\(Y\\) と \\(a\\in\\mathbb{R}\\) について \\[\\begin{align*}\nK_{X+a}(t) &= \\log\\expt{\\mathrm{e}^{t(X+a)}} = \\log\\left(\\expt{\\mathrm{e}^{tX}}\\cdot \\mathrm{e}^{ta}\\right) = K_X(t) + at\\\\%\\quad\\text{for } t\\in\\mathrm{dom}(K_X)\\\\\nK_{aX}(t) &= \\log\\expt{\\mathrm{e}^{t(aX)}} = K_X(at)\\\\%\\qquad\\text{if } at\\in\\mathrm{dom}(K_X)\\\\\nK_{X+Y}(t) &= \\log\\expt{\\mathrm{e}^{t(X+Y)}} =\\log\\left(\\expt{\\mathrm{e}^{tX}}\\expt{\\mathrm{e}^{tY}}\\right) = K_X(t) + K_Y(t).\n%&\\hspace{17em}\\text{for } t\\in\\mathrm{dom}(K_X)\\cap\\mathrm{dom}(K_Y)\n\\end{align*}\\]"
  },
  {
    "objectID": "slides/08_cramer.html#ルジャンドル変換",
    "href": "slides/08_cramer.html#ルジャンドル変換",
    "title": "確率論",
    "section": "ルジャンドル変換",
    "text": "ルジャンドル変換\n\n\nDefinition 1 (ルジャンドル変換)  \n\n恒等的に \\(+\\infty\\) ではない凸関数 \\(f\\colon \\mathbb{R}\\to (-\\infty,\\,+\\infty]\\) のルジャンドル変換 \\(f^*\\colon \\mathbb{R}\\to (-\\infty,\\,+\\infty]\\) を以下で定義する。 \\[\\begin{align*}\nf^*(a) &\\coloneqq \\sup_{t\\in \\mathbb{R}}\\left\\{at-f(t)\\right\\}.\n\\end{align*}\\]\n\nルジャンドル変換において \\(f\\) は凸関数なので、\\(at-f(t)\\) は凹関数(上に凸の関数)になる。 簡単のため \\(f\\) が \\(\\mathrm{dom}(f)\\) の内点で微分可能であると仮定しよう(キュムラント母関数はこの仮定は満たす)。 このとき、\n\n\\(at-f(t)\\) の微分が 0 になる点、つまり \\(f'(t_a) = a\\) を満たす \\(t_a\\in \\mathrm{dom}(f)^\\circ\\) が存在するとき、\\(t_a\\) で \\(at-f(t)\\) は最大化される。\nそのような \\(t_a\\in \\mathrm{dom}(f)^\\circ\\) が存在しないときは、\\(\\mathrm{dom}(f)\\) の端への極限で \\(\\sup\\) が達成される。\n\n\n\n\n\n\n\n\nNote\n\n\nまたルジャンドル変換 \\(f^*\\) は下半連続である。 ルジャンドル変換は凸で下半連続な関数を凸で下半連続な関数に写す。 また、凸で下半連続な関数 \\(f\\) について \\(f=f^{**}\\) である。"
  },
  {
    "objectID": "slides/08_cramer.html#イェンセンの不等式",
    "href": "slides/08_cramer.html#イェンセンの不等式",
    "title": "確率論",
    "section": "イェンセンの不等式",
    "text": "イェンセンの不等式\n\nLemma 2 (イェンセンの不等式) 任意の凸関数 \\(f\\colon\\mathbb{R}\\to\\mathbb{R}\\) と確率変数 \\(X\\) について\n\\[\\begin{align*}\n\\expt{f(X)} &\\ge f(\\expt{X}).\n\\end{align*}\\]\n\n\nProof (\\(X\\) の像が有限のときの証明). 確率変数 \\(X\\) は \\(k=1,2,\\dotsc,m\\) について確率 \\(p_k\\) で値 \\(a_k\\) をとると仮定する。 \\(m\\) についての帰納法で示す。\\(m=1\\) のときは明らかに成り立つ。 \\(X\\) の像のサイズが \\(m\\) 未満のときにイェンセンの不等式が成り立つと仮定すると、 \\[\\begin{align*}\n\\expt{f(X)} &= \\sum_{k=1}^m p_k f(a_k)\n= \\left(\\sum_{k=1}^{m-1}p_k\\right)\\sum_{k=1}^{m-1} \\frac{p_k}{\\sum_{\\ell=1}^{m-1}p_\\ell} f(a_k) + p_m f(a_m)\\\\\n&\\ge \\left(\\sum_{k=1}^{m-1}p_k\\right) f\\left(\\sum_{k=1}^{m-1} \\frac{p_k}{\\sum_{\\ell=1}^{m-1}p_\\ell}a_k\\right) + p_m f(a_m)\\quad\\text{(帰納法の仮定)}\\\\\n&\\ge  f\\left(\\left(\\sum_{k=1}^{m-1}p_k\\right)\\sum_{k=1}^{m-1} \\frac{p_k}{\\sum_{\\ell=1}^{m-1}p_\\ell}a_k + p_ma_m\\right)\\quad\\text{($f$の凸性)}\\\\\n&= f\\left(\\sum_{k=1}^m p_ka_k\\right) = f(\\expt{X}).\n\\end{align*}\\]"
  },
  {
    "objectID": "slides/08_cramer.html#レート関数",
    "href": "slides/08_cramer.html#レート関数",
    "title": "確率論",
    "section": "レート関数",
    "text": "レート関数\n\nLemma 3 レート関数 \\(I_X\\colon \\mathbb{R} \\to[0,\\,+\\infty]\\)を \\[\\begin{align*}\nI_X(a) &:= K_X^*(a) = \\sup_{t \\in\\mathbb{R}}\\left\\{at - K_X(t)\\right\\}\n\\end{align*}\\] と定義する。 このとき、\n\n\\(\\mathrm{dom}(K_X)=\\{0\\}\\) のとき、\\(I_X(a) = 0\\).\nある \\(\\epsilon&gt;0\\) が存在して \\(K_X(\\epsilon)&lt;+\\infty\\) のとき、\\(\\mathbb{E}[X]&lt;+\\infty\\) であり、 \\[\\begin{align*}\n\\sup_{t\\ge0}\\left\\{at-K_X(t)\\right\\}&=\\begin{cases}\nI_X(a)&\\text{if } a &gt; \\expt{X}\\\\\n0&\\text{otherwise.}\n\\end{cases}\n\\end{align*}\\]\nある \\(\\epsilon&gt;0\\) が存在して \\(K_X(-\\epsilon)&lt;+\\infty\\) のとき、\\(\\mathbb{E}[X]&gt;-\\infty\\) であり、 \\[\\begin{align*}\n\\sup_{t\\le0}\\left\\{at-K_X(t)\\right\\}&=\\begin{cases}\nI_X(a)&\\text{if } a &lt; \\expt{X}\\\\\n0&\\text{otherwise.}\n\\end{cases}\n\\end{align*}\\]"
  },
  {
    "objectID": "slides/08_cramer.html#補題の証明",
    "href": "slides/08_cramer.html#補題の証明",
    "title": "確率論",
    "section": "補題の証明",
    "text": "補題の証明\n\nProof. 1 は自明。 2 を示す。 ある \\(\\epsilon&gt;0\\) について、\\(K_X(\\epsilon)&lt;+\\infty\\) と仮定する。 一般に、 \\[\\begin{align*}\n\\mathrm{e}^{tx} &\\ge tx + 1\\qquad\\forall t,x\\in\\mathbb{R}\n\\end{align*}\\] より、\\(M_X(t)\\ge t\\expt{X}+1\\) である。 よって、 \\[\\begin{align*}\n\\expt{X}&\\le \\frac{M_X(\\epsilon)-1}{\\epsilon}&lt;+\\infty\n\\end{align*}\\] である。 また、イェンセンの不等式より、 \\[\\begin{align*}\nK_X(t) &= \\log \\expt{\\mathrm{e}^{tX}} \\ge \\expt{\\log\\mathrm{e}^{tX}} = t\\expt{X}\\qquad\\forall t\\in\\mathbb{R}\n\\end{align*}\\] である。 よって、 \\[\\begin{align*}\nI_X(\\expt{X}) &= \\sup_{t\\in\\mathbb{R}} \\left\\{t\\expt{X} - K_X(t)\\right\\} = 0\n\\end{align*}\\] である。 任意の \\(a &gt; \\expt{X}\\) と \\(t&lt;0\\) について、 \\[\\begin{align*}\nta - K_X(t) &\\le t\\expt{X} - K_X(t) \\le 0\n\\end{align*}\\] であるので、任意の \\(a &gt; \\expt{X}\\) について \\[\\begin{align*}\nI_X(a) &:= \\sup_{t \\in\\mathbb{R}}\\left\\{at - K_X(t)\\right\\}\n= \\sup_{t\\ge 0}\\left\\{at - K_X(t)\\right\\}\n\\end{align*}\\] また、\\(\\sup_{t\\ge 0}\\left\\{at - K_X(t)\\right\\}\\) は \\(a\\) について単調なので、 任意の \\(a &lt; \\expt{X}\\) について \\(\\sup_{t\\ge 0}\\left\\{at - K_X(t)\\right\\} = 0\\)."
  },
  {
    "objectID": "slides/08_cramer.html#クラメールの定理",
    "href": "slides/08_cramer.html#クラメールの定理",
    "title": "確率論",
    "section": "クラメールの定理",
    "text": "クラメールの定理\nよってチェルノフ上界を最適化することで確率の指数的な上界を得る。\n\nTheorem 1 (最適化されたチェルノフ上界) \\[\\begin{align*}\n\\Pr\\left(\\frac1N\\sum_{i=1}^N X\\ge a\\right) &\\le \\mathrm{e}^{-I_X(a)N}\\qquad\\forall a&gt;\\expt{X}\\\\\n\\Pr\\left(\\frac1N\\sum_{i=1}^N X\\le a\\right) &\\le \\mathrm{e}^{-I_X(a)N}\\qquad\\forall a&lt;\\expt{X}.\n\\end{align*}\\]\n\nこの指数は漸近的に最適である。証明は少し難しいので紹介しない。\n\nTheorem 2 (クラメールの定理) \\[\\begin{align*}\n\\lim_{N\\to\\infty}\\frac1N\\log \\Pr\\left(\\frac1N\\sum_{i=1}^N X\\ge a\\right) &= -I_X(a)\\qquad\\forall a&gt;\\expt{X}\\\\\n\\lim_{N\\to\\infty}\\frac1N\\log \\Pr\\left(\\frac1N\\sum_{i=1}^N X\\le a\\right) &= -I_X(a)\\qquad\\forall a&lt;\\expt{X}.\n\\end{align*}\\]"
  },
  {
    "objectID": "slides/08_cramer.html#ベルヌーイ分布",
    "href": "slides/08_cramer.html#ベルヌーイ分布",
    "title": "確率論",
    "section": "ベルヌーイ分布",
    "text": "ベルヌーイ分布\n\\[\\begin{align*}\n\\Pr(X=0) &= 1-p,&\\Pr(X=1)=p\n\\end{align*}\\] \\[\\begin{align*}\nK_X(t) &= \\log(p\\mathrm{e}^t + (1-p))\n\\end{align*}\\] \\[\\begin{align*}\nI_X(a) &= \\sup_{t\\in\\mathbb{R}} \\left\\{ at - \\log(p\\mathrm{e}^t+(1-p))\\right\\}\n\\end{align*}\\] \\[\\begin{align*}\na - \\frac{p\\mathrm{e}^{t_a}}{p\\mathrm{e}^{t_a}+1-p} = 0\n\\iff \\mathrm{e}^{t_a} = \\frac{a(1-p)}{p(1-a)}\n\\end{align*}\\] \\[\\begin{align*}\nI_X(a) &= a\\log\\frac{a(1-p)}{p(1-a)} - \\log\\left(\\frac{a(1-p)}{1-a} + (1-p)\\right)\\\\\n%&= (a-1)\\log\\frac{1-p}{1-a} + a\\log\\frac{a}{p}\n&= a\\log\\frac{a}{p} + (1-a)\\log\\frac{1-a}{1-p} \\qquad\\text{for } a\\in(0,1)\n\\end{align*}\\] \\[\\begin{align*}\nI_X(0) &= -\\log(1-p)\\\\\nI_X(1) &= -\\log p\\\\\nI_X(a) &= +\\infty\\qquad\\text{for } a \\notin[0,1]\n\\end{align*}\\]"
  },
  {
    "objectID": "slides/08_cramer.html#ベルヌーイ分布-1",
    "href": "slides/08_cramer.html#ベルヌーイ分布-1",
    "title": "確率論",
    "section": "ベルヌーイ分布",
    "text": "ベルヌーイ分布"
  },
  {
    "objectID": "slides/08_cramer.html#今週の課題",
    "href": "slides/08_cramer.html#今週の課題",
    "title": "確率論",
    "section": "今週の課題",
    "text": "今週の課題\n表が出る確率が \\(1/2\\) のコインを \\(N\\) 回投げて \\(0.6N\\) 回以上表が出る確率を \\(\\mathrm{e}^{-cN}\\) という形で上から抑えるときの最大の定数 \\(c&gt;0\\) をクラメールの定理を用いてもとめよ。"
  },
  {
    "objectID": "slides/03_multi.html#条件付き確率",
    "href": "slides/03_multi.html#条件付き確率",
    "title": "確率論",
    "section": "条件付き確率",
    "text": "条件付き確率\n\nDefinition 1 (条件付き確率) 確率空間 \\((\\Omega,\\,P)\\) の事象 \\(A,B\\subseteq\\Omega\\) について \\(P(B)&gt; 0\\) のとき、\\(B\\) における \\(A\\) の条件付き確率 は以下で定義される。 \\[\\begin{align*}\n   P(A\\mid B) &\\coloneqq \\frac{P(A\\cap B)}{P(B)}.\n   \\end{align*}\\]\n\n二つの事象 \\(A,B\\subseteq\\Omega\\) を考える文脈では \\(P(A\\cap B)\\) を同時確率、\\(P(A),\\,P(B)\\) を周辺確率という。\n\nDefinition 2 (事象の独立性) 確率空間 \\((\\Omega,\\,P)\\) の事象 \\(A,B\\subseteq\\Omega\\) について \\[\\begin{align*}\nP(A\\cap B) &= P(A) P(B)\n\\end{align*}\\] を満たすとき、事象 \\(A\\) と \\(B\\) は独立であるという。\n\n\n\nExample 1 (二回のコイン投げ) 標本空間を \\(\\Omega = \\{\\mathrm{HH},\\mathrm{HT},\\mathrm{TH},\\mathrm{TT}\\}\\) とし、確率測度を \\(P(A) = \\frac{|A|}4\\quad\\forall A\\subseteq\\Omega\\) とする。 このとき、\\(A=\\{\\mathrm{HH},\\mathrm{HT}\\},\\,B=\\{\\mathrm{HH},\\mathrm{TH}\\}\\) とおくと、 \\[\\begin{align*}\nP(A\\cap B) &= \\frac14,&P(A)&=P(B)=\\frac12\n\\end{align*}\\] より \\(P(A\\cap B) = P(A)P(B)\\) を満たすことが分かる。 よって事象 \\(A,\\,B\\) は独立である。\n\n事象 \\(A\\) と \\(B\\) が独立であり、\\(P(B)&gt;0\\) であるとき、\\(P(A\\mid B)=P(A)\\) である。"
  },
  {
    "objectID": "slides/03_multi.html#確率変数の条件付き確率と独立性",
    "href": "slides/03_multi.html#確率変数の条件付き確率と独立性",
    "title": "確率論",
    "section": "確率変数の条件付き確率と独立性",
    "text": "確率変数の条件付き確率と独立性\n事象は確率変数を通じて表すことが多い。そのため確率変数を用いた条件付き確率も定義する。\n\nDefinition 3 (確率変数) 確率空間 \\((\\Omega,\\,P)\\) 上の確率変数 \\(X_1, X_2\\) について同時確率を \\[\\begin{align*}\n\\Pr(X_1\\in A,\\,X_2\\in B) &\\coloneqq P(\\{\\omega\\in\\Omega\\mid X_1(\\omega)\\in A\\}\\cap\\{\\omega\\in\\Omega\\mid X_2(\\omega)\\in B\\}\\})\\quad\\forall A,B\\subseteq\\mathbb{R}\n\\end{align*}\\] と定義する。確率変数が三つ以上の場合も同様に定義する。 また \\(\\Pr(X_2\\in B)&gt;0\\) のとき、条件付き確率は以下で定義する。 \\[\\begin{align*}\n\\Pr(X_1\\in A\\mid X_2\\in B) &\\coloneqq P(\\{\\omega\\in\\Omega\\mid X_1(\\omega)\\in A\\}\\mid\\{\\omega\\in\\Omega\\mid X_2(\\omega)\\in B\\}\\})\\\\\n&=\\frac{\\Pr(X_1\\in A, X_2\\in B)}{\\Pr(X_2\\in B)}\\qquad\\forall A,B\\subseteq\\mathbb{R}.\n\\end{align*}\\] 任意の \\(A,B\\subseteq\\mathbb{R}\\) について、 \\[\\begin{align*}\n\\Pr(X_1\\in A,\\,X_2\\in B)  &= \\Pr(X_1\\in A)\\Pr(X_2\\in B)\n\\end{align*}\\] を満たすとき、確率変数 \\(X_1\\) と \\(X_2\\) は独立であるという。\n\n\nLemma 1 確率空間 \\((\\Omega,\\,P)\\) 上の確率変数 \\(X_1, X_2\\) が独立であるとする。 このとき任意の関数 \\(f_1,\\,f_2\\colon\\mathbb{R}\\to\\mathbb{R}\\) について、\\(f_1(X_1),\\,f_2(X_2)\\) は独立である。\n\n\nProof. \\[\\begin{align*}\n\\Pr(f_1(X_1)\\in A,\\,f_2(X_2)\\in B) &=\n\\Pr(X_1\\in f_1^{-1}(A),\\,X_2\\in f_2^{-1}(B))\\\\\n&=\\Pr(X_1\\in f_1^{-1}(A))\\Pr(X_2\\in f_2^{-1}(B))\\\\\n&=\\Pr(f_1(X_1)\\in A)\\Pr(f_2(X_2)\\in B).\n\\end{align*}\\]"
  },
  {
    "objectID": "slides/03_multi.html#離散型確率変数と確率質量関数",
    "href": "slides/03_multi.html#離散型確率変数と確率質量関数",
    "title": "確率論",
    "section": "離散型確率変数と確率質量関数",
    "text": "離散型確率変数と確率質量関数\n\nDefinition 4 確率空間 \\((\\Omega,\\,P)\\) 上の離散型確率変数 \\(X_1\\), \\(X_2\\) について、同時確率質量関数を \\[\\begin{align*}\nf_{X_1,\\,X_2}(x_1,x_2) &\\coloneqq \\Pr(X_1=x_1,\\,X_2=x_2)\\\\\n\\end{align*}\\] と定義する。\n\n同時確率質量関数からそれぞれの確率変数の確率質量関数が得られる。 \\[\\begin{align*}\nf_{X_1}(x_1) &= \\sum_{x_2} f_{X_1,\\, X_2}(x_1, x_2),&\nf_{X_2}(x_2) &= \\sum_{x_1} f_{X_1,\\, X_2}(x_1, x_2)\n\\end{align*}\\] それぞれの確率変数の確率質量関数を周辺質量関数と呼ぶ。 同時確率質量関数から周辺質量関数を計算する操作のことを周辺化という。\n\nDefinition 5 確率空間 \\((\\Omega,\\,P)\\) 上の離散型確率変数 \\(X_1\\), \\(X_2\\) について、条件付き確率質量関数を \\[\\begin{align*}\nf_{X_1\\mid X_2}(x_1\\mid x_2) &\\coloneqq \\Pr(X_1=x_1\\mid X_2=x_2)\n\\end{align*}\\] と定義する。\n\n条件付き確率の定義より \\[\\begin{align*}\nf_{X_1,\\,X_2}(x_1,x_2) &= f_{X_1\\mid X_2}(x_1\\mid x_2) f_{X_2}(x_2)\n\\end{align*}\\] が成り立つ。"
  },
  {
    "objectID": "slides/03_multi.html#離散型確率変数の独立性",
    "href": "slides/03_multi.html#離散型確率変数の独立性",
    "title": "確率論",
    "section": "離散型確率変数の独立性",
    "text": "離散型確率変数の独立性\n\nLemma 2 確率空間 \\((\\Omega,\\,P)\\) 上の離散型確率変数 \\(X_1, X_2\\) について、 \\(X_1\\) と \\(X_2\\) が独立 \\(\\iff\\) \\[\\begin{align*}\nf_{X_1,\\,X_2}(x_1,x_2) &= f_{X_1}(x_1) f_{X_2}(x_2)\n&\\forall x_1\\in\\mathrm{Image}(X_1),x_2\\in\\mathrm{Image}(X_2).\n\\end{align*}\\]\n\n\nProof. \\(\\Longrightarrow\\) は自明。 \\(\\Longleftarrow\\) を示す。 \\[\\begin{align*}\n\\Pr(X_1\\in A,\\,X_2\\in B)  &= \\sum_{x_1\\in A}\\sum_{x_2\\in B} \\Pr(X_1=x_1,\\,X_2=x_2)\\\\\n&= \\sum_{x_1\\in A}\\sum_{x_2\\in B} \\Pr(X_1=x_1)\\Pr(X_2=x_2)\\\\\n&= \\Pr(X_1\\in A)\\Pr(X_2\\in B)\n\\end{align*}\\]\n\n\nExample 2 (二回のコイン投げ) 標本空間を \\(\\Omega = \\{\\mathrm{HH},\\mathrm{HT},\\mathrm{TH},\\mathrm{TT}\\}\\) とし、確率測度を \\(P(A) = \\frac{|A|}4\\quad\\forall A\\subseteq\\Omega\\) とする。 \\[\\begin{align*}\nX_1(\\mathrm{HH})&=X_1(\\mathrm{HT}) = 1,&\nX_1(\\mathrm{TH})&=X_1(\\mathrm{TT}) = 0\\\\\nX_2(\\mathrm{HH})&=X_2(\\mathrm{TH}) = 1,&\nX_2(\\mathrm{HT})&=X_2(\\mathrm{TT}) = 0\n\\end{align*}\\] と定義する。 このとき、 \\[\\begin{align*}\nf_{X_1,\\,X_2}(x_1,\\,x_2) &= \\frac14,&\nf_{X_1}(x_1)=f_{X_2}(x_2)&=\\frac12\\qquad\\forall x_1,x_2\\in\\{0,1\\}\n\\end{align*}\\] より \\(f_{X_1,\\,X_2}(x_1,\\,x_2) = f_{X_1}(x_1)f_{X_2}(x_2)\\) を満たすことが分かる。 よって確率変数 \\(X_1,\\,X_2\\) は独立である。"
  },
  {
    "objectID": "slides/03_multi.html#連続型確率変数と確率密度関数",
    "href": "slides/03_multi.html#連続型確率変数と確率密度関数",
    "title": "確率論",
    "section": "連続型確率変数と確率密度関数",
    "text": "連続型確率変数と確率密度関数\n確率空間 \\((\\Omega,\\,P)\\) 上の連続型確率変数 \\(X_1\\), \\(X_2\\) について、同時確率密度関数を \\[\\begin{align*}\n%\\Pr(\\begin{bmatrix}X_1,\\,X_2\\end{bmatrix}\\in A) &= \\int_A f_{X_1,\\,X_2}(x_1,x_2)\\mathrm{d}x_1\\mathrm{d}x_2\n\\Pr(X_1\\in A,\\,X_2\\in B) &= \\int_A\\left(\\int_B f_{X_1,\\,X_2}(x_1,x_2)\\mathrm{d}x_2\\right)\\mathrm{d}x_1\n\\end{align*}\\] を満たすものと定義する。 \\(X_1\\) と \\(X_2\\) が確率密度関数を持つ場合でも \\(X_1\\) と \\(X_2\\) の同時確率密度関数が存在するとは限らない。 例えば \\(X_1=X_2\\) の場合がその例である。 逆に \\(X_1\\) と \\(X_2\\) が同時確率密度関数を持つとき、それぞれの確率密度関数は \\[\\begin{align*}\nf_{X_1}(x_1) &= \\int_{-\\infty}^\\infty f_{X_1,\\,X_2}(x_1,x_2)\\mathrm{d}x_2\\\\\nf_{X_2}(x_2) &= \\int_{-\\infty}^\\infty f_{X_1,\\,X_2}(x_1,x_2)\\mathrm{d}x_1\n\\end{align*}\\] で得られる。この操作を確率密度関数の周辺化という。 同時確率密度関数を持つ確率変数 \\(X_1\\), \\(X_2\\) が独立であるとき、 \\[\\begin{align*}\nf_{X_1,\\,X_2}(x_1,x_2) &= f_{X_1}(x_1) f_{X_2}(x_2)\n\\end{align*}\\] が成り立つ。"
  },
  {
    "objectID": "slides/03_multi.html#三つ以上の独立確率変数",
    "href": "slides/03_multi.html#三つ以上の独立確率変数",
    "title": "確率論",
    "section": "三つ以上の独立確率変数",
    "text": "三つ以上の独立確率変数\n三つ以上の確率変数についても同時確率質量関数、同時確率密度関数を同様に定義する。 独立性についても同様に定義する。\n\nDefinition 6 確率空間 \\((\\Omega,\\,P)\\) 上の確率変数 \\(X_1, X_2,\\dotsc, X_n\\) が独立 \\(\\defiff\\) \\[\\begin{align*}\n\\Pr(X_1\\in A_1,\\dotsc, X_n\\in A_n) &= \\prod_{k=1}^n \\Pr(X_k\\in A_k)\\qquad\\forall A_1,\\dotsc,A_n\\subseteq\\mathbb{R}.\n\\end{align*}\\]\n\n\nDefinition 7 確率空間 \\((\\Omega,\\,P)\\) 上の確率変数 \\(X_1, X_2,\\dotsc, X_n\\) が互いに独立 \\(\\defiff\\) 任意の \\(1\\le i&lt; j\\le n\\) について、\\(X_i\\) と \\(X_j\\) が独立。\n\n\n確率変数 \\(X_1,\\dotsc,X_n\\) が独立であるとき、それらは互いに独立であることは以下から分かる。 \\[\\begin{align*}\n\\Pr(X_1\\in A,\\, X_2\\in B) &= \\Pr(X_1\\in A,\\, X_2\\in B,\\, X_3\\in\\mathbb{R},\\dotsc, X_n\\in\\mathbb{R})\\\\\n&= \\Pr(X_1\\in A)\\Pr(X_2\\in B) \\prod_{k=3}^n \\Pr(X_k\\in\\mathbb{R})\\\\\n&= \\Pr(X_1\\in A)\\Pr(X_2\\in B).\n\\end{align*}\\]"
  },
  {
    "objectID": "slides/03_multi.html#互いに独立であるが独立ではない例",
    "href": "slides/03_multi.html#互いに独立であるが独立ではない例",
    "title": "確率論",
    "section": "互いに独立であるが独立ではない例",
    "text": "互いに独立であるが独立ではない例\n一方で確率変数 \\(X_1,\\dotsc,X_n\\) が互いに独立であっても、それらが独立であるとは限らない。 例えば、離散型確率変数 \\(X_1,\\dotsc,X_n\\) を \\[\\begin{align*}\nf_{X_1,\\dotsc,X_n}(x_1,\\dotsc,x_n)&=\\begin{cases}\n\\frac1{2^{n-1}}&\\text{if } \\sum_{k=1}^n x_k \\text{ is even}\\\\\n0&\\text{otherwise}\n\\end{cases}&\n\\forall x_1,\\dotsc,x_n\\in\\{0,1\\}\n\\end{align*}\\] と定義する。 このとき、確率変数 \\(X_n\\) を周辺化すると \\[\\begin{align*}\nf_{X_1,\\dotsc,X_{n-1}}(x_1,\\dotsc,x_{n-1})&=\nf_{X_1,\\dotsc,X_n}(x_1,\\dotsc,x_{n-1},0)+ f_{X_1,\\dotsc,X_n}(x_1,\\dotsc,x_{n-1},1)\n=\\frac1{2^{n-1}}\n\\end{align*}\\] となる。つまり、\\(X_1,\\dotsc,X_{n-1}\\) は \\(\\{0,1\\}^{n-1}\\) 上の一様分布に従う。 この確率分布は \\(X_1,\\dotsc,X_n\\) について対称なので、どの確率変数を周辺化しても一様分布に従う。 一様分布は独立なので、\\(n\\ge 3\\) のとき、どの二つの確率変数も独立である。 よって \\(n\\ge 3\\) のとき、\\(X_1,\\dotsc,X_n\\) は互いに独立である。\n一方で、\\(n\\ge 2\\) のとき、これらの確率変数の周辺確率は一様である。つまり、 \\[\\begin{align*}\nf_{X_k}(0) &= f_{X_k}(1) = \\frac12\\qquad\\forall k=1,2,\\dotsc,n.\n\\end{align*}\\] しかし、 \\[\\begin{align*}\nf_{X_1,\\dotsc,X_n}(x_1,\\dotsc,x_n)&=\\prod_{k=1}^n f_{X_k}(x_k)\\qquad\\forall x_1,\\dotsc,x_n\\in\\{0,1\\}\n\\end{align*}\\] は成り立たないので独立ではない。"
  },
  {
    "objectID": "slides/03_multi.html#独立な離散型確率変数の和",
    "href": "slides/03_multi.html#独立な離散型確率変数の和",
    "title": "確率論",
    "section": "独立な離散型確率変数の和",
    "text": "独立な離散型確率変数の和\n離散型確率変数 \\(X_1\\) と \\(X_2\\) が独立であるとする。 このとき、\\(X_1+X_2\\) の確率質量関数は \\[\\begin{align*}\nf_{X_1+X_2}(x) &= \\sum_z f_{X_1}(z)f_{X_2}(x-z)\n\\end{align*}\\] で与えられる。 これを確率質量関数の畳み込みという。\n\nExample 3 二項分布の \\(N=1\\) の場合をベルヌーイ分布 \\(\\mathrm{Ber}(p)\\) と呼ぶ。 つまり、\\(X\\sim\\mathrm{Ber}(p)\\defiff\\) \\[\\begin{align*}\n\\Pr(X=0) &= 1-p,& \\Pr(X=1) &= p\n\\end{align*}\\] である。 確率変数 \\(X_1,X_2\\) が独立で \\(\\mathrm{Ber}(p)\\) に従うとする。 このとき、\\(X_1+X_2\\) は \\(\\mathrm{Binom}(2, p)\\) に従う。 \\[\\begin{align*}\n\\Pr(X_1+X_2 = 0) &= \\Pr(X_1=0,\\,X_2=0)\n= \\Pr(X_1=0)\\Pr(X_2=0) = (1-p)^2\\\\\n\\Pr(X_1+X_2 = 1) &= \\Pr(X_1=0,\\,X_2=1) + \\Pr(X_1=1,\\,X_2=0)\\\\\n&=  \\Pr(X_1=0)\\Pr(X_2=1) + \\Pr(X_1=1)\\Pr(X_2=0)\\\\\n&= 2p(1-p)\\\\\n\\Pr(X_1+X_2 = 2) &= \\Pr(X_1=1,\\,X_2=1)\n= \\Pr(X_1=1)\\Pr(X_2=1) = p^2\n\\end{align*}\\] と計算できる。 よって \\[\\begin{align*}\n\\Pr(X_1+X_2 = k) &= \\binom{2}{k} p^k(1-p)^{2-k}\n\\end{align*}\\] が成り立ち \\(X_1+X_2\\sim\\mathrm{Binom}(2, p)\\) であることが分かる。"
  },
  {
    "objectID": "slides/03_multi.html#二項分布の再生性",
    "href": "slides/03_multi.html#二項分布の再生性",
    "title": "確率論",
    "section": "二項分布の再生性",
    "text": "二項分布の再生性\n確率分布の族(集合)が畳み込みに閉じているとき、確率分布の族は再生性を持つという。 二項分布の場合はパラメータ \\(p\\) を固定したときに再生性を持つ。\n\nExample 4 一般に、独立確率変数 \\(X_1,\\,X_2\\) について \\(X_1\\sim\\mathrm{Binom}(n, p)\\), \\(X_2\\sim\\mathrm{Binom}(m, p)\\) のとき、\\(X_1+X_2\\sim\\mathrm{Binom}(n+m,p)\\) である。 \\[\\begin{align*}\n\\Pr(X_1+X_2 = k) &= \\sum_{\\ell\\ge 0} \\Pr(X_1 = \\ell) \\Pr(X_2 = k-\\ell)\\\\\n&= \\sum_{\\ell\\ge 0} \\binom{n}{\\ell} p^\\ell(1-p)^{n-\\ell} \\binom{m}{k-\\ell} p^{k-\\ell}(1-p)^{m-k+\\ell}\\\\\n&= \\left(\\sum_{\\ell= 0}^k \\binom{n}{\\ell} \\binom{m}{k-\\ell}\\right) p^k(1-p)^{n+m-k}\\\\\n&= \\binom{n+m}{k} p^k(1-p)^{n+m-k}.\n\\end{align*}\\]"
  },
  {
    "objectID": "slides/03_multi.html#ポアソン分布の再生性",
    "href": "slides/03_multi.html#ポアソン分布の再生性",
    "title": "確率論",
    "section": "ポアソン分布の再生性",
    "text": "ポアソン分布の再生性\nポアソン分布も再生性を持つ。\n\nExample 5 確率変数 \\(X_1\\), \\(X_2\\) が独立で \\(X_1\\sim\\mathrm{Poisson}(\\lambda_1)\\), \\(X_2\\sim\\mathrm{Poisson}(\\lambda_2)\\) とする。 このとき、 \\[\\begin{align*}\nf_{X_1+X_2}(x) &= \\sum_{z= 0}^x f_{X_1}(z) f_{X_2}(x-z)\\\\\n&= \\sum_{z= 0}^x \\frac{\\lambda_1^z}{z!}\\mathrm{e}^{-\\lambda_1}\\frac{\\lambda_2^{x-z}}{(x-z)!}\\mathrm{e}^{-\\lambda_2}\\\\\n&= \\frac1{x!}\\mathrm{e}^{-(\\lambda_1+\\lambda_2)}\\sum_{z=0}^x\\binom{x}{z} \\lambda_1^z\\lambda_2^{x-z}\\\\\n&= \\frac1{x!}\\mathrm{e}^{-(\\lambda_1+\\lambda_2)}(\\lambda_1+\\lambda_2)^x\n\\end{align*}\\] が成り立つ。よって \\(X_1+X_2\\sim\\mathrm{Poisson}(\\lambda_1+\\lambda_2)\\) である。"
  },
  {
    "objectID": "slides/03_multi.html#独立な連続型確率変数の和",
    "href": "slides/03_multi.html#独立な連続型確率変数の和",
    "title": "確率論",
    "section": "独立な連続型確率変数の和",
    "text": "独立な連続型確率変数の和\n連続確率変数 \\(X_1\\) と \\(X_2\\) が独立で密度関数を持つとき、 \\[\\begin{align*}\n\\Pr(X_1+X_2\\in A) &= \\int\\int_{y+z\\in A} f_{X_1}(y)f_{X_2}(z)\\mathrm{d}y\\mathrm{d}z\\\\\n&= \\int\\int_{x\\in A} f_{X_1}(y)f_{X_2}(x-y)\\mathrm{d}y\\mathrm{d}x \\qquad(x=y+z)\\\\\n&= \\int_{A} \\left(\\int_{-\\infty}^\\infty f_{X_1}(y)f_{X_2}(x-y)\\mathrm{d}y\\right)\\mathrm{d}x \\qquad(x=y+z)\\\\\n\\end{align*}\\] と表せるので、\\(X_1+X_2\\) は確率密度関数を持ち \\[\\begin{align*}\nf_{X_1+X_2}(x) &= \\int_{-\\infty}^\\infty f_{X_1}(z)f_{X_2}(x-z)\\mathrm{d} z\n\\end{align*}\\] とすることができる。 これを確率密度関数の畳み込みという。"
  },
  {
    "objectID": "slides/03_multi.html#正規分布の再生性",
    "href": "slides/03_multi.html#正規分布の再生性",
    "title": "確率論",
    "section": "正規分布の再生性",
    "text": "正規分布の再生性\n確率変数 \\(X_1,\\,X_2\\) が独立で \\(X_1\\sim N(\\mu_1,\\,\\sigma_1^2)\\), \\(X_2\\sim N(\\mu_2,\\,\\sigma_2^2)\\) とする。 このとき、 \\[\\begin{align*}\nf_{X_1+X_2}(x) &= \\int_{-\\infty}^\\infty f_{X_1}(z)f_{X_2}(x-z)\\mathrm{d} z\\\\\n&= \\int_{-\\infty}^\\infty \\frac1{\\sqrt{2\\pi\\sigma_1^2}} \\mathrm{e}^{-\\frac{(z-\\mu_1)^2}{2\\sigma_1^2}}\\frac1{\\sqrt{2\\pi\\sigma_2^2}} \\mathrm{e}^{-\\frac{(x-z-\\mu_2)^2}{2\\sigma_2^2}}\\mathrm{d} z\\\\\n&= \\frac1{2\\pi\\sqrt{\\sigma_1^2\\sigma_2^2}}\\int_{-\\infty}^\\infty  \\mathrm{e}^{-\\frac{\\sigma_2^2(z-\\mu_1)^2+\\sigma_1^2(x-z-\\mu_2)^2}{2\\sigma_1^2\\sigma_2^2}}\\mathrm{d} z\\\\\n&= \\frac1{2\\pi\\sqrt{\\sigma_1^2\\sigma_2^2}}\\int_{-\\infty}^\\infty  \\mathrm{e}^{-\\frac{(\\sigma_1^2+\\sigma_2^2)\\left(z-\\frac{\\sigma_2^2\\mu_1+\\sigma_1^2(x-\\mu_2)}{\\sigma_1^2+\\sigma_2^2}\\right)^2 + \\sigma_2^2\\mu_1^2 + \\sigma_1^2(x-\\mu_2)^2 - \\frac{(\\sigma_2^2\\mu_1+\\sigma_1^2(x-\\mu_2))^2}{\\sigma_1^2+\\sigma_2^2}}{2\\sigma_1^2\\sigma_2^2}}\\mathrm{d} z\\\\\n&= \\frac1{\\sqrt{2\\pi(\\sigma_1^2+\\sigma_2^2)}}\\mathrm{e}^{-\\frac{\\sigma_2^2\\mu_1^2 + \\sigma_1^2(x-\\mu_2)^2 - \\frac{(\\sigma_2^2\\mu_1+\\sigma_1^2(x-\\mu_2))^2}{\\sigma_1^2+\\sigma_2^2}}{2\\sigma_1^2\\sigma_2^2}}\\\\\n&= \\frac1{\\sqrt{2\\pi(\\sigma_1^2+\\sigma_2^2)}}\\mathrm{e}^{-\\frac{(x-(\\mu_1+\\mu_2))^2}{2(\\sigma_1^2+\\sigma_2^2)}}\\\\\n\\end{align*}\\] が成り立つので \\(X_1+X_2\\sim N(\\mu_1+\\mu_2,\\,\\sigma_1^2+\\sigma_2^2)\\) であることが分かる。 よって正規分布は再生性を持つ。"
  },
  {
    "objectID": "slides/03_multi.html#今週の課題",
    "href": "slides/03_multi.html#今週の課題",
    "title": "確率論",
    "section": "今週の課題",
    "text": "今週の課題\n以下の問に答えよ\n\n\n共通の確率空間上の離散型確率変数 \\(X\\) と \\(Y\\) が以下の同時確率質量関数を持つとする。 \\[\\begin{align*}\nf_{X,\\,Y}(0,\\,0) &= a,&\nf_{X,\\,Y}(0,\\,1) &= b,&\nf_{X,\\,Y}(0,\\,2) &= c,\\\\\nf_{X,\\,Y}(1,\\,0) &= d,&\nf_{X,\\,Y}(1,\\,1) &= e,&\nf_{X,\\,Y}(1,\\,2) &= f\n\\end{align*}\\] ここで、 \\(a,b,c,d,e,f\\in\\mathbb{R}_{\\ge 0}\\) は \\(a+b+c+d+e+f=1\\) を満たすものとする。 このとき、周辺確率質量関数 \\(f_X\\) と \\(f_Y\\) をもとめよ。\n確率変数 \\(X\\) と \\(Y\\) が独立で \\[\\begin{align*}\nX&\\sim\\mathrm{Ber}(p)& p\\in[0,1]\\\\\nY&\\sim\\mathrm{Poisson}(\\lambda)& \\lambda &gt; 0\n\\end{align*}\\] とする。 このとき、 \\(X+Y\\) の確率質量関数をもとめよ。結果の式は共通因子でくくらなくてよい(採点が楽なので)。"
  },
  {
    "objectID": "slides/macros.html",
    "href": "slides/macros.html",
    "title": "確率・統計基礎",
    "section": "",
    "text": "\\[\n\\newcommand{\\defiff}{\\overset{\\text{def}}{\\iff}}\n\\newcommand{\\expt}[1]{\\mathbb{E}\\left[#1\\right]}\n\\newcommand{\\var}[1]{\\mathrm{Var}\\left[#1\\right]}\n\\newcommand{\\cov}[2]{\\mathrm{Cov}\\left[#1,\\,#2\\right]}\n\\]"
  },
  {
    "objectID": "slides/11_stationary.html#スペクトル半径-12",
    "href": "slides/11_stationary.html#スペクトル半径-12",
    "title": "確率論",
    "section": "スペクトル半径 1/2",
    "text": "スペクトル半径 1/2\n\nDefinition 1 (スペクトル半径) 正方行列 \\(A\\in\\mathbb{C}^{n\\times n}\\) について、その固有値の絶対値の最大値をスペクトル半径といい \\(\\rho(A)\\) で表す 。\n\n\n\n\n\n\n\nCaution\n\n\nスペクトルノルムはスペクトル半径と似た概念であるが異なるものである。 正方行列とは限らない行列 \\(A\\in\\mathbb{C}^{n\\times m}\\) のスペクトルノルムは \\[\\begin{align*}\n\\|A\\|_2&\\coloneqq \\max_{x\\in\\mathbb{C}^m \\setminus\\{0\\}} \\frac{\\|Ax\\|_2}{\\|x\\|_2}\n\\end{align*}\\] と定義される。 ここで、右辺の \\(\\|\\cdot\\|_2\\) は複素ユークリッド空間上の \\(L_2\\) ノルムを表す。ここで、 \\[\\begin{align*}\n\\|A\\|_2&=\n\\max_{x\\in\\mathbb{C}^m \\setminus\\{0\\}} \\left\\|A\\frac{x}{\\|x\\|_2}\\right\\|_2\\\\\n&=\\max_{x\\in\\mathbb{C}^m\\colon\\, \\|x\\|_2=1} \\left\\|Ax\\right\\|_2\\\\\n&=\\max_{x\\in\\mathbb{C}^m\\colon\\, \\|x\\|_2=1} \\sqrt{\\left\\|Ax\\right\\|_2^2}\\\\\n&=\\sqrt{\\max_{x\\in\\mathbb{C}^m\\colon\\, \\|x\\|_2=1} x^*A^*Ax}\\\\\n&=\\sqrt{\\lambda_{\\max}(A^*A)}\\\\\n&=\\sigma_{\\max}(A)\n\\end{align*}\\] である。\\(\\lambda_{\\max}\\) と \\(\\sigma_{\\max}\\) は最大固有値と最大特異値を表す。"
  },
  {
    "objectID": "slides/11_stationary.html#スペクトル半径-22",
    "href": "slides/11_stationary.html#スペクトル半径-22",
    "title": "確率論",
    "section": "スペクトル半径 2/2",
    "text": "スペクトル半径 2/2\n\n\n\n\n\n\nCaution\n\n\n直感的な意味としては\n\nスペクトルノルム\\(\\colon\\) 線形写像 \\(A\\) が \\(L_2\\) ノルムをどれだけ大きくするか？\nスペクトル半径 \\(\\colon\\) 線形写像 \\(A\\) が向きを変えずに \\(L_2\\) ノルムをどれだけ大きくするか？\n\nということになる。 これらの意味から \\(\\|A\\|_2\\ge\\rho(A)\\) であることが分かる。 実際 \\(\\|A\\|_2\\) の定義の中で \\(x\\) として \\(A\\) の絶対値最大固有値に対応する固有ベクトルを選べばこの不等式が得られる。\n正方行列 \\(A\\in\\mathbb{C}^{n\\times n}\\) が正規行列のとき、スペクトル分解定理よりユニタリ行列 \\(U\\) と対角行列 \\(D\\) を用いて \\(A = UDU^*\\) と表せる。 このとき、\\(A^*A=UD^*DU^*\\) であることから、簡単な計算により \\(\\|A\\|_2=\\rho(A)\\) であることが分かる。\nしかし一般的には(対角化可能であっても)スペクトル半径とスペクトルノルムは異なる。 例えば、 \\[\\begin{align*}\nA&=\\begin{bmatrix}\n1&0\\\\\n1&0\n\\end{bmatrix}\n\\end{align*}\\] とすると、 \\(A\\) の固有値は 0 と 1 なので\\(\\rho(A)=1\\) である。 一方で、 \\[\\begin{align*}\nA^*A&=\n\\begin{bmatrix}\n2&0\\\\\n0&0\n\\end{bmatrix}\n\\end{align*}\\] より、\\(A^*A\\) の固有値は 0 と 2 である。 よって、\\(A\\) のスペクトルノルムは \\(\\|A\\|_2=\\sqrt{2} &gt; 1 =\\rho(A)\\) である。 ここで、\\(A\\) は確率行列であり、二つの異なる固有値を持つので対角化可能である。 また、スペクトル半径はノルムにもならない。 \\[\\begin{align*}\n\\rho\\left(\\begin{bmatrix}0&1\\\\0&0\\end{bmatrix}\\right) &= 0\n\\end{align*}\\] であるし、 \\[\\begin{align*}\n1&=\\rho\\left(\\begin{bmatrix}0&1\\\\1&0\\end{bmatrix}\\right) &gt;\n\\rho\\left(\\begin{bmatrix}0&1\\\\0&0\\end{bmatrix}\\right) +\n\\rho\\left(\\begin{bmatrix}0&0\\\\1&0\\end{bmatrix}\\right) = 0\n\\end{align*}\\] なので三角不等式も満たさない。\n\n\n\n\nLemma 1 任意の確率行列 \\(T\\) について、\\(\\rho(T)=1\\) である。\n\n\nProof. すべての成分が1の列ベクトルは確率行列 \\(T\\) の固有値1に対する右固有ベクトルになるので、\\(\\rho(T)\\ge 1\\) である。\n以下では \\(\\rho(T)\\le 1\\) を示す。 遷移行列 \\(T\\) の固有値 \\(\\lambda\\in\\mathbb{C}\\) に対応する固有ベクトルを \\(v\\) とすると \\[\\begin{align*}\nTv &= \\lambda v\n\\end{align*}\\] が成り立つ。 \\(v\\) の成分で絶対値最大のものを第 \\(i\\) 成分とする。 第 \\(i\\) 成分に注目すると \\[\\begin{align*}\n\\sum_{j\\in S}T_{i,j}v_j &= \\lambda v_i\n\\end{align*}\\] が成り立つ。ここで \\[\\begin{align*}\n|\\lambda| |v_i| &= \\left|\\sum_{j\\in S}T_{i,j}v_j\\right|\\\\\n&\\le \\sum_{j\\in S}T_{i,j}\\left|v_j\\right|\\\\\n&\\le \\sum_{j\\in S}T_{i,j}\\left|v_i\\right|\\\\\n&=\\left|v_i\\right|\n\\end{align*}\\] と \\(|v_i|&gt;0\\) より、 \\(|\\lambda|\\le 1\\) である。"
  },
  {
    "objectID": "slides/11_stationary.html#確率行列のスペクトル半径",
    "href": "slides/11_stationary.html#確率行列のスペクトル半径",
    "title": "確率論",
    "section": "確率行列のスペクトル半径",
    "text": "確率行列のスペクトル半径\n\nLemma 2 任意の確率行列 \\(T\\) について、\\(\\rho(T)=1\\) である。\n\n\nProof. すべての成分が1の列ベクトルは確率行列 \\(T\\) の固有値1に対する右固有ベクトルになるので、\\(\\rho(T)\\ge 1\\) である。\n以下では \\(\\rho(T)\\le 1\\) を示す。 遷移行列 \\(T\\) の固有値 \\(\\lambda\\in\\mathbb{C}\\) に対応する固有ベクトルを \\(v\\) とすると \\[\\begin{align*}\nTv &= \\lambda v\n\\end{align*}\\] が成り立つ。 \\(v\\) の成分で絶対値最大のものを第 \\(i\\) 成分とする。 第 \\(i\\) 成分に注目すると \\[\\begin{align*}\n\\sum_{j\\in S}T_{i,j}v_j &= \\lambda v_i\n\\end{align*}\\] が成り立つ。ここで \\[\\begin{align*}\n|\\lambda| |v_i| &= \\left|\\sum_{j\\in S}T_{i,j}v_j\\right|\\\\\n&\\le \\sum_{j\\in S}T_{i,j}\\left|v_j\\right|\\\\\n&\\le \\sum_{j\\in S}T_{i,j}\\left|v_i\\right|\\\\\n&=\\left|v_i\\right|\n\\end{align*}\\] と \\(|v_i|&gt;0\\) より、 \\(|\\lambda|\\le 1\\) である。"
  },
  {
    "objectID": "slides/11_stationary.html#定常分布",
    "href": "slides/11_stationary.html#定常分布",
    "title": "確率論",
    "section": "定常分布",
    "text": "定常分布\nマルコフ連鎖の推移行列 \\(T\\) について、 \\[\\begin{align*}\n\\mu T &= \\mu\n\\end{align*}\\] を満たす確率ベクトル(非負で成分の和が1) \\(\\mu\\) を定常分布と呼ぶのであった。 今回は定常分布の存在と唯一性について考える。\n\nDefinition 2 (有向グラフ) 有限集合 \\(V\\) と集合 \\(E\\subseteq V\\times V\\) のペア \\(G=(V,\\,E)\\) を有向グラフという。 \\(V\\) の元を頂点、\\(E\\) の元を辺(有向辺)と呼ぶ。\n\n有向辺 \\((u,v)\\in E\\) は頂点 \\(u\\) から頂点 \\(v\\) への有向辺と解釈することにする。\n\n\n\n\n\n\n\nirreduc_graph\n\n\n\n1\n\n1\n\n\n\n2\n\n2\n\n\n\n1-&gt;2\n\n\n\n\n\n3\n\n3\n\n\n\n2-&gt;3\n\n\n\n\n\n5\n\n5\n\n\n\n2-&gt;5\n\n\n\n\n\n3-&gt;1\n\n\n\n\n\n4\n\n4\n\n\n\n3-&gt;4\n\n\n\n\n\n4-&gt;2\n\n\n\n\n\n4-&gt;4\n\n\n\n\n\n5-&gt;1\n\n\n\n\n\n\n 有向グラフ \\(G=(V=\\{1,2,3,4,5\\},\\, E=\\{(1,2),\\,(2,3),\\,(2,5),\\,(3,1),\\,(3,4),\\,(4,2),\\,(5,1)\\})\\)"
  },
  {
    "objectID": "slides/11_stationary.html#遷移グラフ",
    "href": "slides/11_stationary.html#遷移グラフ",
    "title": "確率論",
    "section": "遷移グラフ",
    "text": "遷移グラフ\n\nDefinition 3 (遷移グラフ) 有向グラフ \\(G=(V,\\,E)\\) が状態集合 \\(S\\) 上のマルコフ連鎖の遷移行列 \\(T\\) の遷移グラフ \\(\\defiff\\) \\[\\begin{align*}\nV&= S\\\\\nE&=\\left\\{(u,v)\\in V\\times V\\mid T_{u,v}&gt;0\\right\\}.\n\\end{align*}\\]\n\nマルコフ連鎖の定常分布や収束に関する議論をする際には遷移確率は 0 か正かということが問題になり、具体的な値は問題にならない。 したがって、定常分布が唯一であるための条件などは遷移グラフの性質として表すことができる。\n\nDefinition 4 (有向グラフのウォーク) 有向グラフ \\(G=(V,E)\\) の頂点列 \\[\\begin{align*}\n(v_0,v_1,\\dotsc,v_\\ell)\n\\end{align*}\\] で各 \\(i=0,1,\\dotsc,\\ell-1\\) について \\((v_i,\\,v_{i+1})\\in E\\) を満たすものを(\\(v_0\\) から \\(v_{\\ell}\\) への)ウォークという。 また、\\(\\ell\\) をウォークの長さという。\n\n頂点列 \\((v)\\) は長さ0のウォークであることに気をつけよう。 遷移グラフの定義より、任意の \\(u,v\\in S\\) について \\[\\begin{align*}\n&\\text{遷移グラフ上に $u$ から $v$ への長さ $\\ell$ のウォークが存在する} \\iff (T^\\ell)_{u,v} &gt; 0\\\\\n\\iff&\\Pr(X_\\ell=v\\mid X_0=u) &gt; 0\n\\end{align*}\\] である。"
  },
  {
    "objectID": "slides/11_stationary.html#既約性と定常分布",
    "href": "slides/11_stationary.html#既約性と定常分布",
    "title": "確率論",
    "section": "既約性と定常分布",
    "text": "既約性と定常分布\n\nDefinition 5 (順序関係) 推移行列 \\(T\\) を持つマルコフ連鎖の状態 \\(u,v\\in S\\) について \\(u\\le_T v\\) \\(\\defiff\\) その遷移グラフにおいて \\(u\\) から \\(v\\) へのウォークが存在する。 また、\\(u\\le_T v\\) かつ \\(v\\le_T u\\) のとき、\\(u\\sim_T v\\) とする。\n\nこの \\(\\le_T\\) は以下の前順序関係の公理を満たす。\n\n(反射律) \\(\\forall u\\in S,\\, u\\le_T u\\).\n(推移律) \\(\\forall u,v,w\\in S,\\, (u\\le_T v\\,\\land\\, v\\le_T w) \\implies u\\le_T w\\).\n\nまた、\\(\\sim_T\\) は以下の同値関係の公理を満たす。\n\n(反射律) \\(\\forall u\\in S,\\, u\\sim_T u\\).\n(対称律) \\(\\forall u,v\\in S,\\, u\\sim_T v\\implies v\\sim_T u\\).\n(推移律) \\(\\forall u,v,w\\in S,\\, (u\\sim_T v\\,\\land\\, v\\sim_T w) \\implies u\\sim_T w\\).\n\n\nDefinition 6 (マルコフ連鎖の既約性) マルコフ連鎖が既約である \\(\\defiff\\) 任意の \\(u,v\\in S\\) について \\(u\\sim_T v\\). \n\n有向グラフ \\(G\\) の任意の頂点 \\(u, v\\in V\\) について \\(u\\) から \\(v\\) へのウォークが存在するとき、\\(G\\) は強連結であるという。 よってマルコフ連鎖が既約 \\(\\iff\\) 遷移グラフが強連結である。\n\n\n\n\n\n\n\nirreduc_graph\n\n\n\n1\n\n1\n\n\n\n2\n\n2\n\n\n\n1-&gt;2\n\n\n\n\n\n3\n\n3\n\n\n\n2-&gt;3\n\n\n\n\n\n5\n\n5\n\n\n\n2-&gt;5\n\n\n\n\n\n3-&gt;1\n\n\n\n\n\n4\n\n4\n\n\n\n3-&gt;4\n\n\n\n\n\n4-&gt;2\n\n\n\n\n\n4-&gt;4\n\n\n\n\n\n5-&gt;1\n\n\n\n\n\n\n 既約なマルコフ連鎖の遷移グラフ。任意の頂点 \\(u, v\\in V\\) について、\\(u\\) から \\(v\\) へのウォークが存在する。"
  },
  {
    "objectID": "slides/11_stationary.html#既約なマルコフ連鎖",
    "href": "slides/11_stationary.html#既約なマルコフ連鎖",
    "title": "確率論",
    "section": "既約なマルコフ連鎖",
    "text": "既約なマルコフ連鎖\n\nLemma 3 既約なマルコフ連鎖について \\(\\mathrm{Ker}(I-T)=\\mathrm{span}(1)\\) である。\n\n\nProof. 列ベクトル \\(v\\in\\mathbb{R}^n\\) を \\[\\begin{align*}\n(I-T)v = 0 &\\iff Tv = v\n\\end{align*}\\] を満たすものとする。 このとき、\\(i\\in\\arg\\max_{k\\in S} v_k\\) とすると \\[\\begin{align*}\nv_i &= \\sum_{j\\in S} T_{i,j} v_j\\\\\n&= \\sum_{j\\in S\\colon\\,(i,j)\\in E} T_{i,j} v_j\\\\\n&\\le \\sum_{j\\in S\\colon\\,(i,j)\\in E} T_{i,j} v_i\\\\\n&= v_i\n\\end{align*}\\] という不等式が得られる。 この不等号は等号でなくてはいけないので、 \\[\\begin{align*}\nv_j &= v_i\\qquad\\text{if } (i, j)\\in E\n\\end{align*}\\] である。 この議論を繰り返すと \\(i\\le_T j\\) である \\(j\\) について \\(v_j=v_i\\) である。 マルコフ連鎖が既約であることから、任意の \\(j\\in S\\) について \\(i\\le j\\) であり、\\(v = v_i 1\\) である。 したがって、\\(\\mathrm{Ker}(I-T)=\\mathrm{span}(1)\\) である。\n\nよって既約なマルコフ連鎖に対して定常分布は高々一つである。 実際には既約なマルコフ連鎖は一つの定常分布を持つ。"
  },
  {
    "objectID": "slides/11_stationary.html#既約なマルコフ連鎖の定常分布",
    "href": "slides/11_stationary.html#既約なマルコフ連鎖の定常分布",
    "title": "確率論",
    "section": "既約なマルコフ連鎖の定常分布",
    "text": "既約なマルコフ連鎖の定常分布\n\nTheorem 1 既約なマルコフ連鎖は唯一の定常分布 \\(\\mu\\in\\mathbb{R}_{&gt;0}^n\\) を持つ。\n\n\nProof. マルコフ連鎖のラプラシアン行列を \\(\\Lambda \\coloneqq I-T\\) と定義する。 ラプラシアン行列の余因子行列を \\(\\mathrm{adj}(\\Lambda)\\) で表す(\\(\\mathrm{adj}(\\Lambda)\\) の \\((i,j)\\) 成分は \\((j,i)\\) 余因子である)。 余因子展開より \\[\\begin{align*}\n\\mathrm{adj}(\\Lambda)\\Lambda &= \\Lambda\\,\\mathrm{adj}(\\Lambda) = \\det(\\Lambda)I\n\\end{align*}\\] である。確率行列 \\(T\\) は固有値1を持つので、\\(\\det(\\Lambda)=0\\) である。 よって、 \\[\\begin{align*}\n\\mathrm{adj}(\\Lambda)\\Lambda &= \\Lambda\\,\\mathrm{adj}(\\Lambda) = O\n\\end{align*}\\] である。 まず、\\(\\Lambda\\,\\mathrm{adj}(\\Lambda)=O\\) と Lemma 3 より \\(\\mathrm{adj}(\\Lambda)\\) の各列は \\(1\\) のスカラー倍である。よって、\\(\\mathrm{adj}(\\Lambda)\\) の行はすべて等しい。 次に、\\(\\mathrm{adj}(\\Lambda)\\Lambda=O\\) より、\\(\\mathrm{adj}(\\Lambda)\\) の行 \\(\\mu\\in\\mathbb{R}^n\\) は \\(\\mu\\Lambda=0\\) を満たす。 ここで、\\(\\mathrm{adj}(\\Lambda)\\) の行がすべて等しいことから \\[\\begin{align*}\n\\mu_i &= \\mathrm{adj}(\\Lambda)_{i,i}\\qquad\\forall i\\in S\n\\end{align*}\\] が成り立つ。 よって \\[\\begin{align*}\n\\mathrm{adj}(\\Lambda)_{i,i}&&gt;0\\qquad\\forall i\\in S\n\\end{align*}\\] を示せば十分である。 余因子行列の定義より、 \\[\\begin{align*}\n\\mathrm{adj}(\\Lambda)_{i,i}&= \\det(I - T^{(i)})\n\\end{align*}\\] である。 ここで、\\(T^{(i)}\\) は \\(T\\) の \\(i\\) 行目と \\(i\\) 列目を削除して得られる行列である。\n目標である \\(\\det(I-T^{(i)})&gt;0\\) を示すためには \\(\\rho(T^{(i)})&lt;1\\) を示せば十分である。"
  },
  {
    "objectID": "slides/11_stationary.html#スペクトル半径と行列式",
    "href": "slides/11_stationary.html#スペクトル半径と行列式",
    "title": "確率論",
    "section": "スペクトル半径と行列式",
    "text": "スペクトル半径と行列式\n\nLemma 4 任意の実正方行列 \\(A\\) について、\\(\\rho(A)&lt;1\\) ならば \\(\\det(I-A)&gt;0\\) である。\n\n\n\n\n\n\n\n代数的な証明\n\n\n実正方行列 \\(A\\) の固有値の多重集合を \\(\\mathrm{spec}(A)\\) で表すことにする。 実多項式の実数でない根はその複素共役とペアで現れることに注意すると、 \\[\\begin{align*}\n\\det(I-A)&= \\prod_{\\lambda\\in\\mathrm{spec}(A)} (1-\\lambda)\\\\\n&= \\prod_{\\lambda\\in\\mathrm{spec}(A)\\cap\\mathbb{R}} (1-\\lambda)\n\\cdot \\prod_{\\lambda\\in\\mathrm{spec}(A)\\setminus\\mathbb{R}} (1-\\lambda)\\\\\n&= \\prod_{\\lambda\\in\\mathrm{spec}(A)\\cap\\mathbb{R}} (1-\\lambda)\n\\cdot \\prod_{\\lambda\\in\\mathrm{spec}(A)\\setminus\\mathbb{R}} |1-\\lambda|\\\\\n\\end{align*}\\] よって \\(\\rho(A)&lt;1\\) であれば \\(\\det(I-A)&gt;0\\) である。\n\n\n\n\n\n\n\n\n\n解析的な証明\n\n\n実正方行列 \\(A\\) の特性多項式を \\[\\begin{align*}\np_A(x) &\\coloneqq \\det(xI - A)\n\\end{align*}\\] と定義する。 これはモニックな多項式であるため \\(x\\to+\\infty\\) で \\(p_A(x)\\to+\\infty\\) である。 よって \\(p_A(x)\\) が実根を持たないもしくは、すべての実根が 1 未満であれば \\(p_A(1)&gt;0\\) である。 特性多項式 \\(p_A\\) の根は \\(A\\) の固有値なので、\\(\\rho(A)&lt;1\\) であれば \\(p_A(1)=\\det(I-A)&gt;0\\) である。"
  },
  {
    "objectID": "slides/11_stationary.html#証明の続き",
    "href": "slides/11_stationary.html#証明の続き",
    "title": "確率論",
    "section": "証明の続き",
    "text": "証明の続き\nよって、\\(\\rho(T^{(i)})&lt;1\\) を示せば \\(\\mathrm{adj}(\\Lambda)_{i,i}=\\det(I-T^{(i)}) &gt; 0\\) がしたがう。\n\\(T^{(i)}\\) の絶対値最大の固有値を \\(\\lambda\\) とおき、対応する固有ベクトルを \\(v\\) とする。 このとき \\[\\begin{align*}\nT^{(i)}v &= \\lambda v\n\\end{align*}\\] が成り立つ。 \\(v\\) の絶対値最大の成分のインデックスを \\(j\\in S\\setminus\\{i\\}\\) とおく。 マルコフ連鎖が既約であることから、その遷移グラフ上で \\(j\\) から \\(i\\) へのウォークが存在する。 そのウォークの長さを \\(\\ell\\in\\mathbb{Z}_{\\ge 1}\\) とおく。 このとき、\\(S\\coloneqq T^{(i)\\ell}\\) とおくと、 \\[\\begin{align*}\nS v &= \\lambda^\\ell v\n\\end{align*}\\] である。 ここで、\\(S\\) の \\(j\\) 行目の和は \\[\\begin{align*}\n\\sum_k S_{j,k} &= \\Pr(X_1\\ne i,\\dotsc,X_\\ell \\ne i\\mid X_0 = j) &lt; 1\n\\end{align*}\\] である。 よって、 \\[\\begin{align*}\n|\\lambda^\\ell v_j| &= |(S v)_j|\n= \\left|\\sum_{k}S_{j,k} v_k\\right|\\\\\n&\\le \\sum_{k}S_{j,k} \\left|v_k\\right|\n\\le \\sum_{k}S_{j,k} |v_j| &lt; |v_j|\\\\\n\\end{align*}\\] である。\\(|v_j|&gt;0\\) より、\\(|\\lambda|&lt;1\\) である。 したがって、\\(\\rho(T^{(i)}) &lt; 1\\) であることが示された。"
  },
  {
    "objectID": "slides/11_stationary.html#今週の課題",
    "href": "slides/11_stationary.html#今週の課題",
    "title": "確率論",
    "section": "今週の課題",
    "text": "今週の課題\n以下の推移行列を持つマルコフ連鎖の遷移グラフを描け。 状態のラベルは行と列のインデックスに対応して \\(i,j=1,2,\\dotsc,\\) とする。 また、それぞれのマルコフ連鎖が既約であるか判定せよ。 既約である場合は「既約である」、 既約でない場合は「状態 \\(i\\) から状態 \\(j\\) へ推移できないため既約でない」と記せ。 既約でないことを示すための状態ペア \\((i,\\,j)\\) は一つ示せばよい。\n\n\n\\[\\begin{align*}\n\\begin{bmatrix}\n1/2&1/3&1/6\\\\\n1/4&1/2&1/4\\\\\n1/3&1/3&1/3\n\\end{bmatrix}\n\\end{align*}\\]\n\\[\\begin{align*}\n\\begin{bmatrix}\n0&1&0\\\\\n0&0&1\\\\\n1&0&0\n\\end{bmatrix}\n\\end{align*}\\]\n\\[\\begin{align*}\n\\begin{bmatrix}\n1/2&1/2&0\\\\\n0&1/2&1/2\\\\\n0&0&1\n\\end{bmatrix}\n\\end{align*}\\]\n\\[\\begin{align*}\n\\begin{bmatrix}\n1/2&1/2&0&0\\\\\n1/3&2/3&0&0\\\\\n0&0&0&1\\\\\n0&0&1&0\n\\end{bmatrix}\n\\end{align*}\\]"
  }
]